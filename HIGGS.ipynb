{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6a8aINrT-rM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://huggingface.co/ibm-ai-platform/Bamba-9B/blob/main/README.md"
      ],
      "metadata": {
        "id": "pHflhYjhha3A"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mw064mgXUJK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hugging Face's logo\n",
        "Hugging Face\n",
        "Models\n",
        "Datasets\n",
        "Spaces\n",
        "Docs\n",
        "Enterprise\n",
        "Pricing\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ibm-ai-platform\n",
        "/\n",
        "Bamba-9B\n",
        "\n",
        "like\n",
        "29\n",
        "\n",
        "Follow\n",
        "\n",
        "ibm-ai-platform\n",
        "65\n",
        "Text Generation\n",
        "Transformers\n",
        "Safetensors\n",
        "GGUF\n",
        "bamba\n",
        "Inference Endpoints\n",
        "\n",
        "License:\n",
        "apache-2.0\n",
        "Model card\n",
        "Files\n",
        "Community\n",
        "2\n",
        "Bamba-9B\n",
        "/\n",
        "README.md\n",
        "\n",
        "Linsong-C's picture\n",
        "Linsong-C\n",
        "Update README.md\n",
        "0cbf233\n",
        "verified\n",
        "about 1 month ago\n",
        "preview\n",
        "code\n",
        "|\n",
        "raw\n",
        "\n",
        "Copy download link\n",
        "history\n",
        "blame\n",
        "contribute\n",
        "delete\n",
        "13.1 kB\n",
        "metadata\n",
        "license: apache-2.0\n",
        "library_name: transformers\n",
        "tags:\n",
        "  - bamba\n",
        "Model Details\n",
        "Bamba\n",
        "\n",
        "Model Card for Bamba 9B\n",
        "نقدم Bamba-9B ، وهو نموذج لغة لوحدة فك التشفير فقط يعتمد على بنية Mamba-2 وهو مصمم للتعامل مع مجموعة واسعة من مهام إنشاء النص. يتم تدريبه من الصفر باستخدام نهج تدريب على مرحلتين. في المرحلة الأولى ، يتم تدريب النموذج على 2 تريليون رمز مميز من مجموعة بيانات Dolma v1.7. في المرحلة الثانية ، تخضع لتدريب إضافي على 200 مليار رمز مميز ، والاستفادة من مزيج منسق بعناية من البيانات عالية الجودة لتحسين أدائها وتحسين جودة الإخراج.\n",
        "\n",
        "نموذج\tالمعلمات\t# الطبقات\tخافت مخفي.\tرؤوس الانتباه\tGQA\tرؤوس KV\tطول السياق\tالتضمينات المقيدة\n",
        "بامبا\t9 ب (9.78 مل)\t32\t4096\t32\tنعم\t8\t4096\tخطأ\n",
        "يتضمن الإصدار الحالي النماذج التالية:\n",
        "\n",
        "مرحلة\tبامبا 9 ب\tكمية\tملاحظه\n",
        "النموذج الأساسي\tآي بي إم إم إس / بامبا -9 ب\tآي بي إم-إف إم إس/بامبا-9ب-إف بي 8\tالمرحلة 2 التدريب المسبق\n",
        "النموذج الأساسي\tآي بي إم إم إس / بامبا -9 ب - 2 تي\tآي بي إم-إف إم إس/بامبا-9ب-إف بي 8\tالمرحلة 1 التدريب المسبق\n",
        "النموذج الأساسي\tآي بي إم إم إس / بامبا -9 ب - 1.8 تي\tآي بي إم-إف إم إس/بامبا-9ب-إف بي 8\tنقاط التفتيش الوسيطة خلال المرحلة 1 ، المزيد في المستقبل\n",
        "SFT\tقريباً\tقريباً\tليتم إصداره في القطرة التالية\n",
        "DPO\tقريباً\tقريباً\tليتم إصداره في القطرة التالية\n",
        "تم أيضا تحميل نقاط التفتيش الأصلية (بتنسيق DCP) إلى الحاوية العامة:\n",
        "\n",
        "bucket: bamba-public\n",
        "endpoint-url: https://s3.us-east.cloud-object-storage.appdomain.cloud\n",
        "مثال على الأمر لإدراج نقاط التفتيش الموزعة الأصلية في بامبا:\n",
        "\n",
        "aws --endpoint-url https://s3.us-east.cloud-object-storage.appdomain.cloud s3 ls s3://bamba-public/checkpoints/pretraining/phase_two/2_2t/step_140000_ckp/\n",
        "تركيب\n",
        "إلى جانب PyTorch ، ستحتاج إلى بعض التبعيات الإضافية ل نماذج مامبا.\n",
        "\n",
        "وجدنا أن بعض هذه التبعيات من الصعب إرضاءها في إصدارات PyTorch عند إجراء تثبيت النقطة ، لذلك أفضل طريقة هي البناء من المصدر لجميع تبعيات Mamba إذا ضغطت على التبعية مشكلة في ENV الخاص بك:\n",
        "\n",
        "git clone https://github.com/Dao-AILab/causal-conv1d.git\n",
        "cd causal-conv1d && pip install . && cd ..\n",
        "git clone https://github.com/state-spaces/mamba.git\n",
        "cd mamba && pip install . && cd ..\n",
        "git clone https://github.com/Dao-AILab/flash-attention.git\n",
        "cd flash-attention && pip install . && cd ..\n",
        "بالنسبة للمستخدمين الذين يستخدمون إصدارات HF الخاصة بنا من النموذج ، ستحتاج إلى تثبيت أحدث المحولات التي تتضمن تطبيقنا المدمج حديثا لطرازات Bamba الخاصة بنا:\n",
        "\n",
        "pip install git+https://github.com/huggingface/transformers.git\n",
        "استدلال\n",
        "يمكنك الاستفادة من تكامل HF الذي ساهم به حديثا لتشغيل الاستدلال على طرازات Bamba الخاصة بنا:\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"ibm-fms/Bamba-9B\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"ibm-fms/Bamba-9B\")\n",
        "\n",
        "message = [\"Mamba is a snake with following properties  \"]\n",
        "inputs = tokenizer(message, return_tensors='pt', return_token_type_ids=False)\n",
        "response = model.generate(**inputs, max_new_tokens=64)\n",
        "print(tokenizer.batch_decode(response, skip_special_tokens=True)[0])\n",
        "تدريب\n",
        "قمنا بتدريب نموذج Bamba الخاص بنا مع FSDP باستخدام مستودع التدريب الخاص بنا هنا. لاحظ أن هذا الجهد التدريبي بدأ قبل FSDP2 وأيضا قبل وقت طويل من مساهمتنا في HF ، لذلك كنا نقوم بتدريب FSDP1 مع تطبيق Mamba الرسمي. بالنسبة للمستخدمين الذين يحاولون إعادة إنتاج التدريب ، لديك الآن خيارات أكثر بكثير من خلال أحدث ساهم في إصدار HF من Mamba2-Hybrid.Mamba2-Hybrid\n",
        "\n",
        "الدرجات المعيارية\n",
        "النماذج الأساسية المدربة مسبقا\n",
        "باب\tالمعيار\tبامبا 9 ب (2.2 طن)\n",
        "عام\tMMLU (5 طلقات)\t60.77\n",
        "ARC-C (25 طلقة)\t63.23\n",
        "GSM8K (5 لقطات)\t36.77\n",
        "هيلاسواج (10 طلقات)\t81.8\n",
        "OpenbookQA (5 طلقات)\t47.6\n",
        "بيكا (5 طلقات)\t82.26\n",
        "TruthfulQA (0 طلقة)\t49.21\n",
        "وينوغراندي (5 طلقات)\t76.87\n",
        "HF OpenLLM- V2*\tMMLU-PRO (5 طلقات)\t17.53\n",
        "BBH (3 طلقات)\t17.4\n",
        "GPQA (0 طلقة)\t4.14\n",
        "IFEval (0 طلقة)\t15.16\n",
        "الرياضيات المستوى 5 (4 طلقات)\t1.66\n",
        "MuSR (0 طلقة)\t9.59\n",
        "مهام السلامة\tPopQA (5 طلقات)\t20.5\n",
        "توكسيجين (5 طلقات)\t57.4\n",
        "شواء (5 طلقات)\t44.2\n",
        "أزواج الغربان الإنجليزية (5 طلقات)\t70.78\n",
        "* بالنسبة لنتائج لوحة المتصدرين v2 ، نقوم بإجراء التطبيع والإبلاغ عن النتائج الطبيعية. يمكن العثور على مزيد من التفاصيل حول تفاصيل التقييم والتطبيع جنبا إلى جنب مع البرامج النصية للتشغيل والتحليل هنا.\n",
        "\n",
        "Fine-tuning\n",
        "This example shows how to fine tune the bamba model for a specific task using SFT Trainer.\n",
        "\n",
        "Quantization\n",
        "We can create a (FP8) quantized model using fms-model-optimizer, which will make the storage and inference even more efficient.\n",
        "\n",
        "python -m fms_mo.run_quant \\\n",
        "    --model_name_or_path <\"path_to_original_model\"> \\\n",
        "    --quant_method fp8 \\\n",
        "    --torch_dtype bfloat16 \\\n",
        "    --output_dir <\"path_to_save_new_model\">\n",
        "Model size comparison before and after FP8:\n",
        "\n",
        "original\tquantized\n",
        "memory (total)\t39.12 GB\t10.83 GB\n",
        "memory (break-down)\ttorch.float32 39.12 GB\ttorch.bfloat16 2.10 GB\n",
        "8.73 GBtorch.float8_e4m3fn\n",
        "More details about can be found here.fms-model-optimizer\n",
        "\n",
        "Llama.cpp\n",
        "There is preliminary work to enable running Bamba architecture models using llama.cpp. This is work-in-progress, so should only be used as a guide for the adventurous!\n",
        "\n",
        "Known Limitations\n",
        "Currently, inference is only supported on CPUs\n",
        "Models quantized with exhibit bad performancellama-quantize\n",
        "Setup\n",
        "To enable Bamba support, you'll need to build from source using Gabe's fork.\n",
        "\n",
        "git clone --branch BambaArchitecture git@github.com:gabe-l-hart/llama.cpp.git\n",
        "cd llama.cpp\n",
        "mkdir build\n",
        "cd build\n",
        "# NOTE: To build with debug symbols and extra logging, use CMAKE_BUILD_TYPE=Debug\n",
        "cmake .. -DCMAKE_BUILD_TYPE=Release\n",
        "make -j\n",
        "Conversion to GGUF\n",
        "You can use a pre-converted GGUF file from Huggingface (e.g. bamba-9b.gguf). If one doesn't exist, you can use the convert_hf_to_gguf.py script from Gabe's fork to perform the conversion manually.\n",
        "\n",
        "# Install the python dependencies\n",
        "cd /path/to/llama.cpp\n",
        "pip install -r requirements/requirements-convert_hf_to_gguf.txt\n",
        "\n",
        "# Perform the conversion\n",
        "./convert_hf_to_gguf.py /path/to/bamba-model --outfile /path/to/bamba-model/bamba-model.gguf\n",
        "Run with llama-cli\n",
        "# Run the model with no layers on the GPU (CPU-only)\n",
        "cd /path/to/llama.cpp\n",
        "./bin/llama-cli  -ngl 0 -m /path/to/bamba-model/bamba-model.gguf -p \"Tell me a story about a developer and their dog\"\n",
        "Quantization with llama-quantize\n",
        "You can (optionally) quantize the GGUF model using 's built in quantizaiton tool .llama.cppllama-quantize\n",
        "\n",
        "# Run the quantization (see llama-quantize --help for all quant types)\n",
        "cd /path/to/llama.cpp\n",
        "./build/bin/llama-quantize /path/to/bamba-model/bamba-model.gguf Q4_K_M\n",
        "Contributors\n",
        "Data collection and curation: We acknowledge and thank AllenAI team for making a high quality open source dataset Dolma as well as Hugging Face data team for making FineWeb-edu and Cosmopedia available. These are tremendous contributions and enable us to create the model today.\n",
        "Data preprocessing: We thank IBM's internal data preprocessing team, specifically Tuan Hoang Trong, Syed Zawad, Jay Gala, and Ryan Gordon for helping tokenize the data at scale. The code for tokenization is available here.\n",
        "Model architecture: The model architecture design was jointly done by Princeton, CMU, IBM, and UIUC and involved the following folks: Tri Dao (Princeton), Albert Gu (CMU), Linsong Chu (IBM), Davis Wertheimer (IBM), Minjia Zhang (UIUC), Mudhakar Srivatsa (IBM), and Raghu Ganti (IBM).\n",
        "Model training: Model training was performed primarily by the IBM team using the Mamba2 kernels and layer implementation from Tri Dao and Albert Gu. The following folks from IBM were primarily involved: Linsong Chu, Divya Kumari, Davis Wertheimer, Raghu Ganti, and Dakshi Agrawal.\n",
        "Model tuning: Tuning of the model was enabled and verified in TRL by the IBM team, involving Sukriti Sharma and Anh Uong.\n",
        "Model inference: Model inference in , , and builds on the kernels written by Princeton and CMU. The IBM team is working with the community to enable it in various ecosystems, the team includes Fabian Lim, Antoni viros i Martin, Adnan Hoque, Jamie Yang, Nelson Nimura Gomez, Joshua Rosenkranz, Nick Hill, and Gabe Goodhart. transformersvLLMllama.cpp\n",
        "Quantization: Quantization is led by the IBM team - Naigang Wang and Charlie Liu.\n",
        "Evaluations: Evaluations are led by a team in IBM with long context evaluations being performed by UIUC, involving the following folks: Yotam Perlitz, Ofir Arviv, Michal Shmueli-Scheuer (IBM), Haoechen Shen, and Minjia Zhang (UIUC).\n",
        "Finally, we would like to thank our leadership for their support in this effort - Priya Nagpurkar, David Cox, Sriram Raghavan, Aya Soffer, and Mukesh Khare.\n",
        "\n",
        "We would also like to thank the community, in particular Pablo Montalvo-Leroux and Vaibhav Srivastav from Hugging Face who provided valuable feedback to this blog and the PRs into transformers. Further, we would like to thank Tyler Michael Smith from Neural Magic, who is shepherding the integration with vLLM.\n",
        "\n",
        "A huge shoutout to Meta PyTorch, AllenAI, and Hugging Face teams for their contributions to the open initative, FSDP allowed us to smoothly train this model and the data from Dolma and Fineweb/Cosmopedia made this model today!"
      ],
      "metadata": {
        "id": "DzF5wvzChX65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch torchvision torchaudio -y"
      ],
      "metadata": {
        "id": "T2bOg3qnUJN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.2.0 torchvision==0.17.0 torchaudio==2.2.0"
      ],
      "metadata": {
        "id": "Wh0-feapUWpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/Dao-AILab/fast-hadamard-transform/releases/download/v1.0.4.post1/fast_hadamard_transform-1.0.4.post1+cu122torch2.2cxx11abiTRUE-cp311-cp311-linux_x86_64.whl"
      ],
      "metadata": {
        "id": "Ue9uao8gUn9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install /content/fast_hadamard_transform-1.0.4.post1+cu122torch2.2cxx11abiTRUE-cp311-cp311-linux_x86_64.whl"
      ],
      "metadata": {
        "id": "xOLjIE1hVEXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Dao-AILab/fast-hadamard-transform.git"
      ],
      "metadata": {
        "id": "Tdr0wA5VU_g0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fast_hadamard_transform import hadamard_transform"
      ],
      "metadata": {
        "id": "1CDJ2T3YUbCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!nvcc --version"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "rgkj8V56V5CV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Uninstall existing PyTorch installations.\n",
        "!pip uninstall torch torchvision torchaudio -y\n",
        "\n",
        "# Install the correct PyTorch version (2.2.0).\n",
        "!pip install torch==2.2.0 torchvision==0.17.0 torchaudio==2.2.0\n",
        "\n",
        "# Reinstall the fast-hadamard-transform library.\n",
        "!pip install /content/fast_hadamard_transform-1.0.4.post1+cu122torch2.2cxx11abiTRUE-cp311-cp311-linux_x86_64.whl"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "tSE2vlJDVQz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install /content/fast_hadamard_transform-1.0.4.post1+cu122torch2.2cxx11abiTRUE-cp311-cp311-linux_x86_64.whl"
      ],
      "metadata": {
        "id": "RO0u4CbqVh-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Dao-AILab/fast-hadamard-transform.git"
      ],
      "metadata": {
        "id": "E1KMSzpWWVNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd fast-hadamard-transform"
      ],
      "metadata": {
        "id": "cRpAJFMqWYX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/fast-hadamard-transform/setup.py setup"
      ],
      "metadata": {
        "id": "BIZ1MKVNWa8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/fast-hadamard-transform/setup.py"
      ],
      "metadata": {
        "id": "bCJcQ2aFWg9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ."
      ],
      "metadata": {
        "id": "_4-_dkbjWoD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fast_hadamard_transform import hadamard_transform"
      ],
      "metadata": {
        "id": "K1Yi16sxWs8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flute-kernel>=0.3.0"
      ],
      "metadata": {
        "id": "D3Vi_KeNXDW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, HiggsConfig\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"openai-community/gpt2\",\n",
        "    quantization_config=HiggsConfig(bits=4),\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
        "\n",
        "tokenizer.decode(model.generate(\n",
        "    **tokenizer(\"Hi,\", return_tensors=\"pt\").to(model.device),\n",
        "    temperature=0.5,\n",
        "    top_p=0.80,\n",
        ")[0])"
      ],
      "metadata": {
        "id": "XQZz-UhLWzb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip uninstall flute-kernel -y\n",
        "!pip install flute-kernel==0.3.0 # or a different version if recommended"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "B1s2_KG_YBbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lnh-hNR2YzSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd fast-hadamard-transform"
      ],
      "metadata": {
        "id": "EZDyk2faYzmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ."
      ],
      "metadata": {
        "id": "3KvDNXkkYzmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "model = AutoModelForCausalLM.from_pretrained(\"ISTA-DASLab/Llama-3.1-8B-HIGGS-3bit\", torch_dtype=torch.float16, device_map=\"auto\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"ISTA-DASLab/Llama-3.1-8B-HIGGS-3bit\")\n",
        "\n",
        "message = [\"Mamba is a snake with following properties  \"]\n",
        "inputs = tokenizer(message, return_tensors='pt', return_token_type_ids=False)\n",
        "response = model.generate(**inputs, max_new_tokens=64)\n",
        "print(tokenizer.batch_decode(response, skip_special_tokens=True)[0])"
      ],
      "metadata": {
        "id": "I0tufcxKYzPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/fast-hadamard-transform/build/lib.linux-x86_64-cpython-311/fast_hadamard_transform/fast_hadamard_transform_interface.py openai-community/gpt2"
      ],
      "metadata": {
        "id": "N5j8xnWcYzLN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/fast-hadamard-transform/build/lib.linux-x86_64-cpython-311/fast_hadamard_transform/fast_hadamard_transform_interface.py --help"
      ],
      "metadata": {
        "id": "jUtT1QP7bWPm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/fast-hadamard-transform/tests/test_fast_hadamard_transform.py"
      ],
      "metadata": {
        "id": "2gSut3CjZyfV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/fast-hadamard-transform/benchmarks/benchmark_fast_hadamard_transform.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqgqNvXKf7fG",
        "outputId": "a8e364ca-6fcf-40a3-f67e-cec7f95df4b3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/fast-hadamard-transform/benchmarks/benchmark_fast_hadamard_transform.py\", line 3, in <module>\n",
            "    from flash_attn.utils.benchmark import benchmark_forward, pytorch_profiler\n",
            "ModuleNotFoundError: No module named 'flash_attn'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fast_hadamard_transform import hadamard_transform"
      ],
      "metadata": {
        "id": "xswmnfoDW5nF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hadamard_transform(x, scale=1.0):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "        x: (..., dim)\n",
        "        scale: float. Multiply the output by this number.\n",
        "    Returns:\n",
        "        out: (..., dim)\n",
        "\n",
        "    Multiply each row of x by the Hadamard transform matrix.\n",
        "    Equivalent to F.linear(x, torch.tensor(scipy.linalg.hadamard(dim))) * scale.\n",
        "    If dim is not a power of 2, we implicitly pad x with zero so that dim is the next power of 2.\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "yh2q8q7RYTzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a pipeline as a high-level helper\n",
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=\"ISTA-DASLab/Llama-3.1-8B-HIGGS-3bit\")"
      ],
      "metadata": {
        "id": "ONwdlKB6ft0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"ISTA-DASLab/Llama-3.1-8B-HIGGS-3bit\",\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=False  # تعطيل الكود البعيد\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"ISTA-DASLab/Llama-3.1-8B-HIGGS-3bit\")\n",
        "\n",
        "message = [\"Mamba is a snake with following properties  \"]\n",
        "inputs = tokenizer(message, return_tensors='pt', return_token_type_ids=False)\n",
        "response = model.generate(**inputs, max_new_tokens=64)\n",
        "print(tokenizer.batch_decode(response, skip_special_tokens=True)[0])\n"
      ],
      "metadata": {
        "id": "k_uND3h2dmEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show transformers\n"
      ],
      "metadata": {
        "id": "mD1pfFB3dmd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "print(dir(transformers.integrations))\n"
      ],
      "metadata": {
        "id": "G6N03Ni1duYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.integrations import higgs\n",
        "print(dir(higgs))\n"
      ],
      "metadata": {
        "id": "UUHPIxNSd1ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers safetensors torch numpy\n"
      ],
      "metadata": {
        "id": "_W3FxzR_d8g3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.integrations import dequantize_higgs, replace_with_higgs_linear\n",
        "print(dequantize_higgs, replace_with_higgs_linear)\n"
      ],
      "metadata": {
        "id": "COB1FqhUeEcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "https://huggingface.co/ibm-ai-platform/Bamba-9B/blob/main/bamba-9b.gguf"
      ],
      "metadata": {
        "id": "IE3gE93DfE5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "higgs = importlib.import_module(\"transformers.integrations.higgs\")\n",
        "print(dir(higgs))\n"
      ],
      "metadata": {
        "id": "De6B-SsbfO7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.integrations import higgs\n",
        "print(dir(higgs))  # Check available functions and attributes\n"
      ],
      "metadata": {
        "id": "4EzHV-MbfPVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qh6fbsMjfVR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/Dao-AILab"
      ],
      "metadata": {
        "id": "h5rppBcyff4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpDm_hcAgJY-",
        "outputId": "f544daf2-97de-4b67-eb0c-74aad91e3bae"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/ibm-ai-platform/Bamba-9B/resolve/main/bamba-9b.gguf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnQqg0HLgG-G",
        "outputId": "56ebd890-b8b1-484b-fe2d-2e4988b2bb76"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-19 00:01:06--  https://huggingface.co/ibm-ai-platform/Bamba-9B/resolve/main/bamba-9b.gguf\n",
            "Resolving huggingface.co (huggingface.co)... 3.165.160.61, 3.165.160.12, 3.165.160.11, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.165.160.61|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/94/d1/94d1d0c4447b2c848c572468cce9539a4d32289c18e1eb13af939cca7a2cbf33/9a4145cf68afe2b15cdc32b6ab5975ef0c2e0bdcb057d71ff7165c2f58a4c8b5?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27bamba-9b.gguf%3B+filename%3D%22bamba-9b.gguf%22%3B&Expires=1739926866&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczOTkyNjg2Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzk0L2QxLzk0ZDFkMGM0NDQ3YjJjODQ4YzU3MjQ2OGNjZTk1MzlhNGQzMjI4OWMxOGUxZWIxM2FmOTM5Y2NhN2EyY2JmMzMvOWE0MTQ1Y2Y2OGFmZTJiMTVjZGMzMmI2YWI1OTc1ZWYwYzJlMGJkY2IwNTdkNzFmZjcxNjVjMmY1OGE0YzhiNT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=nBNYTkCWe5Y%7EyoUpyriHJiUj0er-bD6qexwnkfHwGu1PV7x7u8sNi2pQiJZ7O%7ECjb5NMLm29f8y1n6TNY8SqfRHPDf9-tELDRe39OD1ilyCgCHk3JOsWDQKrPNUMPQZEyJh156nwEGbhx9vevNgcDbXQEjQG1%7E2kjN9aT8cbZP1eEQ7XwDQc0s4xrTdP7wYCaQMzIWOgl05Ce%7E-%7ECiBJSajrZp61B8%7EXqMhHO0VnFzJOTiTJOSA2CWnRSI-rgDYy4%7E5f8wY4vWqjAJd9dp5eVkdWcU9ep-qxEIHRV5U5ptC5lWUEaj55yXw4vcQWo8a25WJCz65CEddpIldhq%7EATHw__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-02-19 00:01:06--  https://cdn-lfs-us-1.hf.co/repos/94/d1/94d1d0c4447b2c848c572468cce9539a4d32289c18e1eb13af939cca7a2cbf33/9a4145cf68afe2b15cdc32b6ab5975ef0c2e0bdcb057d71ff7165c2f58a4c8b5?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27bamba-9b.gguf%3B+filename%3D%22bamba-9b.gguf%22%3B&Expires=1739926866&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczOTkyNjg2Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzk0L2QxLzk0ZDFkMGM0NDQ3YjJjODQ4YzU3MjQ2OGNjZTk1MzlhNGQzMjI4OWMxOGUxZWIxM2FmOTM5Y2NhN2EyY2JmMzMvOWE0MTQ1Y2Y2OGFmZTJiMTVjZGMzMmI2YWI1OTc1ZWYwYzJlMGJkY2IwNTdkNzFmZjcxNjVjMmY1OGE0YzhiNT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=nBNYTkCWe5Y%7EyoUpyriHJiUj0er-bD6qexwnkfHwGu1PV7x7u8sNi2pQiJZ7O%7ECjb5NMLm29f8y1n6TNY8SqfRHPDf9-tELDRe39OD1ilyCgCHk3JOsWDQKrPNUMPQZEyJh156nwEGbhx9vevNgcDbXQEjQG1%7E2kjN9aT8cbZP1eEQ7XwDQc0s4xrTdP7wYCaQMzIWOgl05Ce%7E-%7ECiBJSajrZp61B8%7EXqMhHO0VnFzJOTiTJOSA2CWnRSI-rgDYy4%7E5f8wY4vWqjAJd9dp5eVkdWcU9ep-qxEIHRV5U5ptC5lWUEaj55yXw4vcQWo8a25WJCz65CEddpIldhq%7EATHw__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 3.165.160.20, 3.165.160.3, 3.165.160.38, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|3.165.160.20|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19571792544 (18G) [binary/octet-stream]\n",
            "Saving to: ‘bamba-9b.gguf’\n",
            "\n",
            "bamba-9b.gguf       100%[===================>]  18.23G  39.9MB/s    in 7m 56s  \n",
            "\n",
            "2025-02-19 00:09:02 (39.2 MB/s) - ‘bamba-9b.gguf’ saved [19571792544/19571792544]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gpt4all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9EZjn5ggSGO",
        "outputId": "e566c77c-3c06-4c70-fb35-e623d58ffca3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gpt4all\n",
            "  Downloading gpt4all-2.8.2-py3-none-manylinux1_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from gpt4all) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gpt4all) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->gpt4all) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->gpt4all) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->gpt4all) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->gpt4all) (2025.1.31)\n",
            "Downloading gpt4all-2.8.2-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gpt4all\n",
            "Successfully installed gpt4all-2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://huggingface.co/ibm-ai-platform/Bamba-9B/tree/main"
      ],
      "metadata": {
        "id": "xUUQeT8ig-I_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gpt4all import GPT4All\n",
        "model = GPT4All(\"/content/bamba-9b.gguf\") # downloads / loads a 4.66GB LLM\n",
        "with model.chat_session():\n",
        "    print(model.generate(\"How can I run LLMs efficiently on my laptop?\", max_tokens=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "kyDmwU8NgTE2",
        "outputId": "04135a21-f14e-436c-b1d7-cb941c358a01"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Unable to instantiate model: Unsupported model architecture: bamba",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-825c348d5c15>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgpt4all\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGPT4All\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPT4All\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/bamba-9b.gguf\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# downloads / loads a 4.66GB LLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"How can I run LLMs efficiently on my laptop?\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gpt4all/gpt4all.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name, model_path, model_type, allow_download, n_threads, device, n_ctx, ngl, verbose)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;31m# Retrieve model and download if allowed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConfigType\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLLModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdevice_init\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gpt4all/_pyllmodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_path, n_ctx, ngl, backend)\u001b[0m\n\u001b[1;32m    263\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'WARNING: CUDA runtime libraries not found. Try `pip install \"gpt4all[cuda]\"`\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unable to instantiate model: {errmsg}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Unable to instantiate model: Unsupported model architecture: bamba"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://huggingface.co/ibm-ai-platform/Bamba-9B/blob/main/README.md"
      ],
      "metadata": {
        "id": "3vPTn8D0hNve"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lpL51W3ShOLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"ibm-fms/Bamba-9B\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"ibm-fms/Bamba-9B\")\n",
        "\n",
        "message = [\"Mamba is a snake with following properties  \"]\n",
        "inputs = tokenizer(message, return_tensors='pt', return_token_type_ids=False)\n",
        "response = model.generate(**inputs, max_new_tokens=1)\n",
        "print(tokenizer.batch_decode(response, skip_special_tokens=True)[0])"
      ],
      "metadata": {
        "id": "Ym3XULkWhojW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from mamba_ssm import Mamba\n",
        "\n",
        "batch, length, dim = 2, 64, 16\n",
        "x = torch.randn(batch, length, dim).to(\"cuda\")\n",
        "model = Mamba(\n",
        "    # This module uses roughly 3 * expand * d_model^2 parameters\n",
        "    d_model=dim, # Model dimension d_model\n",
        "    d_state=16,  # SSM state expansion factor\n",
        "    d_conv=4,    # Local convolution width\n",
        "    expand=2,    # Block expansion factor\n",
        ").to(\"cuda\")\n",
        "y = model(x)\n",
        "assert y.shape == x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "k4l4oyeCjIUQ",
        "outputId": "0217d181-e656-47d2-d4f2-e379db81c991"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'mamba_ssm'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e160b7215ca2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmamba_ssm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMamba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mamba_ssm'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Dao-AILab/causal-conv1d.git\n",
        "%cd causal-conv1d && pip install . && cd ..\n",
        "!git clone https://github.com/state-spaces/mamba.git\n",
        "%cd mamba && pip install . && cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GS-B3WfhjItg",
        "outputId": "1eae0ce1-d288-42e4-d208-97632eb1dd89"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'causal-conv1d'...\n",
            "remote: Enumerating objects: 445, done.\u001b[K\n",
            "remote: Counting objects: 100% (139/139), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 445 (delta 118), reused 90 (delta 90), pack-reused 306 (from 2)\u001b[K\n",
            "Receiving objects: 100% (445/445), 107.90 KiB | 8.30 MiB/s, done.\n",
            "Resolving deltas: 100% (221/221), done.\n",
            "[Errno 2] No such file or directory: 'causal-conv1d && pip install . && cd ..'\n",
            "/content\n",
            "Cloning into 'mamba'...\n",
            "remote: Enumerating objects: 715, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 715 (delta 26), reused 18 (delta 18), pack-reused 680 (from 2)\u001b[K\n",
            "Receiving objects: 100% (715/715), 1.55 MiB | 16.04 MiB/s, done.\n",
            "Resolving deltas: 100% (383/383), done.\n",
            "[Errno 2] No such file or directory: 'mamba && pip install . && cd ..'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "twzvRZDBjRIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "#\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"ibm-fms/Bamba-9B\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"ibm-fms/Bamba-9B\")\n",
        "\n",
        "message = \"How can I run LLMs efficiently on my laptop?\"\n",
        "inputs = tokenizer(message, return_tensors=\"pt\")\n",
        "generated_ids = model.generate(**inputs, max_new_tokens=10)\n",
        "generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "\n",
        "print(generated_text)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "ZeA1Ee_8jUBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOxFw8qzjhRQ",
        "outputId": "b1fd66f8-564e-4ea2-90fe-b0caba15ae86"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: torch\n",
            "Version: 2.6.0\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org/\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD-3-Clause\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: filelock, fsspec, jinja2, networkx, nvidia-cublas-cu12, nvidia-cuda-cupti-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-runtime-cu12, nvidia-cudnn-cu12, nvidia-cufft-cu12, nvidia-curand-cu12, nvidia-cusolver-cu12, nvidia-cusparse-cu12, nvidia-cusparselt-cu12, nvidia-nccl-cu12, nvidia-nvjitlink-cu12, nvidia-nvtx-cu12, sympy, triton, typing-extensions\n",
            "Required-by: accelerate, bitsandbytes, compressed-tensors, fast_hadamard_transform, fastai, peft, sentence-transformers, timm, torchaudio, torchvision, vllm, vllm-flash-attn, xformers, xgrammar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torchvision==0.17.0 torchaudio==2.2.0"
      ],
      "metadata": {
        "id": "1MvwhhX6junX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch torchvision torchaudio -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFg0Nc7djkyA",
        "outputId": "04d90fad-d5d6-4581-f211-2307427ba27b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.6.0\n",
            "Uninstalling torch-2.6.0:\n",
            "  Successfully uninstalled torch-2.6.0\n",
            "Found existing installation: torchvision 0.19.0\n",
            "Uninstalling torchvision-0.19.0:\n",
            "  Successfully uninstalled torchvision-0.19.0\n",
            "Found existing installation: torchaudio 2.5.1\n",
            "Uninstalling torchaudio-2.5.1:\n",
            "  Successfully uninstalled torchaudio-2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.0.0 torchvision==0.15.1 torchaudio==2.0.1 --index-url https://download.pytorch.org/whl/cu118"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 985
        },
        "id": "55_KW6_ujxpn",
        "outputId": "a5ae6760-f449-4841-aef2-a1d97e5ed5c3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch==2.0.0\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.0.0%2Bcu118-cp311-cp311-linux_x86_64.whl (2267.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m613.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.15.1\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.15.1%2Bcu118-cp311-cp311-linux_x86_64.whl (6.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.0.1\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.0.1%2Bcu118-cp311-cp311-linux_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (3.1.5)\n",
            "Collecting triton==2.0.0 (from torch==2.0.0)\n",
            "  Downloading https://download.pytorch.org/whl/triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.1) (2.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.1) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.1) (11.1.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.0) (3.31.4)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.0)\n",
            "  Downloading https://download.pytorch.org/whl/lit-15.0.7.tar.gz (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.1) (2025.1.31)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.0) (1.3.0)\n",
            "Building wheels for collected packages: lit\n",
            "  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-15.0.7-py3-none-any.whl size=89991 sha256=0e6214899cf895e67d32d12c11746bbb5dbde237328727f099a3236ce0691b46\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/5d/45/34fe9945d5e45e261134e72284395be36c2d4828af38e2b0fe\n",
            "Successfully built lit\n",
            "Installing collected packages: lit, triton, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "vllm-flash-attn 2.6.1 requires torch==2.4.0, but you have torch 2.0.0+cu118 which is incompatible.\n",
            "vllm 0.5.4 requires numpy<2.0.0, but you have numpy 2.2.3 which is incompatible.\n",
            "vllm 0.5.4 requires torch==2.4.0, but you have torch 2.0.0+cu118 which is incompatible.\n",
            "vllm 0.5.4 requires torchvision==0.19, but you have torchvision 0.15.1+cu118 which is incompatible.\n",
            "xformers 0.0.27.post2 requires torch==2.4.0, but you have torch 2.0.0+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-15.0.7 torch-2.0.0+cu118 torchaudio-2.0.1+cu118 torchvision-0.15.1+cu118 triton-2.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen"
                ]
              },
              "id": "11ab0fa2e1bc4622ac934272326647be"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install causal-conv1d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIjkMZRwkF5g",
        "outputId": "d07ba7b8-4cce-480f-adf5-bb0b310a03d8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting causal-conv1d\n",
            "  Using cached causal_conv1d-1.5.0.post8.tar.gz (9.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from causal-conv1d) (2.0.0+cu118)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from causal-conv1d) (24.2)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from causal-conv1d) (1.11.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->causal-conv1d) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch->causal-conv1d) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->causal-conv1d) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->causal-conv1d) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->causal-conv1d) (3.1.5)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch->causal-conv1d) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch->causal-conv1d) (3.31.4)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch->causal-conv1d) (15.0.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->causal-conv1d) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->causal-conv1d) (1.3.0)\n",
            "Building wheels for collected packages: causal-conv1d\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for causal-conv1d (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for causal-conv1d\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for causal-conv1d\n",
            "Failed to build causal-conv1d\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (causal-conv1d)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mamba-ssm[causal-conv1d]"
      ],
      "metadata": {
        "id": "eS-6BGmhko0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from mamba_ssm import Mamba"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "njmRL0C9kwXA",
        "outputId": "596089e7-3ca2-40dd-952c-bb1b9c16e995"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'mamba_ssm'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9f5a5b3b7567>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmamba_ssm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMamba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mamba_ssm'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from mamba_ssm import Mamba\n",
        "\n",
        "batch, length, dim = 2, 64, 16\n",
        "x = torch.randn(batch, length, dim).to(\"cuda\")\n",
        "model = Mamba(\n",
        "    # This module uses roughly 3 * expand * d_model^2 parameters\n",
        "    d_model=dim, # Model dimension d_model\n",
        "    d_state=16,  # SSM state expansion factor\n",
        "    d_conv=4,    # Local convolution width\n",
        "    expand=2,    # Block expansion factor\n",
        ").to(\"cuda\")\n",
        "y = model(x)\n",
        "assert y.shape == x.shape"
      ],
      "metadata": {
        "id": "sRN8jLDSkvC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/ggml-org/llama.cpp/releases/download/b4739/llama-b4739-bin-ubuntu-x64.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIG_GS9ulj1o",
        "outputId": "58fe91b7-9864-454a-a2ae-39296445d026"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-19 00:23:15--  https://github.com/ggml-org/llama.cpp/releases/download/b4739/llama-b4739-bin-ubuntu-x64.zip\n",
            "Resolving github.com (github.com)... 140.82.116.3\n",
            "Connecting to github.com (github.com)|140.82.116.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/612354784/dc0a4ab7-8426-44fc-9dad-e5fc5dc8aaf4?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250219%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250219T002315Z&X-Amz-Expires=300&X-Amz-Signature=adae9ba48226c3a65f90e18b805f0f9b1918972fbe251cbbd9cc07fae7883c95&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dllama-b4739-bin-ubuntu-x64.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-02-19 00:23:15--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/612354784/dc0a4ab7-8426-44fc-9dad-e5fc5dc8aaf4?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250219%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250219T002315Z&X-Amz-Expires=300&X-Amz-Signature=adae9ba48226c3a65f90e18b805f0f9b1918972fbe251cbbd9cc07fae7883c95&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dllama-b4739-bin-ubuntu-x64.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28141998 (27M) [application/octet-stream]\n",
            "Saving to: ‘llama-b4739-bin-ubuntu-x64.zip’\n",
            "\n",
            "llama-b4739-bin-ubu 100%[===================>]  26.84M  51.8MB/s    in 0.5s    \n",
            "\n",
            "2025-02-19 00:23:16 (51.8 MB/s) - ‘llama-b4739-bin-ubuntu-x64.zip’ saved [28141998/28141998]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip llama-b4739-bin-ubuntu-x64.zip"
      ],
      "metadata": {
        "id": "nvdn68sAlmGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/build/bin/llama-cli -m /content/bamba-9b.gguf -p \"hi\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxbA-7EhmEYR",
        "outputId": "f7ccf57b-095e-475d-b575-8b8a3559e95c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/build/bin/llama-cli: error while loading shared libraries: libllama.so: cannot open shared object file: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/build/bin/llama-cli -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prjEKdTvmLko",
        "outputId": "101e23c0-93ac-4276-cbd1-0d968a4ce53e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/build/bin/llama-cli: error while loading shared libraries: libllama.so: cannot open shared object file: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/content/llama.cpp/build/Release"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "9wcA3jjpmmbj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/build/bin/test-log"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcUX-swEmPUZ",
        "outputId": "c78d4262-4506-46f9-e40e-bcd506bc017c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Thread 6: 418\n",
            "Thread 6: 419\n",
            "0.00.001.765 E Thread 6: 420\n",
            "Thread 6: 421\n",
            "Thread 6: 422\n",
            "Thread 6: 423\n",
            "W Thread 6: 424\n",
            "I Thread 6: 425\n",
            "Thread 6: 429\n",
            "0.00.001.769 I Thread 6: 432\n",
            "0.00.001.769 E Thread 6: 433\n",
            "Thread 6: 434\n",
            "E Thread 6: 435\n",
            "Thread 6: 437\n",
            "Thread 6: 438\n",
            "Thread 6: 439\n",
            "0.00.001.773 E Thread 6: 440\n",
            "0.00.001.773 I Thread 6: 441\n",
            "0.00.001.774 W Thread 6: 442\n",
            "E Thread 6: 443\n",
            "0.00.001.775 W Thread 6: 445\n",
            "0.00.001.775 W Thread 6: 446\n",
            "Thread 6: 448\n",
            "W Thread 6: 450\n",
            "0.00.001.777 W Thread 6: 453\n",
            "Thread 6: 454\n",
            "0.00.001.779 E Thread 6: 455\n",
            "0.00.001.779 E Thread 6: 457\n",
            "0.00.001.780 W Thread 6: 458\n",
            "0.00.001.780 I Thread 6: 459\n",
            "Thread 6: 461\n",
            "Thread 6: 462\n",
            "Thread 6: 463\n",
            "Thread 6: 464\n",
            "Thread 6: 465\n",
            "Thread 6: 467\n",
            "Thread 6: 472\n",
            "Thread 6: 473\n",
            "0.00.001.785 E Thread 6: 474\n",
            "Thread 6: 475\n",
            "W Thread 6: 477\n",
            "W Thread 6: 478\n",
            "Thread 6: 479\n",
            "Thread 6: 480\n",
            "0.00.001.789 I Thread 6: 481\n",
            "Thread 6: 482\n",
            "Thread 6: 483\n",
            "I Thread 6: 485\n",
            "E Thread 6: 486\n",
            "W Thread 6: 487\n",
            "W Thread 6: 489\n",
            "W Thread 6: 490\n",
            "I Thread 6: 491\n",
            "0.00.001.793 E Thread 6: 492\n",
            "Thread 6: 494\n",
            "Thread 6: 495\n",
            "W Thread 6: 496\n",
            "E Thread 6: 497\n",
            "I Thread 6: 498\n",
            "0.00.001.797 I Thread 6: 500\n",
            "0.00.001.797 E Thread 6: 501\n",
            "0.00.001.798 E Thread 6: 502\n",
            "0.00.001.798 I Thread 6: 503\n",
            "0.00.001.799 W Thread 6: 506\n",
            "0.00.001.799 E Thread 6: 508\n",
            "0.00.001.800 E Thread 6: 510\n",
            "0.00.001.801 I Thread 6: 511\n",
            "0.00.001.801 E Thread 6: 512\n",
            "0.00.001.802 I Thread 6: 513\n",
            "Thread 6: 514\n",
            "Thread 6: 515\n",
            "Thread 6: 516\n",
            "Thread 6: 517\n",
            "Thread 6: 518\n",
            "Thread 6: 519\n",
            "Thread 6: 520\n",
            "W Thread 6: 521\n",
            "Thread 6: 523\n",
            "Thread 6: 524\n",
            "Thread 6: 525\n",
            "Thread 6: 526\n",
            "Thread 6: 529\n",
            "E Thread 6: 530\n",
            "E Thread 6: 531\n",
            "Thread 6: 532\n",
            "Thread 6: 533\n",
            "Thread 6: 534\n",
            "Thread 6: 536\n",
            "Thread 6: 537\n",
            "E Thread 6: 540\n",
            "W Thread 6: 541\n",
            "I Thread 6: 542\n",
            "Thread 6: 543\n",
            "Thread 6: 545\n",
            "Thread 6: 547\n",
            "Thread 6: 548\n",
            "Thread 6: 550\n",
            "Thread 6: 552\n",
            "Thread 6: 554\n",
            "Thread 6: 555\n",
            "Thread 6: 556\n",
            "W Thread 6: 557\n",
            "Thread 6: 560\n",
            "E Thread 6: 561\n",
            "I Thread 6: 562\n",
            "I Thread 6: 563\n",
            "W Thread 6: 565\n",
            "0.00.001.824 E Thread 6: 568\n",
            "W Thread 6: 569\n",
            "I Thread 6: 571\n",
            "0.00.001.826 W Thread 6: 573\n",
            "0.00.001.826 W Thread 6: 575\n",
            "E Thread 6: 577\n",
            "I Thread 6: 579\n",
            "I Thread 6: 580\n",
            "I Thread 6: 581\n",
            "W Thread 6: 582\n",
            "0.00.001.830 I Thread 6: 583\n",
            "Thread 6: 584\n",
            "Thread 6: 586\n",
            "Thread 6: 587\n",
            "Thread 6: 588\n",
            "Thread 6: 589\n",
            "Thread 6: 590\n",
            "Thread 6: 591\n",
            "I Thread 6: 592\n",
            "E Thread 6: 593\n",
            "E Thread 6: 594\n",
            "I Thread 6: 596\n",
            "I Thread 6: 597\n",
            "Thread 6: 601\n",
            "Thread 6: 602\n",
            "E Thread 6: 604\n",
            "I Thread 6: 605\n",
            "W Thread 6: 606\n",
            "W Thread 6: 607\n",
            "0.00.001.840 W Thread 6: 609\n",
            "Thread 6: 611\n",
            "Thread 6: 612\n",
            "Thread 6: 614\n",
            "Thread 6: 615\n",
            "Thread 6: 616\n",
            "Thread 6: 618\n",
            "Thread 6: 619\n",
            "E Thread 6: 620\n",
            "I Thread 6: 621\n",
            "0.00.001.845 W Thread 6: 623\n",
            "Thread 6: 625\n",
            "Thread 6: 626\n",
            "Thread 6: 627\n",
            "I Thread 6: 628\n",
            "Thread 6: 629\n",
            "Thread 6: 633\n",
            "Thread 6: 634\n",
            "Thread 6: 635\n",
            "Thread 6: 636\n",
            "Thread 6: 637\n",
            "E Thread 6: 640\n",
            "I Thread 6: 643\n",
            "0.00.001.852 W Thread 6: 644\n",
            "0.00.001.853 E Thread 6: 645\n",
            "Thread 6: 646\n",
            "Thread 6: 647\n",
            "Thread 6: 648\n",
            "Thread 6: 650\n",
            "Thread 6: 652\n",
            "I Thread 6: 653\n",
            "I Thread 6: 654\n",
            "Thread 6: 655\n",
            "Thread 6: 656\n",
            "Thread 6: 658\n",
            "W Thread 6: 660\n",
            "Thread 6: 661\n",
            "Thread 6: 662\n",
            "0.00.001.861 I Thread 6: 665\n",
            "0.00.001.862 W Thread 6: 666\n",
            "0.00.001.862 W Thread 6: 667\n",
            "Thread 6: 668\n",
            "Thread 6: 669\n",
            "Thread 6: 670\n",
            "Thread 6: 671\n",
            "0.00.001.865 W Thread 6: 673\n",
            "0.00.001.865 I Thread 6: 674\n",
            "0.00.001.866 E Thread 6: 675\n",
            "Thread 6: 677\n",
            "Thread 6: 678\n",
            "Thread 6: 680\n",
            "Thread 6: 681\n",
            "Thread 6: 683\n",
            "Thread 6: 684\n",
            "Thread 6: 685\n",
            "Thread 6: 687\n",
            "Thread 6: 688\n",
            "Thread 6: 689\n",
            "Thread 6: 690\n",
            "Thread 6: 691\n",
            "Thread 6: 692\n",
            "Thread 6: 694\n",
            "W Thread 6: 695\n",
            "Thread 6: 697\n",
            "Thread 6: 698\n",
            "0.00.001.876 W Thread 6: 699\n",
            "0.00.001.876 W Thread 6: 700\n",
            "0.00.001.877 I Thread 6: 701\n",
            "0.00.001.877 I Thread 6: 702\n",
            "0.00.001.878 W Thread 6: 703\n",
            "0.00.001.879 E Thread 6: 705\n",
            "Thread 6: 709\n",
            "0.00.001.880 I Thread 6: 711\n",
            "Thread 6: 712\n",
            "Thread 6: 713\n",
            "Thread 6: 714\n",
            "Thread 6: 716\n",
            "Thread 6: 717\n",
            "Thread 6: 718\n",
            "Thread 6: 719\n",
            "Thread 6: 720\n",
            "I Thread 6: 721\n",
            "I Thread 6: 722\n",
            "I Thread 6: 723\n",
            "W Thread 6: 724\n",
            "Thread 6: 725\n",
            "Thread 6: 727\n",
            "Thread 6: 728\n",
            "Thread 6: 729\n",
            "0.00.001.889 E Thread 6: 731\n",
            "Thread 6: 733\n",
            "Thread 6: 734\n",
            "Thread 6: 735\n",
            "0.00.001.891 E Thread 6: 736\n",
            "W Thread 6: 737\n",
            "E Thread 6: 738\n",
            "I Thread 6: 739\n",
            "I Thread 6: 740\n",
            "0.00.001.894 I Thread 6: 742\n",
            "0.00.001.894 I Thread 6: 743\n",
            "W Thread 6: 745\n",
            "Thread 6: 746\n",
            "0.00.001.896 E Thread 6: 748\n",
            "Thread 6: 749\n",
            "Thread 6: 751\n",
            "Thread 6: 752\n",
            "Thread 6: 753\n",
            "I Thread 6: 754\n",
            "E Thread 6: 755\n",
            "I Thread 6: 756\n",
            "W Thread 6: 759\n",
            "0.00.001.901 E Thread 6: 761\n",
            "0.00.001.902 E Thread 6: 762\n",
            "W Thread 6: 764\n",
            "Thread 6: 765\n",
            "Thread 6: 766\n",
            "Thread 6: 767\n",
            "Thread 6: 768\n",
            "Thread 6: 769\n",
            "Thread 6: 770\n",
            "Thread 6: 771\n",
            "E Thread 6: 772\n",
            "I Thread 6: 773\n",
            "E Thread 6: 775\n",
            "I Thread 6: 776\n",
            "W Thread 6: 777\n",
            "0.00.001.909 E Thread 6: 779\n",
            "0.00.001.909 E Thread 6: 781\n",
            "Thread 6: 782\n",
            "Thread 6: 783\n",
            "Thread 6: 784\n",
            "Thread 6: 785\n",
            "Thread 6: 786\n",
            "0.00.001.913 E Thread 6: 788\n",
            "Thread 6: 790\n",
            "Thread 6: 792\n",
            "Thread 6: 793\n",
            "Thread 6: 794\n",
            "Thread 6: 795\n",
            "0.00.001.917 E Thread 6: 797\n",
            "0.00.001.917 I Thread 6: 798\n",
            "0.00.001.918 I Thread 6: 799\n",
            "0.00.001.918 I Thread 6: 800\n",
            "Thread 6: 803\n",
            "Thread 6: 804\n",
            "Thread 6: 805\n",
            "Thread 6: 806\n",
            "I Thread 6: 807\n",
            "I Thread 6: 809\n",
            "Thread 6: 810\n",
            "Thread 6: 811\n",
            "Thread 6: 812\n",
            "Thread 6: 813\n",
            "I Thread 6: 817\n",
            "E Thread 6: 818\n",
            "I Thread 6: 819\n",
            "I Thread 6: 820\n",
            "I Thread 6: 821\n",
            "0.00.001.926 I Thread 6: 823\n",
            "Thread 6: 824\n",
            "Thread 6: 825\n",
            "Thread 6: 826\n",
            "Thread 6: 828\n",
            "Thread 6: 829\n",
            "Thread 6: 830\n",
            "Thread 6: 831\n",
            "Thread 6: 832\n",
            "Thread 6: 833\n",
            "Thread 6: 834\n",
            "0.00.001.932 E Thread 6: 835\n",
            "0.00.001.933 E Thread 6: 836\n",
            "0.00.001.933 W Thread 6: 837\n",
            "0.00.001.934 E Thread 6: 838\n",
            "0.00.001.934 I Thread 6: 839\n",
            "0.00.001.935 E Thread 6: 840\n",
            "Thread 6: 842\n",
            "W Thread 6: 844\n",
            "W Thread 6: 845\n",
            "Thread 6: 846\n",
            "0.00.001.938 E Thread 6: 847\n",
            "0.00.001.938 I Thread 6: 848\n",
            "0.00.001.939 E Thread 6: 849\n",
            "0.00.001.939 W Thread 6: 850\n",
            "W Thread 6: 851\n",
            "Thread 6: 853\n",
            "Thread 6: 856\n",
            "Thread 6: 857\n",
            "Thread 6: 858\n",
            "Thread 6: 859\n",
            "Thread 6: 860\n",
            "Thread 6: 861\n",
            "Thread 6: 863\n",
            "Thread 6: 864\n",
            "Thread 6: 865\n",
            "Thread 6: 866\n",
            "Thread 6: 867\n",
            "Thread 6: 870\n",
            "Thread 6: 871\n",
            "I Thread 6: 873\n",
            "0.00.001.949 E Thread 6: 874\n",
            "0.00.001.949 I Thread 6: 875\n",
            "Thread 6: 878\n",
            "Thread 6: 879\n",
            "E Thread 6: 880\n",
            "Thread 6: 881\n",
            "Thread 6: 882\n",
            "I Thread 6: 883\n",
            "Thread 6: 884\n",
            "W Thread 6: 886\n",
            "Thread 6: 887\n",
            "E Thread 6: 888\n",
            "I Thread 6: 889\n",
            "E Thread 6: 890\n",
            "W Thread 6: 891\n",
            "Thread 6: 892\n",
            "Thread 6: 893\n",
            "Thread 6: 894\n",
            "Thread 6: 896\n",
            "Thread 6: 897\n",
            "I Thread 6: 899\n",
            "W Thread 6: 900\n",
            "0.00.001.961 I Thread 6: 901\n",
            "0.00.001.962 W Thread 6: 902\n",
            "Thread 6: 903\n",
            "Thread 6: 904\n",
            "Thread 6: 906\n",
            "Thread 6: 907\n",
            "Thread 6: 908\n",
            "Thread 6: 909\n",
            "0.00.001.965 W Thread 6: 910\n",
            "Thread 6: 913\n",
            "0.00.001.967 W Thread 6: 914\n",
            "0.00.001.967 I Thread 6: 915\n",
            "0.00.001.968 I Thread 6: 916\n",
            "E Thread 6: 917\n",
            "Thread 6: 920\n",
            "Thread 6: 921\n",
            "E Thread 6: 927\n",
            "Thread 6: 932\n",
            "W Thread 6: 933\n",
            "I Thread 6: 934\n",
            "I Thread 6: 935\n",
            "Thread 6: 937\n",
            "0.00.001.975 W Thread 6: 940\n",
            "0.00.001.975 I Thread 6: 941\n",
            "0.00.001.976 I Thread 6: 942\n",
            "W Thread 6: 943\n",
            "I Thread 6: 944\n",
            "Thread 6: 945\n",
            "Thread 6: 948\n",
            "0.00.001.979 W Thread 6: 949\n",
            "Thread 6: 950\n",
            "Thread 6: 951\n",
            "Thread 6: 952\n",
            "0.00.001.981 E Thread 6: 953\n",
            "0.00.001.981 W Thread 6: 954\n",
            "Thread 6: 955\n",
            "Thread 6: 956\n",
            "0.00.001.983 I Thread 6: 957\n",
            "E Thread 6: 958\n",
            "0.00.001.984 E Thread 6: 959\n",
            "Thread 6: 961\n",
            "Thread 6: 962\n",
            "Thread 6: 963\n",
            "Thread 6: 965\n",
            "Thread 6: 966\n",
            "Thread 6: 967\n",
            "E Thread 6: 968\n",
            "W Thread 6: 969\n",
            "E Thread 6: 970\n",
            "E Thread 6: 972\n",
            "Thread 6: 973\n",
            "I Thread 6: 974\n",
            "Thread 6: 975\n",
            "Thread 6: 976\n",
            "0.00.002.000 I Thread 6: 978\n",
            "E Thread 6: 979\n",
            "W Thread 6: 980\n",
            "W Thread 6: 981\n",
            "W Thread 6: 982\n",
            "E Thread 6: 984\n",
            "Thread 6: 986\n",
            "E Thread 6: 987\n",
            "E Thread 6: 989\n",
            "I Thread 6: 991\n",
            "I Thread 6: 992\n",
            "0.00.002.006 W Thread 6: 993\n",
            "I Thread 6: 995\n",
            "E Thread 6: 999\n",
            "Thread 5: 0\n",
            "Thread 5: 1\n",
            "Thread 5: 2\n",
            "Thread 5: 4\n",
            "0.00.002.038 E Thread 5: 5\n",
            "0.00.002.039 E Thread 5: 7\n",
            "Thread 5: 8\n",
            "0.00.002.040 I Thread 5: 9\n",
            "0.00.002.040 W Thread 5: 10\n",
            "E Thread 5: 11\n",
            "E Thread 5: 12\n",
            "I Thread 5: 14\n",
            "E Thread 5: 15\n",
            "0.00.002.043 W Thread 5: 16\n",
            "E Thread 5: 18\n",
            "W Thread 5: 19\n",
            "I Thread 5: 20\n",
            "0.00.002.046 W Thread 5: 23\n",
            "Thread 5: 24\n",
            "Thread 5: 25\n",
            "Thread 5: 26\n",
            "Thread 5: 28\n",
            "Thread 5: 29\n",
            "0.00.002.050 E Thread 5: 31\n",
            "0.00.002.050 I Thread 5: 32\n",
            "E Thread 5: 33\n",
            "Thread 5: 34\n",
            "W Thread 5: 36\n",
            "0.00.002.053 I Thread 5: 41\n",
            "E Thread 5: 42\n",
            "W Thread 5: 43\n",
            "Thread 5: 44\n",
            "Thread 5: 45\n",
            "Thread 5: 46\n",
            "Thread 5: 49\n",
            "Thread 5: 50\n",
            "0.00.002.058 I Thread 5: 52\n",
            "0.00.002.058 W Thread 5: 53\n",
            "0.00.002.059 E Thread 5: 54\n",
            "0.00.002.059 I Thread 5: 55\n",
            "W Thread 5: 56\n",
            "W Thread 5: 57\n",
            "Thread 5: 58\n",
            "Thread 5: 60\n",
            "Thread 5: 61\n",
            "Thread 5: 62\n",
            "Thread 5: 63\n",
            "I Thread 5: 64\n",
            "0.00.002.064 E Thread 5: 65\n",
            "Thread 5: 66\n",
            "Thread 5: 67\n",
            "Thread 5: 68\n",
            "Thread 5: 69\n",
            "Thread 5: 70\n",
            "Thread 5: 71\n",
            "Thread 5: 72\n",
            "W Thread 5: 73\n",
            "E Thread 5: 74\n",
            "E Thread 5: 75\n",
            "I Thread 5: 76\n",
            "Thread 5: 77\n",
            "0.00.002.071 I Thread 5: 78\n",
            "0.00.002.072 W Thread 5: 79\n",
            "0.00.002.072 W Thread 5: 80\n",
            "W Thread 5: 81\n",
            "E Thread 5: 82\n",
            "Thread 5: 84\n",
            "Thread 5: 85\n",
            "Thread 5: 86\n",
            "0.00.002.076 I Thread 5: 87\n",
            "Thread 5: 91\n",
            "Thread 5: 92\n",
            "0.00.002.078 I Thread 5: 93\n",
            "0.00.002.078 W Thread 5: 94\n",
            "0.00.002.079 E Thread 5: 95\n",
            "0.00.002.079 W Thread 5: 96\n",
            "0.00.002.080 E Thread 5: 97\n",
            "Thread 5: 98\n",
            "Thread 5: 99\n",
            "0.00.002.081 E Thread 5: 101\n",
            "Thread 5: 102\n",
            "Thread 5: 103\n",
            "Thread 5: 105\n",
            "Thread 5: 107\n",
            "Thread 5: 108\n",
            "Thread 5: 109\n",
            "W Thread 5: 110\n",
            "W Thread 5: 111\n",
            "W Thread 5: 112\n",
            "Thread 5: 114\n",
            "Thread 5: 115\n",
            "Thread 5: 116\n",
            "Thread 5: 118\n",
            "Thread 5: 119\n",
            "W Thread 5: 120\n",
            "E Thread 5: 121\n",
            "W Thread 5: 123\n",
            "I Thread 5: 124\n",
            "W Thread 5: 125\n",
            "Thread 5: 127\n",
            "E Thread 5: 129\n",
            "Thread 5: 130\n",
            "0.00.002.095 W Thread 5: 131\n",
            "Thread 5: 133\n",
            "Thread 5: 134\n",
            "Thread 5: 135\n",
            "I Thread 5: 137\n",
            "W Thread 5: 138\n",
            "W Thread 5: 139\n",
            "E Thread 5: 140\n",
            "Thread 5: 141\n",
            "Thread 5: 144\n",
            "Thread 5: 145\n",
            "Thread 5: 146\n",
            "Thread 5: 147\n",
            "Thread 5: 149\n",
            "Thread 5: 150\n",
            "Thread 5: 151\n",
            "Thread 5: 152\n",
            "Thread 5: 153\n",
            "Thread 5: 155\n",
            "Thread 5: 156\n",
            "Thread 5: 157\n",
            "Thread 5: 158\n",
            "Thread 5: 159\n",
            "E Thread 5: 160\n",
            "0.00.002.108 W Thread 5: 161\n",
            "E Thread 5: 162\n",
            "Thread 5: 165\n",
            "Thread 5: 166\n",
            "W Thread 5: 167\n",
            "E Thread 5: 168\n",
            "Thread 5: 170\n",
            "Thread 5: 171\n",
            "Thread 5: 174\n",
            "Thread 5: 175\n",
            "Thread 5: 176\n",
            "Thread 5: 177\n",
            "I Thread 5: 178\n",
            "I Thread 5: 179\n",
            "0.00.002.117 E Thread 5: 182\n",
            "0.00.002.117 W Thread 5: 183\n",
            "0.00.002.118 E Thread 5: 184\n",
            "0.00.002.118 W Thread 5: 186\n",
            "0.00.002.119 I Thread 5: 187\n",
            "I Thread 5: 188\n",
            "I Thread 5: 190\n",
            "E Thread 5: 191\n",
            "Thread 5: 192\n",
            "Thread 5: 193\n",
            "Thread 5: 194\n",
            "Thread 5: 195\n",
            "Thread 5: 196\n",
            "Thread 5: 197\n",
            "Thread 5: 198\n",
            "Thread 5: 199\n",
            "E Thread 5: 201\n",
            "0.00.002.125 E Thread 5: 202\n",
            "0.00.002.126 E Thread 5: 203\n",
            "Thread 5: 206\n",
            "Thread 5: 207\n",
            "Thread 5: 208\n",
            "I Thread 5: 210\n",
            "0.00.002.146 E Thread 5: 212\n",
            "0.00.002.147 W Thread 5: 213\n",
            "0.00.002.147 W Thread 5: 214\n",
            "Thread 5: 215\n",
            "Thread 5: 216\n",
            "Thread 5: 217\n",
            "Thread 5: 218\n",
            "Thread 5: 219\n",
            "Thread 5: 221\n",
            "Thread 5: 222\n",
            "Thread 5: 223\n",
            "Thread 5: 224\n",
            "Thread 5: 225\n",
            "I Thread 5: 226\n",
            "E Thread 5: 227\n",
            "0.00.002.153 W Thread 5: 228\n",
            "0.00.002.154 I Thread 5: 230\n",
            "0.00.002.154 E Thread 5: 231\n",
            "0.00.002.155 I Thread 5: 232\n",
            "0.00.002.155 W Thread 5: 233\n",
            "0.00.002.156 I Thread 5: 234\n",
            "0.00.002.156 E Thread 5: 235\n",
            "0.00.002.157 I Thread 5: 236\n",
            "I Thread 5: 237\n",
            "Thread 5: 238\n",
            "Thread 5: 239\n",
            "Thread 5: 240\n",
            "Thread 5: 242\n",
            "Thread 5: 243\n",
            "Thread 5: 244\n",
            "Thread 5: 245\n",
            "Thread 5: 246\n",
            "Thread 5: 247\n",
            "Thread 5: 248\n",
            "Thread 5: 249\n",
            "Thread 5: 250\n",
            "Thread 5: 251\n",
            "0.00.002.164 I Thread 5: 253\n",
            "W Thread 5: 254\n",
            "I Thread 5: 255\n",
            "Thread 5: 257\n",
            "0.00.002.167 W Thread 5: 259\n",
            "0.00.002.167 W Thread 5: 260\n",
            "0.00.002.168 E Thread 5: 261\n",
            "0.00.002.168 W Thread 5: 262\n",
            "Thread 5: 263\n",
            "Thread 5: 265\n",
            "Thread 5: 266\n",
            "Thread 5: 267\n",
            "Thread 5: 268\n",
            "Thread 5: 269\n",
            "Thread 5: 270\n",
            "Thread 5: 271\n",
            "Thread 5: 272\n",
            "Thread 5: 273\n",
            "Thread 5: 274\n",
            "Thread 5: 275\n",
            "Thread 5: 277\n",
            "0.00.002.176 E Thread 5: 281\n",
            "Thread 5: 283\n",
            "Thread 5: 284\n",
            "Thread 5: 285\n",
            "Thread 5: 286\n",
            "Thread 5: 287\n",
            "Thread 5: 288\n",
            "0.00.002.180 E Thread 5: 289\n",
            "E Thread 5: 291\n",
            "Thread 5: 293\n",
            "Thread 5: 294\n",
            "0.00.002.182 W Thread 5: 295\n",
            "0.00.002.183 E Thread 5: 296\n",
            "0.00.002.183 W Thread 5: 297\n",
            "0.00.002.184 W Thread 5: 298\n",
            "Thread 5: 299\n",
            "Thread 5: 301\n",
            "Thread 5: 302\n",
            "Thread 5: 304\n",
            "Thread 5: 305\n",
            "I Thread 5: 307\n",
            "Thread 5: 308\n",
            "0.00.002.189 I Thread 5: 309\n",
            "Thread 5: 310\n",
            "Thread 5: 311\n",
            "E Thread 5: 312\n",
            "W Thread 5: 313\n",
            "E Thread 5: 314\n",
            "I Thread 5: 315\n",
            "Thread 5: 316\n",
            "Thread 5: 317\n",
            "0.00.002.194 W Thread 5: 320\n",
            "Thread 5: 321\n",
            "Thread 5: 324\n",
            "Thread 5: 325\n",
            "Thread 5: 326\n",
            "0.00.002.197 W Thread 5: 327\n",
            "Thread 5: 328\n",
            "Thread 5: 329\n",
            "W Thread 5: 330\n",
            "E Thread 5: 331\n",
            "E Thread 5: 332\n",
            "Thread 5: 334\n",
            "0.00.002.201 W Thread 5: 335\n",
            "0.00.002.201 I Thread 5: 336\n",
            "0.00.002.202 I Thread 5: 337\n",
            "0.00.002.202 E Thread 5: 338\n",
            "W Thread 5: 340\n",
            "W Thread 5: 341\n",
            "I Thread 5: 342\n",
            "W Thread 5: 343\n",
            "0.00.002.205 I Thread 5: 344\n",
            "0.00.002.205 E Thread 5: 345\n",
            "0.00.002.206 I Thread 5: 346\n",
            "I Thread 5: 349\n",
            "W Thread 5: 351\n",
            "Thread 5: 352\n",
            "0.00.002.208 E Thread 5: 354\n",
            "Thread 5: 355\n",
            "Thread 5: 356\n",
            "Thread 5: 357\n",
            "Thread 5: 358\n",
            "Thread 5: 359\n",
            "Thread 5: 361\n",
            "Thread 5: 362\n",
            "Thread 5: 363\n",
            "Thread 5: 364\n",
            "Thread 5: 365\n",
            "Thread 5: 366\n",
            "Thread 5: 367\n",
            "Thread 5: 368\n",
            "Thread 5: 369\n",
            "W Thread 5: 370\n",
            "Thread 5: 372\n",
            "Thread 5: 373\n",
            "Thread 5: 374\n",
            "Thread 5: 375\n",
            "Thread 5: 377\n",
            "Thread 5: 378\n",
            "Thread 5: 379\n",
            "Thread 5: 381\n",
            "Thread 5: 382\n",
            "Thread 5: 383\n",
            "Thread 5: 384\n",
            "I Thread 5: 385\n",
            "0.00.002.223 I Thread 5: 387\n",
            "Thread 5: 388\n",
            "Thread 5: 389\n",
            "Thread 5: 390\n",
            "Thread 5: 391\n",
            "Thread 5: 393\n",
            "W Thread 5: 395\n",
            "W Thread 5: 397\n",
            "W Thread 5: 398\n",
            "0.00.002.228 W Thread 5: 401\n",
            "Thread 5: 403\n",
            "0.00.002.230 E Thread 5: 404\n",
            "E Thread 5: 405\n",
            "Thread 5: 408\n",
            "Thread 5: 409\n",
            "I Thread 5: 411\n",
            "E Thread 5: 414\n",
            "Thread 5: 416\n",
            "Thread 5: 417\n",
            "E Thread 5: 418\n",
            "I Thread 5: 419\n",
            "W Thread 5: 420\n",
            "W Thread 5: 422\n",
            "E Thread 5: 423\n",
            "Thread 5: 424\n",
            "Thread 5: 425\n",
            "Thread 5: 426\n",
            "Thread 5: 427\n",
            "W Thread 5: 429\n",
            "Thread 5: 430\n",
            "Thread 5: 431\n",
            "Thread 5: 432\n",
            "Thread 5: 433\n",
            "Thread 5: 434\n",
            "Thread 5: 435\n",
            "0.00.002.242 W Thread 5: 437\n",
            "E Thread 5: 438\n",
            "E Thread 5: 440\n",
            "Thread 5: 442\n",
            "Thread 5: 443\n",
            "Thread 5: 444\n",
            "0.00.002.246 I Thread 5: 445\n",
            "0.00.002.246 W Thread 5: 446\n",
            "E Thread 5: 447\n",
            "E Thread 5: 448\n",
            "Thread 5: 449\n",
            "0.00.002.249 W Thread 5: 450\n",
            "0.00.002.249 W Thread 5: 452\n",
            "Thread 5: 454\n",
            "Thread 5: 456\n",
            "Thread 5: 457\n",
            "Thread 5: 459\n",
            "Thread 5: 460\n",
            "Thread 5: 461\n",
            "Thread 5: 462\n",
            "Thread 5: 463\n",
            "Thread 5: 465\n",
            "Thread 5: 467\n",
            "Thread 5: 468\n",
            "Thread 5: 469\n",
            "Thread 5: 470\n",
            "0.00.002.256 I Thread 5: 473\n",
            "Thread 5: 474\n",
            "Thread 5: 475\n",
            "Thread 5: 476\n",
            "Thread 5: 477\n",
            "0.00.002.259 I Thread 5: 478\n",
            "Thread 5: 479\n",
            "Thread 5: 480\n",
            "Thread 5: 482\n",
            "Thread 5: 484\n",
            "I Thread 5: 485\n",
            "Thread 5: 486\n",
            "Thread 5: 487\n",
            "Thread 5: 489\n",
            "Thread 5: 490\n",
            "Thread 5: 491\n",
            "0.00.002.266 W Thread 5: 492\n",
            "0.00.002.266 W Thread 5: 493\n",
            "0.00.002.267 E Thread 5: 496\n",
            "0.00.002.267 E Thread 5: 497\n",
            "0.00.002.268 W Thread 5: 498\n",
            "0.00.002.268 I Thread 5: 499\n",
            "E Thread 5: 500\n",
            "E Thread 5: 501\n",
            "W Thread 5: 502\n",
            "Thread 5: 503\n",
            "Thread 5: 504\n",
            "Thread 5: 505\n",
            "Thread 5: 506\n",
            "Thread 5: 507\n",
            "0.00.002.273 W Thread 5: 508\n",
            "Thread 5: 510\n",
            "Thread 5: 511\n",
            "W Thread 5: 512\n",
            "E Thread 5: 513\n",
            "W Thread 5: 514\n",
            "Thread 5: 516\n",
            "Thread 5: 517\n",
            "Thread 5: 518\n",
            "E Thread 5: 519\n",
            "0.00.002.278 W Thread 5: 521\n",
            "I Thread 5: 522\n",
            "E Thread 5: 523\n",
            "I Thread 5: 524\n",
            "I Thread 5: 525\n",
            "E Thread 5: 526\n",
            "E Thread 5: 527\n",
            "E Thread 5: 528\n",
            "Thread 5: 529\n",
            "Thread 5: 530\n",
            "Thread 5: 531\n",
            "Thread 5: 532\n",
            "Thread 5: 533\n",
            "Thread 5: 535\n",
            "0.00.002.286 E Thread 5: 537\n",
            "0.00.002.286 E Thread 5: 538\n",
            "Thread 5: 539\n",
            "Thread 5: 540\n",
            "Thread 5: 542\n",
            "Thread 5: 543\n",
            "0.00.002.289 W Thread 5: 545\n",
            "0.00.002.289 E Thread 5: 546\n",
            "Thread 5: 547\n",
            "Thread 5: 548\n",
            "I Thread 5: 549\n",
            "E Thread 5: 551\n",
            "I Thread 5: 552\n",
            "I Thread 5: 553\n",
            "E Thread 5: 554\n",
            "E Thread 5: 555\n",
            "I Thread 5: 556\n",
            "Thread 5: 557\n",
            "Thread 5: 558\n",
            "0.00.002.296 E Thread 5: 559\n",
            "Thread 5: 560\n",
            "Thread 5: 561\n",
            "W Thread 5: 564\n",
            "Thread 5: 567\n",
            "Thread 5: 568\n",
            "Thread 5: 569\n",
            "I Thread 5: 570\n",
            "Thread 5: 571\n",
            "Thread 5: 572\n",
            "Thread 5: 573\n",
            "Thread 5: 574\n",
            "Thread 5: 575\n",
            "Thread 5: 577\n",
            "Thread 5: 578\n",
            "Thread 5: 579\n",
            "0.00.002.306 E Thread 5: 580\n",
            "Thread 5: 581\n",
            "I Thread 5: 582\n",
            "I Thread 5: 584\n",
            "E Thread 5: 585\n",
            "I Thread 5: 586\n",
            "Thread 5: 587\n",
            "Thread 5: 589\n",
            "0.00.002.310 I Thread 5: 590\n",
            "0.00.002.310 I Thread 5: 591\n",
            "W Thread 5: 594\n",
            "0.00.002.312 W Thread 5: 596\n",
            "0.00.002.313 W Thread 5: 597\n",
            "Thread 5: 598\n",
            "Thread 5: 599\n",
            "Thread 5: 600\n",
            "E Thread 5: 603\n",
            "E Thread 5: 606\n",
            "I Thread 5: 607\n",
            "E Thread 5: 608\n",
            "I Thread 5: 609\n",
            "0.00.002.318 W Thread 5: 610\n",
            "W Thread 5: 612\n",
            "E Thread 5: 613\n",
            "I Thread 5: 614\n",
            "Thread 5: 615\n",
            "Thread 5: 617\n",
            "Thread 5: 618\n",
            "0.00.002.322 W Thread 5: 619\n",
            "0.00.002.323 W Thread 5: 620\n",
            "0.00.002.323 W Thread 5: 621\n",
            "0.00.002.324 E Thread 5: 622\n",
            "W Thread 5: 625\n",
            "E Thread 5: 626\n",
            "Thread 5: 627\n",
            "E Thread 5: 628\n",
            "E Thread 5: 630\n",
            "Thread 5: 631\n",
            "Thread 5: 632\n",
            "0.00.002.329 W Thread 5: 633\n",
            "0.00.002.329 E Thread 5: 634\n",
            "Thread 5: 635\n",
            "Thread 5: 636\n",
            "Thread 5: 637\n",
            "Thread 5: 638\n",
            "Thread 5: 639\n",
            "0.00.002.332 W Thread 5: 640\n",
            "W Thread 5: 642\n",
            "0.00.002.333 I Thread 5: 643\n",
            "0.00.002.334 I Thread 5: 644\n",
            "0.00.002.335 I Thread 5: 645\n",
            "Thread 5: 646\n",
            "0.00.002.336 I Thread 5: 648\n",
            "Thread 5: 651\n",
            "Thread 5: 652\n",
            "E Thread 5: 654\n",
            "Thread 5: 655\n",
            "Thread 5: 657\n",
            "Thread 5: 659\n",
            "Thread 5: 660\n",
            "Thread 5: 661\n",
            "Thread 5: 662\n",
            "Thread 5: 663\n",
            "Thread 5: 664\n",
            "Thread 5: 665\n",
            "Thread 5: 666\n",
            "0.00.002.344 W Thread 5: 667\n",
            "Thread 5: 669\n",
            "Thread 5: 670\n",
            "Thread 5: 671\n",
            "Thread 5: 672\n",
            "0.00.002.347 I Thread 5: 673\n",
            "0.00.002.348 I Thread 5: 674\n",
            "Thread 5: 675\n",
            "Thread 5: 676\n",
            "0.00.002.350 I Thread 5: 678\n",
            "0.00.002.350 E Thread 5: 679\n",
            "0.00.002.351 E Thread 5: 680\n",
            "0.00.002.351 E Thread 5: 681\n",
            "Thread 5: 682\n",
            "Thread 5: 683\n",
            "Thread 5: 684\n",
            "Thread 5: 685\n",
            "W Thread 5: 686\n",
            "E Thread 5: 687\n",
            "I Thread 5: 688\n",
            "Thread 5: 689\n",
            "Thread 5: 690\n",
            "Thread 5: 691\n",
            "I Thread 5: 692\n",
            "I Thread 5: 693\n",
            "W Thread 5: 696\n",
            "Thread 5: 697\n",
            "I Thread 5: 698\n",
            "Thread 5: 700\n",
            "Thread 5: 701\n",
            "Thread 5: 702\n",
            "E Thread 5: 703\n",
            "I Thread 5: 704\n",
            "0.00.003.497 I Thread 5: 705\n",
            "Thread 5: 707\n",
            "I Thread 5: 708\n",
            "Thread 5: 709\n",
            "Thread 5: 711\n",
            "I Thread 5: 712\n",
            "I Thread 5: 714\n",
            "W Thread 5: 715\n",
            "Thread 5: 717\n",
            "Thread 5: 719\n",
            "Thread 5: 720\n",
            "Thread 5: 721\n",
            "Thread 5: 725\n",
            "Thread 5: 726\n",
            "Thread 5: 727\n",
            "Thread 5: 728\n",
            "E Thread 5: 730\n",
            "0.00.003.507 E Thread 5: 731\n",
            "0.00.003.508 I Thread 5: 733\n",
            "0.00.003.509 W Thread 5: 734\n",
            "0.00.003.509 W Thread 5: 735\n",
            "0.00.003.510 E Thread 5: 738\n",
            "Thread 5: 740\n",
            "Thread 5: 741\n",
            "Thread 5: 743\n",
            "Thread 5: 744\n",
            "Thread 5: 745\n",
            "Thread 5: 746\n",
            "0.00.003.514 I Thread 5: 747\n",
            "Thread 5: 748\n",
            "0.00.003.515 I Thread 5: 749\n",
            "0.00.003.515 E Thread 5: 750\n",
            "0.00.003.516 E Thread 5: 751\n",
            "E Thread 5: 753\n",
            "E Thread 5: 755\n",
            "W Thread 5: 756\n",
            "0.00.003.518 E Thread 5: 758\n",
            "Thread 5: 759\n",
            "Thread 5: 760\n",
            "Thread 5: 761\n",
            "0.00.003.520 I Thread 5: 763\n",
            "0.00.003.521 I Thread 5: 764\n",
            "0.00.003.521 I Thread 5: 765\n",
            "0.00.003.522 W Thread 5: 766\n",
            "0.00.003.522 E Thread 5: 767\n",
            "I Thread 5: 768\n",
            "Thread 5: 769\n",
            "I Thread 5: 770\n",
            "Thread 5: 772\n",
            "I Thread 5: 773\n",
            "E Thread 5: 774\n",
            "E Thread 5: 775\n",
            "Thread 5: 777\n",
            "Thread 5: 778\n",
            "Thread 5: 780\n",
            "Thread 5: 781\n",
            "Thread 5: 782\n",
            "Thread 5: 783\n",
            "Thread 5: 784\n",
            "Thread 5: 786\n",
            "Thread 5: 787\n",
            "E Thread 5: 789\n",
            "Thread 5: 790\n",
            "Thread 5: 791\n",
            "Thread 5: 792\n",
            "0.00.003.531 I Thread 5: 793\n",
            "0.00.003.532 I Thread 5: 794\n",
            "0.00.003.532 W Thread 5: 796\n",
            "E Thread 5: 799\n",
            "E Thread 5: 801\n",
            "W Thread 5: 802\n",
            "0.00.003.534 I Thread 5: 803\n",
            "Thread 5: 804\n",
            "Thread 5: 806\n",
            "Thread 5: 807\n",
            "Thread 5: 808\n",
            "Thread 5: 809\n",
            "I Thread 5: 811\n",
            "E Thread 5: 812\n",
            "W Thread 5: 813\n",
            "W Thread 5: 814\n",
            "I Thread 5: 815\n",
            "Thread 5: 816\n",
            "W Thread 5: 817\n",
            "E Thread 5: 818\n",
            "Thread 5: 820\n",
            "Thread 5: 822\n",
            "Thread 5: 823\n",
            "0.00.003.542 E Thread 5: 824\n",
            "0.00.003.542 I Thread 5: 825\n",
            "0.00.003.543 I Thread 5: 826\n",
            "Thread 5: 827\n",
            "Thread 5: 828\n",
            "Thread 5: 829\n",
            "0.00.003.545 E Thread 5: 830\n",
            "0.00.003.546 I Thread 5: 831\n",
            "Thread 5: 832\n",
            "I Thread 5: 833\n",
            "0.00.003.547 W Thread 5: 834\n",
            "E Thread 5: 835\n",
            "I Thread 5: 837\n",
            "W Thread 5: 838\n",
            "0.00.003.550 I Thread 5: 840\n",
            "Thread 5: 841\n",
            "Thread 5: 842\n",
            "Thread 5: 843\n",
            "Thread 5: 844\n",
            "Thread 5: 845\n",
            "Thread 5: 846\n",
            "Thread 5: 847\n",
            "I Thread 5: 851\n",
            "I Thread 5: 852\n",
            "0.00.003.555 E Thread 5: 856\n",
            "0.00.003.556 W Thread 5: 857\n",
            "0.00.003.556 I Thread 5: 858\n",
            "0.00.003.557 I Thread 5: 859\n",
            "0.00.003.557 I Thread 5: 860\n",
            "0.00.003.558 I Thread 5: 861\n",
            "0.00.003.558 E Thread 5: 862\n",
            "0.00.003.559 E Thread 5: 863\n",
            "Thread 5: 864\n",
            "0.00.003.560 W Thread 5: 865\n",
            "0.00.003.560 E Thread 5: 866\n",
            "0.00.003.561 E Thread 5: 870\n",
            "Thread 5: 872\n",
            "Thread 5: 873\n",
            "Thread 5: 874\n",
            "Thread 5: 875\n",
            "Thread 5: 878\n",
            "Thread 5: 879\n",
            "0.00.003.565 I Thread 5: 881\n",
            "0.00.003.565 I Thread 5: 882\n",
            "W Thread 5: 885\n",
            "E Thread 5: 886\n",
            "0.00.003.567 I Thread 5: 887\n",
            "I Thread 5: 888\n",
            "0.00.003.568 E Thread 5: 889\n",
            "Thread 5: 890\n",
            "W Thread 5: 891\n",
            "W Thread 5: 893\n",
            "W Thread 5: 894\n",
            "Thread 5: 895\n",
            "Thread 5: 896\n",
            "Thread 5: 897\n",
            "Thread 5: 898\n",
            "Thread 5: 899\n",
            "0.00.003.574 W Thread 5: 901\n",
            "Thread 5: 902\n",
            "W Thread 5: 903\n",
            "I Thread 5: 904\n",
            "W Thread 5: 905\n",
            "I Thread 5: 907\n",
            "0.00.003.577 E Thread 5: 908\n",
            "0.00.003.577 W Thread 5: 909\n",
            "0.00.003.578 E Thread 5: 910\n",
            "Thread 5: 911\n",
            "Thread 5: 912\n",
            "0.00.003.579 I Thread 5: 913\n",
            "Thread 5: 915\n",
            "Thread 5: 916\n",
            "0.00.003.581 I Thread 5: 918\n",
            "0.00.003.582 E Thread 5: 919\n",
            "0.00.003.582 E Thread 5: 920\n",
            "0.00.003.583 W Thread 5: 921\n",
            "Thread 5: 922\n",
            "Thread 5: 923\n",
            "0.00.003.584 I Thread 5: 924\n",
            "Thread 5: 925\n",
            "I Thread 5: 926\n",
            "W Thread 5: 927\n",
            "I Thread 5: 928\n",
            "I Thread 5: 929\n",
            "E Thread 5: 930\n",
            "E Thread 5: 931\n",
            "Thread 5: 935\n",
            "Thread 5: 936\n",
            "Thread 5: 937\n",
            "Thread 5: 938\n",
            "Thread 5: 940\n",
            "Thread 5: 941\n",
            "Thread 5: 942\n",
            "Thread 5: 944\n",
            "I Thread 5: 946\n",
            "W Thread 5: 947\n",
            "I Thread 5: 948\n",
            "I Thread 5: 949\n",
            "0.00.003.595 I Thread 5: 950\n",
            "Thread 5: 951\n",
            "0.00.003.597 W Thread 5: 952\n",
            "Thread 5: 954\n",
            "Thread 5: 955\n",
            "W Thread 5: 957\n",
            "W Thread 5: 958\n",
            "0.00.003.600 E Thread 5: 959\n",
            "0.00.003.600 E Thread 5: 960\n",
            "Thread 5: 964\n",
            "Thread 5: 965\n",
            "Thread 5: 966\n",
            "E Thread 5: 967\n",
            "I Thread 5: 968\n",
            "Thread 5: 971\n",
            "Thread 5: 972\n",
            "Thread 5: 973\n",
            "Thread 5: 974\n",
            "0.00.003.606 E Thread 5: 975\n",
            "0.00.003.607 E Thread 5: 977\n",
            "0.00.003.608 W Thread 5: 978\n",
            "0.00.003.608 I Thread 5: 979\n",
            "0.00.003.609 I Thread 5: 980\n",
            "0.00.003.610 W Thread 5: 983\n",
            "0.00.003.610 W Thread 5: 984\n",
            "Thread 5: 985\n",
            "Thread 5: 987\n",
            "E Thread 5: 990\n",
            "W Thread 5: 991\n",
            "Thread 5: 993\n",
            "Thread 5: 995\n",
            "Thread 5: 996\n",
            "Thread 5: 997\n",
            "Thread 5: 998\n",
            "Thread 1: 0\n",
            "Thread 1: 2\n",
            "Thread 1: 3\n",
            "Thread 1: 4\n",
            "Thread 1: 7\n",
            "0.00.003.642 I Thread 1: 8\n",
            "W Thread 1: 10\n",
            "Thread 1: 11\n",
            "Thread 1: 12\n",
            "0.00.003.644 I Thread 1: 13\n",
            "0.00.003.645 E Thread 1: 15\n",
            "Thread 1: 16\n",
            "Thread 1: 17\n",
            "Thread 1: 18\n",
            "Thread 1: 20\n",
            "0.00.003.648 I Thread 1: 21\n",
            "E Thread 1: 23\n",
            "I Thread 1: 24\n",
            "E Thread 1: 25\n",
            "Thread 1: 26\n",
            "I Thread 1: 27\n",
            "W Thread 1: 28\n",
            "I Thread 1: 30\n",
            "E Thread 1: 31\n",
            "W Thread 1: 32\n",
            "E Thread 1: 33\n",
            "Thread 1: 34\n",
            "Thread 1: 35\n",
            "Thread 1: 36\n",
            "Thread 1: 37\n",
            "Thread 1: 38\n",
            "0.00.003.656 E Thread 1: 39\n",
            "I Thread 1: 40\n",
            "Thread 1: 42\n",
            "Thread 1: 44\n",
            "W Thread 1: 50\n",
            "W Thread 1: 51\n",
            "Thread 1: 53\n",
            "0.00.003.662 W Thread 1: 54\n",
            "0.00.003.662 E Thread 1: 55\n",
            "0.00.003.663 W Thread 1: 57\n",
            "Thread 1: 58\n",
            "Thread 1: 61\n",
            "Thread 1: 62\n",
            "Thread 1: 63\n",
            "Thread 1: 64\n",
            "0.00.003.667 W Thread 1: 65\n",
            "0.00.003.667 I Thread 1: 66\n",
            "0.00.003.668 I Thread 1: 67\n",
            "Thread 1: 68\n",
            "Thread 1: 69\n",
            "Thread 1: 70\n",
            "Thread 1: 71\n",
            "Thread 1: 73\n",
            "Thread 1: 74\n",
            "0.00.003.672 W Thread 1: 75\n",
            "0.00.003.672 E Thread 1: 76\n",
            "Thread 1: 79\n",
            "Thread 1: 80\n",
            "Thread 1: 81\n",
            "Thread 1: 82\n",
            "Thread 1: 83\n",
            "Thread 1: 84\n",
            "Thread 1: 85\n",
            "Thread 1: 86\n",
            "Thread 1: 88\n",
            "Thread 1: 89\n",
            "Thread 1: 90\n",
            "Thread 1: 92\n",
            "Thread 1: 93\n",
            "W Thread 1: 94\n",
            "0.00.003.681 W Thread 1: 96\n",
            "E Thread 1: 97\n",
            "0.00.003.682 W Thread 1: 98\n",
            "Thread 1: 101\n",
            "Thread 1: 102\n",
            "I Thread 1: 103\n",
            "E Thread 1: 104\n",
            "I Thread 1: 105\n",
            "W Thread 1: 106\n",
            "Thread 1: 107\n",
            "Thread 1: 108\n",
            "Thread 1: 110\n",
            "0.00.003.688 I Thread 1: 111\n",
            "Thread 1: 113\n",
            "0.00.003.689 E Thread 1: 114\n",
            "Thread 1: 115\n",
            "Thread 1: 116\n",
            "Thread 1: 118\n",
            "Thread 1: 120\n",
            "Thread 1: 121\n",
            "I Thread 1: 124\n",
            "W Thread 1: 126\n",
            "Thread 1: 127\n",
            "0.00.003.695 W Thread 1: 128\n",
            "Thread 1: 129\n",
            "Thread 1: 130\n",
            "Thread 1: 131\n",
            "Thread 1: 132\n",
            "Thread 1: 133\n",
            "Thread 1: 134\n",
            "Thread 1: 135\n",
            "Thread 1: 137\n",
            "W Thread 1: 139\n",
            "E Thread 1: 140\n",
            "W Thread 1: 141\n",
            "E Thread 1: 142\n",
            "Thread 1: 143\n",
            "Thread 1: 145\n",
            "Thread 1: 146\n",
            "E Thread 1: 149\n",
            "Thread 1: 150\n",
            "Thread 1: 153\n",
            "Thread 1: 154\n",
            "Thread 1: 155\n",
            "Thread 1: 156\n",
            "Thread 1: 157\n",
            "Thread 1: 158\n",
            "Thread 1: 159\n",
            "Thread 1: 160\n",
            "Thread 1: 161\n",
            "Thread 1: 162\n",
            "Thread 1: 163\n",
            "Thread 1: 164\n",
            "I Thread 1: 165\n",
            "Thread 1: 166\n",
            "Thread 1: 168\n",
            "0.00.003.713 I Thread 1: 169\n",
            "0.00.003.714 E Thread 1: 170\n",
            "I Thread 1: 171\n",
            "I Thread 1: 172\n",
            "Thread 1: 173\n",
            "Thread 1: 174\n",
            "Thread 1: 175\n",
            "I Thread 1: 177\n",
            "E Thread 1: 178\n",
            "Thread 1: 179\n",
            "Thread 1: 180\n",
            "Thread 1: 181\n",
            "0.00.003.720 E Thread 1: 183\n",
            "0.00.003.721 E Thread 1: 184\n",
            "0.00.003.722 W Thread 1: 186\n",
            "0.00.003.722 W Thread 1: 187\n",
            "Thread 1: 189\n",
            "Thread 1: 190\n",
            "0.00.003.724 E Thread 1: 191\n",
            "Thread 1: 195\n",
            "0.00.003.726 I Thread 1: 200\n",
            "0.00.003.726 E Thread 1: 201\n",
            "0.00.003.727 E Thread 1: 203\n",
            "0.00.003.728 I Thread 1: 205\n",
            "0.00.003.728 W Thread 1: 206\n",
            "0.00.003.729 E Thread 1: 207\n",
            "0.00.003.729 I Thread 1: 208\n",
            "E Thread 1: 209\n",
            "I Thread 1: 211\n",
            "I Thread 1: 213\n",
            "E Thread 1: 214\n",
            "I Thread 1: 215\n",
            "E Thread 1: 216\n",
            "I Thread 1: 217\n",
            "0.00.003.734 W Thread 1: 218\n",
            "0.00.003.734 W Thread 1: 219\n",
            "W Thread 1: 220\n",
            "Thread 1: 222\n",
            "0.00.003.736 W Thread 1: 223\n",
            "0.00.003.737 I Thread 1: 224\n",
            "E Thread 1: 226\n",
            "Thread 1: 227\n",
            "Thread 1: 228\n",
            "Thread 1: 229\n",
            "0.00.003.740 E Thread 1: 230\n",
            "I Thread 1: 232\n",
            "Thread 1: 233\n",
            "Thread 1: 234\n",
            "0.00.003.742 I Thread 1: 235\n",
            "Thread 1: 237\n",
            "Thread 1: 238\n",
            "0.00.003.744 W Thread 1: 239\n",
            "I Thread 1: 240\n",
            "0.00.003.745 I Thread 1: 241\n",
            "0.00.003.746 W Thread 1: 242\n",
            "Thread 1: 244\n",
            "Thread 1: 245\n",
            "Thread 1: 246\n",
            "Thread 1: 247\n",
            "0.00.003.749 I Thread 1: 249\n",
            "0.00.003.750 E Thread 1: 250\n",
            "Thread 1: 252\n",
            "Thread 1: 253\n",
            "0.00.003.752 W Thread 1: 257\n",
            "0.00.003.753 W Thread 1: 260\n",
            "0.00.003.754 E Thread 1: 262\n",
            "I Thread 1: 265\n",
            "W Thread 1: 266\n",
            "Thread 1: 267\n",
            "Thread 1: 268\n",
            "Thread 1: 269\n",
            "Thread 1: 272\n",
            "Thread 1: 273\n",
            "0.00.003.759 E Thread 1: 274\n",
            "Thread 1: 275\n",
            "Thread 1: 277\n",
            "0.00.003.761 W Thread 1: 278\n",
            "0.00.003.762 I Thread 1: 279\n",
            "0.00.003.762 W Thread 1: 280\n",
            "0.00.003.763 E Thread 1: 281\n",
            "Thread 1: 282\n",
            "Thread 1: 283\n",
            "Thread 1: 284\n",
            "Thread 1: 286\n",
            "E Thread 1: 288\n",
            "E Thread 1: 289\n",
            "E Thread 1: 290\n",
            "Thread 1: 291\n",
            "Thread 1: 292\n",
            "Thread 1: 293\n",
            "Thread 1: 294\n",
            "Thread 1: 295\n",
            "Thread 1: 296\n",
            "Thread 1: 297\n",
            "Thread 1: 298\n",
            "Thread 1: 299\n",
            "Thread 1: 300\n",
            "Thread 1: 301\n",
            "Thread 1: 302\n",
            "0.00.003.774 W Thread 1: 304\n",
            "0.00.003.775 E Thread 1: 305\n",
            "0.00.003.775 E Thread 1: 306\n",
            "0.00.003.776 E Thread 1: 307\n",
            "Thread 1: 309\n",
            "Thread 1: 311\n",
            "Thread 1: 312\n",
            "Thread 1: 315\n",
            "Thread 1: 316\n",
            "Thread 1: 317\n",
            "W Thread 1: 318\n",
            "0.00.003.781 I Thread 1: 319\n",
            "Thread 1: 322\n",
            "Thread 1: 323\n",
            "Thread 1: 324\n",
            "Thread 1: 325\n",
            "Thread 1: 326\n",
            "Thread 1: 327\n",
            "Thread 1: 328\n",
            "E Thread 1: 329\n",
            "W Thread 1: 330\n",
            "W Thread 1: 332\n",
            "Thread 1: 333\n",
            "Thread 1: 334\n",
            "Thread 1: 335\n",
            "I Thread 1: 336\n",
            "W Thread 1: 337\n",
            "W Thread 1: 338\n",
            "Thread 1: 339\n",
            "Thread 1: 340\n",
            "Thread 1: 341\n",
            "Thread 1: 343\n",
            "E Thread 1: 344\n",
            "Thread 1: 345\n",
            "Thread 1: 349\n",
            "Thread 1: 350\n",
            "Thread 1: 351\n",
            "0.00.003.796 W Thread 1: 352\n",
            "0.00.003.797 I Thread 1: 353\n",
            "Thread 1: 354\n",
            "Thread 1: 355\n",
            "Thread 1: 356\n",
            "Thread 1: 357\n",
            "Thread 1: 358\n",
            "Thread 1: 359\n",
            "E Thread 1: 360\n",
            "Thread 1: 362\n",
            "Thread 1: 363\n",
            "E Thread 1: 364\n",
            "0.00.003.803 W Thread 1: 365\n",
            "Thread 1: 366\n",
            "I Thread 1: 367\n",
            "E Thread 1: 368\n",
            "Thread 1: 369\n",
            "Thread 1: 371\n",
            "Thread 1: 372\n",
            "Thread 1: 374\n",
            "E Thread 1: 375\n",
            "Thread 1: 378\n",
            "Thread 1: 379\n",
            "Thread 1: 380\n",
            "0.00.003.811 W Thread 1: 383\n",
            "I Thread 1: 385\n",
            "W Thread 1: 389\n",
            "W Thread 1: 390\n",
            "I Thread 1: 391\n",
            "E Thread 1: 392\n",
            "Thread 1: 393\n",
            "Thread 1: 394\n",
            "Thread 1: 395\n",
            "Thread 1: 396\n",
            "Thread 1: 397\n",
            "Thread 1: 398\n",
            "Thread 1: 399\n",
            "E Thread 1: 401\n",
            "E Thread 1: 402\n",
            "Thread 1: 404\n",
            "E Thread 1: 405\n",
            "I Thread 1: 406\n",
            "W Thread 1: 407\n",
            "0.00.003.822 E Thread 1: 409\n",
            "0.00.003.822 I Thread 1: 410\n",
            "Thread 1: 411\n",
            "Thread 1: 413\n",
            "Thread 1: 414\n",
            "Thread 1: 416\n",
            "Thread 1: 417\n",
            "0.00.003.826 I Thread 1: 419\n",
            "0.00.003.826 W Thread 1: 420\n",
            "0.00.003.827 E Thread 1: 421\n",
            "0.00.003.827 E Thread 1: 422\n",
            "0.00.003.828 E Thread 1: 425\n",
            "0.00.003.829 I Thread 1: 426\n",
            "0.00.003.829 I Thread 1: 427\n",
            "E Thread 1: 428\n",
            "E Thread 1: 429\n",
            "I Thread 1: 430\n",
            "Thread 1: 431\n",
            "Thread 1: 432\n",
            "Thread 1: 433\n",
            "Thread 1: 434\n",
            "Thread 1: 435\n",
            "Thread 1: 436\n",
            "Thread 1: 437\n",
            "Thread 1: 438\n",
            "W Thread 1: 439\n",
            "0.00.003.836 E Thread 1: 440\n",
            "Thread 1: 441\n",
            "Thread 1: 443\n",
            "Thread 1: 445\n",
            "0.00.003.839 I Thread 1: 449\n",
            "Thread 1: 451\n",
            "0.00.003.841 I Thread 1: 453\n",
            "I Thread 1: 454\n",
            "Thread 1: 456\n",
            "Thread 1: 457\n",
            "Thread 1: 458\n",
            "Thread 1: 459\n",
            "Thread 1: 460\n",
            "Thread 1: 462\n",
            "Thread 1: 464\n",
            "0.00.003.846 W Thread 1: 465\n",
            "0.00.003.847 I Thread 1: 466\n",
            "E Thread 1: 468\n",
            "0.00.003.848 I Thread 1: 469\n",
            "0.00.003.849 W Thread 1: 470\n",
            "Thread 1: 472\n",
            "W Thread 1: 473\n",
            "I Thread 1: 474\n",
            "W Thread 1: 475\n",
            "E Thread 1: 476\n",
            "E Thread 1: 477\n",
            "I Thread 1: 478\n",
            "I Thread 1: 479\n",
            "W Thread 1: 480\n",
            "E Thread 1: 481\n",
            "I Thread 1: 483\n",
            "Thread 1: 485\n",
            "Thread 1: 486\n",
            "0.00.003.857 W Thread 1: 487\n",
            "Thread 1: 488\n",
            "Thread 1: 489\n",
            "Thread 1: 490\n",
            "W Thread 1: 491\n",
            "Thread 1: 492\n",
            "0.00.003.861 I Thread 1: 494\n",
            "0.00.003.861 I Thread 1: 495\n",
            "0.00.003.862 E Thread 1: 496\n",
            "Thread 1: 499\n",
            "I Thread 1: 502\n",
            "Thread 1: 503\n",
            "Thread 1: 506\n",
            "Thread 1: 507\n",
            "Thread 1: 508\n",
            "Thread 1: 509\n",
            "Thread 1: 510\n",
            "W Thread 1: 512\n",
            "0.00.003.869 E Thread 1: 514\n",
            "0.00.003.869 W Thread 1: 515\n",
            "Thread 1: 516\n",
            "W Thread 1: 517\n",
            "0.00.003.871 I Thread 1: 518\n",
            "Thread 1: 521\n",
            "Thread 1: 522\n",
            "Thread 1: 523\n",
            "Thread 1: 524\n",
            "W Thread 1: 525\n",
            "Thread 1: 526\n",
            "0.00.003.876 W Thread 1: 527\n",
            "Thread 1: 528\n",
            "Thread 1: 529\n",
            "0.00.003.878 I Thread 1: 531\n",
            "W Thread 1: 532\n",
            "W Thread 1: 533\n",
            "0.00.003.880 I Thread 1: 534\n",
            "0.00.003.880 I Thread 1: 536\n",
            "Thread 1: 537\n",
            "E Thread 1: 538\n",
            "W Thread 1: 539\n",
            "W Thread 1: 543\n",
            "I Thread 1: 545\n",
            "I Thread 1: 546\n",
            "Thread 1: 547\n",
            "Thread 1: 548\n",
            "Thread 1: 550\n",
            "Thread 1: 554\n",
            "Thread 1: 555\n",
            "Thread 1: 556\n",
            "Thread 1: 557\n",
            "Thread 1: 558\n",
            "Thread 1: 559\n",
            "Thread 1: 561\n",
            "Thread 1: 562\n",
            "0.00.003.891 W Thread 1: 563\n",
            "0.00.003.892 I Thread 1: 564\n",
            "Thread 1: 565\n",
            "Thread 1: 566\n",
            "Thread 1: 568\n",
            "Thread 1: 569\n",
            "W Thread 1: 570\n",
            "W Thread 1: 571\n",
            "0.00.003.896 I Thread 1: 572\n",
            "0.00.003.897 E Thread 1: 573\n",
            "E Thread 1: 575\n",
            "I Thread 1: 576\n",
            "I Thread 1: 578\n",
            "E Thread 1: 580\n",
            "Thread 1: 582\n",
            "0.00.003.901 I Thread 1: 586\n",
            "0.00.003.902 E Thread 1: 587\n",
            "Thread 1: 588\n",
            "Thread 1: 589\n",
            "Thread 1: 592\n",
            "0.00.003.905 W Thread 1: 596\n",
            "0.00.003.905 W Thread 1: 597\n",
            "0.00.003.906 W Thread 1: 598\n",
            "Thread 1: 599\n",
            "Thread 1: 600\n",
            "Thread 1: 601\n",
            "Thread 1: 603\n",
            "W Thread 1: 604\n",
            "Thread 1: 606\n",
            "Thread 1: 607\n",
            "Thread 1: 608\n",
            "0.00.003.911 W Thread 1: 609\n",
            "0.00.003.911 W Thread 1: 610\n",
            "E Thread 1: 611\n",
            "W Thread 1: 612\n",
            "Thread 1: 614\n",
            "E Thread 1: 615\n",
            "Thread 1: 617\n",
            "Thread 1: 618\n",
            "Thread 1: 619\n",
            "0.00.003.916 I Thread 1: 620\n",
            "W Thread 1: 622\n",
            "I Thread 1: 624\n",
            "W Thread 1: 625\n",
            "I Thread 1: 627\n",
            "0.00.003.920 E Thread 1: 628\n",
            "W Thread 1: 629\n",
            "0.00.003.921 W Thread 1: 630\n",
            "Thread 1: 633\n",
            "Thread 1: 634\n",
            "I Thread 1: 635\n",
            "Thread 1: 637\n",
            "Thread 1: 638\n",
            "Thread 1: 639\n",
            "Thread 1: 640\n",
            "0.00.003.926 W Thread 1: 641\n",
            "0.00.003.927 E Thread 1: 642\n",
            "0.00.003.927 W Thread 1: 643\n",
            "Thread 1: 644\n",
            "Thread 1: 645\n",
            "Thread 1: 646\n",
            "Thread 1: 647\n",
            "Thread 1: 648\n",
            "Thread 1: 649\n",
            "Thread 1: 650\n",
            "Thread 1: 651\n",
            "Thread 1: 652\n",
            "Thread 1: 653\n",
            "Thread 1: 654\n",
            "Thread 1: 655\n",
            "W Thread 1: 657\n",
            "W Thread 1: 659\n",
            "Thread 1: 660\n",
            "Thread 1: 661\n",
            "Thread 1: 662\n",
            "Thread 1: 663\n",
            "0.00.003.938 W Thread 1: 664\n",
            "0.00.003.939 I Thread 1: 666\n",
            "0.00.003.939 W Thread 1: 667\n",
            "Thread 1: 668\n",
            "Thread 1: 671\n",
            "Thread 1: 672\n",
            "Thread 1: 673\n",
            "Thread 1: 674\n",
            "0.00.003.943 I Thread 1: 675\n",
            "0.00.003.944 I Thread 1: 676\n",
            "Thread 1: 677\n",
            "Thread 1: 680\n",
            "Thread 1: 681\n",
            "Thread 1: 682\n",
            "Thread 1: 684\n",
            "Thread 1: 686\n",
            "Thread 1: 687\n",
            "Thread 1: 688\n",
            "E Thread 1: 689\n",
            "Thread 1: 690\n",
            "Thread 1: 691\n",
            "Thread 1: 692\n",
            "0.00.003.952 W Thread 1: 693\n",
            "Thread 1: 694\n",
            "Thread 1: 695\n",
            "0.00.003.953 I Thread 1: 696\n",
            "0.00.003.954 I Thread 1: 697\n",
            "W Thread 1: 698\n",
            "Thread 1: 700\n",
            "Thread 1: 701\n",
            "0.00.003.957 E Thread 1: 702\n",
            "Thread 1: 703\n",
            "Thread 1: 704\n",
            "Thread 1: 705\n",
            "W Thread 1: 706\n",
            "W Thread 1: 707\n",
            "Thread 1: 708\n",
            "0.00.003.961 W Thread 1: 709\n",
            "0.00.003.961 I Thread 1: 710\n",
            "E Thread 1: 711\n",
            "0.00.003.962 E Thread 1: 712\n",
            "0.00.003.963 E Thread 1: 713\n",
            "Thread 1: 714\n",
            "Thread 1: 716\n",
            "W Thread 1: 717\n",
            "W Thread 1: 718\n",
            "E Thread 1: 720\n",
            "E Thread 1: 721\n",
            "W Thread 1: 722\n",
            "Thread 1: 724\n",
            "Thread 1: 725\n",
            "Thread 1: 726\n",
            "Thread 1: 727\n",
            "Thread 1: 730\n",
            "Thread 1: 732\n",
            "Thread 1: 733\n",
            "Thread 1: 734\n",
            "I Thread 1: 735\n",
            "Thread 1: 736\n",
            "Thread 1: 737\n",
            "Thread 1: 739\n",
            "I Thread 1: 740\n",
            "Thread 1: 741\n",
            "Thread 1: 742\n",
            "0.00.003.976 W Thread 1: 745\n",
            "0.00.003.977 I Thread 1: 746\n",
            "Thread 1: 747\n",
            "Thread 1: 748\n",
            "Thread 1: 749\n",
            "Thread 1: 750\n",
            "0.00.003.980 I Thread 1: 751\n",
            "0.00.003.980 E Thread 1: 752\n",
            "Thread 1: 753\n",
            "0.00.003.981 E Thread 1: 754\n",
            "0.00.003.982 I Thread 1: 755\n",
            "Thread 1: 756\n",
            "Thread 1: 757\n",
            "0.00.003.984 E Thread 1: 760\n",
            "Thread 1: 761\n",
            "Thread 1: 762\n",
            "Thread 1: 763\n",
            "Thread 1: 764\n",
            "0.00.003.994 W Thread 1: 766\n",
            "0.00.003.995 E Thread 1: 767\n",
            "Thread 1: 769\n",
            "Thread 1: 770\n",
            "W Thread 1: 771\n",
            "E Thread 1: 772\n",
            "W Thread 1: 773\n",
            "Thread 1: 775\n",
            "I Thread 1: 776\n",
            "E Thread 1: 777\n",
            "Thread 1: 778\n",
            "Thread 1: 779\n",
            "Thread 1: 780\n",
            "Thread 1: 781\n",
            "W Thread 1: 782\n",
            "Thread 1: 783\n",
            "0.00.004.004 I Thread 1: 784\n",
            "0.00.004.005 E Thread 1: 785\n",
            "Thread 1: 786\n",
            "W Thread 1: 787\n",
            "0.00.004.007 E Thread 1: 788\n",
            "I Thread 1: 790\n",
            "E Thread 1: 791\n",
            "I Thread 1: 794\n",
            "E Thread 1: 795\n",
            "I Thread 1: 796\n",
            "Thread 1: 797\n",
            "Thread 1: 798\n",
            "E Thread 1: 800\n",
            "W Thread 1: 802\n",
            "W Thread 1: 804\n",
            "Thread 1: 805\n",
            "Thread 1: 806\n",
            "W Thread 1: 808\n",
            "Thread 1: 809\n",
            "Thread 1: 810\n",
            "I Thread 1: 811\n",
            "0.00.004.018 I Thread 1: 813\n",
            "E Thread 1: 816\n",
            "0.00.004.019 W Thread 1: 817\n",
            "Thread 1: 818\n",
            "E Thread 1: 819\n",
            "Thread 1: 820\n",
            "0.00.004.022 E Thread 1: 822\n",
            "Thread 1: 823\n",
            "Thread 1: 824\n",
            "Thread 1: 826\n",
            "W Thread 1: 828\n",
            "0.00.004.025 E Thread 1: 830\n",
            "W Thread 1: 833\n",
            "Thread 1: 834\n",
            "Thread 1: 835\n",
            "Thread 1: 836\n",
            "Thread 1: 837\n",
            "0.00.004.029 I Thread 1: 838\n",
            "0.00.004.029 W Thread 1: 839\n",
            "0.00.004.030 W Thread 1: 840\n",
            "Thread 1: 841\n",
            "Thread 1: 842\n",
            "Thread 1: 843\n",
            "0.00.004.032 I Thread 1: 844\n",
            "E Thread 1: 846\n",
            "Thread 1: 848\n",
            "Thread 1: 849\n",
            "E Thread 1: 851\n",
            "W Thread 1: 852\n",
            "W Thread 1: 853\n",
            "I Thread 1: 854\n",
            "E Thread 1: 855\n",
            "I Thread 1: 856\n",
            "Thread 1: 857\n",
            "E Thread 1: 859\n",
            "Thread 1: 860\n",
            "Thread 1: 861\n",
            "Thread 1: 862\n",
            "Thread 1: 864\n",
            "Thread 1: 865\n",
            "Thread 1: 866\n",
            "0.00.004.042 E Thread 1: 868\n",
            "0.00.004.043 E Thread 1: 870\n",
            "I Thread 1: 873\n",
            "W Thread 1: 874\n",
            "Thread 1: 875\n",
            "Thread 1: 877\n",
            "Thread 1: 879\n",
            "Thread 1: 880\n",
            "0.00.004.048 W Thread 1: 884\n",
            "0.00.004.048 W Thread 1: 885\n",
            "0.00.004.049 I Thread 1: 886\n",
            "W Thread 1: 888\n",
            "Thread 1: 889\n",
            "Thread 1: 890\n",
            "E Thread 1: 891\n",
            "I Thread 1: 892\n",
            "W Thread 1: 893\n",
            "Thread 1: 894\n",
            "Thread 1: 895\n",
            "Thread 1: 896\n",
            "Thread 1: 897\n",
            "Thread 1: 898\n",
            "Thread 1: 900\n",
            "0.00.004.057 E Thread 1: 901\n",
            "W Thread 1: 903\n",
            "W Thread 1: 904\n",
            "Thread 1: 906\n",
            "Thread 1: 907\n",
            "Thread 1: 908\n",
            "I Thread 1: 909\n",
            "Thread 1: 910\n",
            "Thread 1: 911\n",
            "Thread 1: 912\n",
            "0.00.004.063 W Thread 1: 913\n",
            "0.00.004.064 E Thread 1: 915\n",
            "0.00.004.064 W Thread 1: 916\n",
            "Thread 1: 917\n",
            "Thread 1: 918\n",
            "Thread 1: 919\n",
            "Thread 1: 920\n",
            "0.00.004.067 E Thread 1: 921\n",
            "Thread 1: 922\n",
            "Thread 1: 923\n",
            "Thread 1: 924\n",
            "0.00.004.070 I Thread 1: 926\n",
            "Thread 1: 927\n",
            "Thread 1: 928\n",
            "Thread 1: 930\n",
            "W Thread 1: 931\n",
            "I Thread 1: 932\n",
            "Thread 1: 933\n",
            "Thread 1: 934\n",
            "Thread 1: 935\n",
            "Thread 1: 936\n",
            "Thread 1: 937\n",
            "Thread 1: 938\n",
            "0.00.004.076 E Thread 1: 939\n",
            "0.00.004.077 I Thread 1: 940\n",
            "0.00.004.077 W Thread 1: 941\n",
            "Thread 1: 942\n",
            "Thread 1: 943\n",
            "Thread 1: 945\n",
            "Thread 1: 946\n",
            "Thread 1: 947\n",
            "Thread 1: 948\n",
            "Thread 1: 949\n",
            "I Thread 1: 950\n",
            "W Thread 1: 952\n",
            "Thread 1: 953\n",
            "E Thread 1: 955\n",
            "E Thread 1: 956\n",
            "0.00.004.085 E Thread 1: 957\n",
            "W Thread 1: 958\n",
            "Thread 1: 959\n",
            "Thread 1: 960\n",
            "Thread 1: 963\n",
            "Thread 1: 964\n",
            "Thread 1: 967\n",
            "Thread 1: 969\n",
            "Thread 1: 970\n",
            "Thread 1: 971\n",
            "Thread 1: 973\n",
            "I Thread 1: 975\n",
            "E Thread 1: 976\n",
            "I Thread 1: 977\n",
            "Thread 1: 980\n",
            "E Thread 1: 982\n",
            "W Thread 1: 983\n",
            "Thread 1: 984\n",
            "Thread 1: 985\n",
            "Thread 1: 986\n",
            "0.00.004.098 I Thread 1: 987\n",
            "W Thread 1: 988\n",
            "0.00.004.099 E Thread 1: 989\n",
            "Thread 1: 990\n",
            "Thread 1: 991\n",
            "Thread 1: 992\n",
            "Thread 1: 993\n",
            "Thread 1: 994\n",
            "Thread 1: 995\n",
            "Thread 1: 996\n",
            "I Thread 1: 997\n",
            "Thread 1: 998\n",
            "W Thread 1: 999\n",
            "E Thread 0: 0\n",
            "0.00.004.127 I Thread 0: 1\n",
            "0.00.004.127 E Thread 0: 2\n",
            "Thread 0: 3\n",
            "0.00.004.128 E Thread 0: 4\n",
            "Thread 0: 5\n",
            "Thread 0: 6\n",
            "Thread 0: 7\n",
            "Thread 0: 8\n",
            "Thread 0: 9\n",
            "I Thread 0: 11\n",
            "Thread 0: 13\n",
            "E Thread 0: 14\n",
            "Thread 0: 15\n",
            "Thread 0: 16\n",
            "Thread 0: 17\n",
            "Thread 0: 18\n",
            "Thread 0: 19\n",
            "Thread 0: 20\n",
            "Thread 0: 21\n",
            "Thread 0: 22\n",
            "Thread 0: 26\n",
            "Thread 0: 28\n",
            "Thread 0: 29\n",
            "0.00.004.158 I Thread 0: 30\n",
            "0.00.004.159 W Thread 0: 33\n",
            "0.00.004.160 I Thread 0: 35\n",
            "W Thread 0: 36\n",
            "I Thread 0: 37\n",
            "W Thread 0: 38\n",
            "W Thread 0: 41\n",
            "W Thread 0: 42\n",
            "W Thread 0: 43\n",
            "W Thread 0: 45\n",
            "Thread 0: 46\n",
            "Thread 0: 51\n",
            "Thread 0: 52\n",
            "0.00.004.167 I Thread 0: 53\n",
            "W Thread 0: 55\n",
            "Thread 0: 57\n",
            "Thread 0: 58\n",
            "Thread 0: 59\n",
            "Thread 0: 61\n",
            "0.00.004.170 E Thread 0: 62\n",
            "0.00.004.171 E Thread 0: 63\n",
            "0.00.004.171 I Thread 0: 64\n",
            "0.00.004.172 I Thread 0: 65\n",
            "0.00.004.172 E Thread 0: 66\n",
            "0.00.004.173 I Thread 0: 67\n",
            "0.00.004.173 W Thread 0: 69\n",
            "E Thread 0: 70\n",
            "Thread 0: 71\n",
            "I Thread 0: 72\n",
            "Thread 0: 73\n",
            "Thread 0: 74\n",
            "Thread 0: 77\n",
            "Thread 0: 78\n",
            "E Thread 0: 79\n",
            "0.00.004.179 E Thread 0: 80\n",
            "0.00.004.180 E Thread 0: 81\n",
            "E Thread 0: 83\n",
            "Thread 0: 84\n",
            "Thread 0: 85\n",
            "Thread 0: 86\n",
            "Thread 0: 87\n",
            "Thread 0: 88\n",
            "Thread 0: 89\n",
            "Thread 0: 90\n",
            "Thread 0: 91\n",
            "Thread 0: 92\n",
            "Thread 0: 93\n",
            "0.00.004.187 W Thread 0: 95\n",
            "Thread 0: 96\n",
            "Thread 0: 98\n",
            "I Thread 0: 99\n",
            "W Thread 0: 100\n",
            "E Thread 0: 102\n",
            "I Thread 0: 103\n",
            "I Thread 0: 104\n",
            "0.00.004.192 I Thread 0: 105\n",
            "Thread 0: 107\n",
            "Thread 0: 109\n",
            "Thread 0: 110\n",
            "Thread 0: 111\n",
            "Thread 0: 112\n",
            "Thread 0: 113\n",
            "Thread 0: 116\n",
            "I Thread 0: 117\n",
            "E Thread 0: 118\n",
            "W Thread 0: 119\n",
            "0.00.004.199 E Thread 0: 123\n",
            "0.00.004.199 E Thread 0: 124\n",
            "0.00.004.200 I Thread 0: 125\n",
            "0.00.004.200 W Thread 0: 126\n",
            "Thread 0: 127\n",
            "I Thread 0: 128\n",
            "E Thread 0: 130\n",
            "0.00.004.203 W Thread 0: 131\n",
            "Thread 0: 132\n",
            "Thread 0: 135\n",
            "Thread 0: 136\n",
            "Thread 0: 137\n",
            "Thread 0: 138\n",
            "Thread 0: 139\n",
            "Thread 0: 140\n",
            "E Thread 0: 141\n",
            "W Thread 0: 142\n",
            "W Thread 0: 143\n",
            "W Thread 0: 144\n",
            "E Thread 0: 145\n",
            "0.00.004.210 E Thread 0: 146\n",
            "0.00.004.211 E Thread 0: 147\n",
            "Thread 0: 148\n",
            "Thread 0: 150\n",
            "0.00.004.213 E Thread 0: 152\n",
            "Thread 0: 154\n",
            "Thread 0: 156\n",
            "Thread 0: 158\n",
            "Thread 0: 159\n",
            "0.00.004.217 I Thread 0: 162\n",
            "Thread 0: 166\n",
            "0.00.004.218 E Thread 0: 167\n",
            "0.00.004.218 E Thread 0: 168\n",
            "0.00.004.219 E Thread 0: 169\n",
            "Thread 0: 170\n",
            "Thread 0: 171\n",
            "W Thread 0: 173\n",
            "E Thread 0: 174\n",
            "W Thread 0: 175\n",
            "Thread 0: 178\n",
            "Thread 0: 179\n",
            "Thread 0: 180\n",
            "I Thread 0: 181\n",
            "I Thread 0: 182\n",
            "W Thread 0: 183\n",
            "E Thread 0: 184\n",
            "Thread 0: 185\n",
            "Thread 0: 186\n",
            "Thread 0: 188\n",
            "Thread 0: 189\n",
            "Thread 0: 190\n",
            "Thread 0: 191\n",
            "Thread 0: 192\n",
            "Thread 0: 193\n",
            "0.00.004.231 E Thread 0: 194\n",
            "Thread 0: 195\n",
            "Thread 0: 196\n",
            "Thread 0: 197\n",
            "Thread 0: 198\n",
            "0.00.004.234 W Thread 0: 200\n",
            "0.00.004.235 W Thread 0: 201\n",
            "Thread 0: 202\n",
            "Thread 0: 204\n",
            "Thread 0: 205\n",
            "Thread 0: 206\n",
            "Thread 0: 207\n",
            "Thread 0: 208\n",
            "0.00.004.238 I Thread 0: 210\n",
            "0.00.004.239 I Thread 0: 211\n",
            "Thread 0: 212\n",
            "Thread 0: 213\n",
            "Thread 0: 214\n",
            "Thread 0: 215\n",
            "Thread 0: 216\n",
            "Thread 0: 217\n",
            "Thread 0: 218\n",
            "Thread 0: 219\n",
            "W Thread 0: 220\n",
            "Thread 0: 221\n",
            "Thread 0: 223\n",
            "0.00.004.246 W Thread 0: 225\n",
            "0.00.004.246 W Thread 0: 226\n",
            "0.00.004.247 I Thread 0: 227\n",
            "0.00.004.248 I Thread 0: 228\n",
            "Thread 0: 229\n",
            "Thread 0: 231\n",
            "Thread 0: 232\n",
            "E Thread 0: 233\n",
            "W Thread 0: 234\n",
            "Thread 0: 236\n",
            "Thread 0: 237\n",
            "W Thread 0: 239\n",
            "W Thread 0: 240\n",
            "I Thread 0: 242\n",
            "W Thread 0: 243\n",
            "E Thread 0: 244\n",
            "E Thread 0: 245\n",
            "E Thread 0: 246\n",
            "E Thread 0: 248\n",
            "Thread 0: 249\n",
            "Thread 0: 250\n",
            "0.00.004.257 E Thread 0: 251\n",
            "0.00.004.257 W Thread 0: 252\n",
            "0.00.004.258 E Thread 0: 255\n",
            "0.00.004.259 W Thread 0: 258\n",
            "0.00.004.260 W Thread 0: 259\n",
            "0.00.004.260 I Thread 0: 260\n",
            "Thread 0: 261\n",
            "Thread 0: 262\n",
            "0.00.004.262 W Thread 0: 263\n",
            "0.00.004.262 W Thread 0: 264\n",
            "Thread 0: 265\n",
            "Thread 0: 266\n",
            "Thread 0: 267\n",
            "W Thread 0: 268\n",
            "W Thread 0: 269\n",
            "Thread 0: 270\n",
            "Thread 0: 271\n",
            "W Thread 0: 273\n",
            "Thread 0: 275\n",
            "W Thread 0: 278\n",
            "I Thread 0: 282\n",
            "0.00.004.269 W Thread 0: 283\n",
            "Thread 0: 287\n",
            "Thread 0: 288\n",
            "W Thread 0: 289\n",
            "I Thread 0: 291\n",
            "E Thread 0: 292\n",
            "E Thread 0: 293\n",
            "E Thread 0: 294\n",
            "Thread 0: 297\n",
            "Thread 0: 298\n",
            "W Thread 0: 300\n",
            "Thread 0: 302\n",
            "Thread 0: 303\n",
            "Thread 0: 304\n",
            "Thread 0: 306\n",
            "Thread 0: 307\n",
            "Thread 0: 308\n",
            "Thread 0: 309\n",
            "Thread 0: 310\n",
            "I Thread 0: 311\n",
            "Thread 0: 312\n",
            "Thread 0: 313\n",
            "Thread 0: 315\n",
            "0.00.004.282 I Thread 0: 317\n",
            "Thread 0: 318\n",
            "Thread 0: 319\n",
            "Thread 0: 320\n",
            "Thread 0: 321\n",
            "0.00.004.285 E Thread 0: 322\n",
            "E Thread 0: 324\n",
            "Thread 0: 325\n",
            "0.00.004.286 I Thread 0: 326\n",
            "W Thread 0: 327\n",
            "W Thread 0: 328\n",
            "E Thread 0: 329\n",
            "Thread 0: 331\n",
            "Thread 0: 332\n",
            "Thread 0: 333\n",
            "0.00.004.290 W Thread 0: 334\n",
            "0.00.004.291 I Thread 0: 335\n",
            "I Thread 0: 336\n",
            "E Thread 0: 337\n",
            "W Thread 0: 338\n",
            "Thread 0: 340\n",
            "0.00.004.293 W Thread 0: 341\n",
            "Thread 0: 343\n",
            "0.00.004.295 W Thread 0: 345\n",
            "0.00.004.295 W Thread 0: 346\n",
            "0.00.004.296 W Thread 0: 347\n",
            "Thread 0: 348\n",
            "Thread 0: 349\n",
            "0.00.004.298 W Thread 0: 350\n",
            "I Thread 0: 353\n",
            "0.00.004.299 E Thread 0: 354\n",
            "0.00.004.300 I Thread 0: 356\n",
            "0.00.004.300 E Thread 0: 357\n",
            "Thread 0: 359\n",
            "Thread 0: 360\n",
            "Thread 0: 361\n",
            "Thread 0: 362\n",
            "Thread 0: 363\n",
            "Thread 0: 365\n",
            "0.00.004.304 E Thread 0: 367\n",
            "I Thread 0: 368\n",
            "I Thread 0: 369\n",
            "Thread 0: 371\n",
            "0.00.004.306 I Thread 0: 372\n",
            "Thread 0: 373\n",
            "Thread 0: 374\n",
            "Thread 0: 376\n",
            "Thread 0: 377\n",
            "Thread 0: 379\n",
            "Thread 0: 381\n",
            "Thread 0: 382\n",
            "0.00.004.312 E Thread 0: 385\n",
            "0.00.004.312 I Thread 0: 388\n",
            "0.00.004.313 I Thread 0: 389\n",
            "Thread 0: 392\n",
            "W Thread 0: 394\n",
            "Thread 0: 395\n",
            "Thread 0: 397\n",
            "Thread 0: 398\n",
            "Thread 0: 399\n",
            "W Thread 0: 400\n",
            "Thread 0: 401\n",
            "Thread 0: 402\n",
            "Thread 0: 403\n",
            "Thread 0: 404\n",
            "Thread 0: 406\n",
            "Thread 0: 407\n",
            "Thread 0: 408\n",
            "Thread 0: 409\n",
            "Thread 0: 410\n",
            "Thread 0: 411\n",
            "Thread 0: 413\n",
            "Thread 0: 415\n",
            "Thread 0: 416\n",
            "Thread 0: 418\n",
            "Thread 0: 419\n",
            "Thread 0: 420\n",
            "Thread 0: 421\n",
            "Thread 0: 422\n",
            "Thread 0: 423\n",
            "Thread 0: 424\n",
            "0.00.004.329 I Thread 0: 425\n",
            "Thread 0: 427\n",
            "Thread 0: 428\n",
            "0.00.004.330 W Thread 0: 429\n",
            "I Thread 0: 430\n",
            "W Thread 0: 431\n",
            "Thread 0: 432\n",
            "Thread 0: 434\n",
            "Thread 0: 435\n",
            "Thread 0: 438\n",
            "Thread 0: 439\n",
            "Thread 0: 440\n",
            "Thread 0: 441\n",
            "0.00.004.336 W Thread 0: 444\n",
            "Thread 0: 445\n",
            "Thread 0: 446\n",
            "Thread 0: 447\n",
            "Thread 0: 448\n",
            "Thread 0: 449\n",
            "Thread 0: 450\n",
            "0.00.004.340 W Thread 0: 452\n",
            "0.00.004.340 W Thread 0: 453\n",
            "Thread 0: 454\n",
            "Thread 0: 456\n",
            "E Thread 0: 457\n",
            "I Thread 0: 460\n",
            "E Thread 0: 461\n",
            "Thread 0: 463\n",
            "I Thread 0: 465\n",
            "I Thread 0: 467\n",
            "0.00.004.346 E Thread 0: 468\n",
            "0.00.004.346 E Thread 0: 469\n",
            "W Thread 0: 472\n",
            "0.00.004.348 E Thread 0: 473\n",
            "0.00.004.348 E Thread 0: 474\n",
            "0.00.004.349 W Thread 0: 475\n",
            "Thread 0: 476\n",
            "Thread 0: 477\n",
            "Thread 0: 478\n",
            "E Thread 0: 479\n",
            "E Thread 0: 482\n",
            "W Thread 0: 483\n",
            "I Thread 0: 484\n",
            "I Thread 0: 485\n",
            "Thread 0: 486\n",
            "Thread 0: 487\n",
            "Thread 0: 488\n",
            "Thread 0: 490\n",
            "0.00.004.356 W Thread 0: 491\n",
            "Thread 0: 492\n",
            "Thread 0: 493\n",
            "E Thread 0: 496\n",
            "W Thread 0: 497\n",
            "E Thread 0: 498\n",
            "Thread 0: 499\n",
            "Thread 0: 500\n",
            "Thread 0: 501\n",
            "Thread 0: 505\n",
            "Thread 0: 506\n",
            "Thread 0: 507\n",
            "Thread 0: 509\n",
            "0.00.004.364 W Thread 0: 510\n",
            "0.00.004.364 W Thread 0: 511\n",
            "0.00.004.365 W Thread 0: 512\n",
            "0.00.004.365 I Thread 0: 513\n",
            "0.00.004.366 I Thread 0: 514\n",
            "0.00.004.366 W Thread 0: 515\n",
            "Thread 0: 516\n",
            "Thread 0: 517\n",
            "Thread 0: 518\n",
            "Thread 0: 519\n",
            "Thread 0: 520\n",
            "Thread 0: 521\n",
            "E Thread 0: 522\n",
            "E Thread 0: 523\n",
            "Thread 0: 525\n",
            "Thread 0: 526\n",
            "Thread 0: 527\n",
            "Thread 0: 528\n",
            "W Thread 0: 529\n",
            "I Thread 0: 530\n",
            "I Thread 0: 531\n",
            "Thread 0: 533\n",
            "Thread 0: 535\n",
            "Thread 0: 536\n",
            "Thread 0: 537\n",
            "Thread 0: 539\n",
            "Thread 0: 540\n",
            "Thread 0: 541\n",
            "Thread 0: 542\n",
            "Thread 0: 543\n",
            "Thread 0: 544\n",
            "Thread 0: 545\n",
            "Thread 0: 546\n",
            "Thread 0: 547\n",
            "E Thread 0: 549\n",
            "W Thread 0: 550\n",
            "E Thread 0: 551\n",
            "Thread 0: 552\n",
            "Thread 0: 553\n",
            "Thread 0: 554\n",
            "Thread 0: 555\n",
            "Thread 0: 556\n",
            "Thread 0: 558\n",
            "I Thread 0: 560\n",
            "I Thread 0: 561\n",
            "W Thread 0: 562\n",
            "I Thread 0: 563\n",
            "E Thread 0: 564\n",
            "E Thread 0: 565\n",
            "0.00.004.390 W Thread 0: 566\n",
            "I Thread 0: 567\n",
            "Thread 0: 568\n",
            "Thread 0: 569\n",
            "Thread 0: 570\n",
            "W Thread 0: 571\n",
            "E Thread 0: 572\n",
            "W Thread 0: 573\n",
            "E Thread 0: 574\n",
            "I Thread 0: 575\n",
            "E Thread 0: 576\n",
            "E Thread 0: 577\n",
            "0.00.004.396 E Thread 0: 579\n",
            "0.00.004.397 I Thread 0: 582\n",
            "Thread 0: 583\n",
            "Thread 0: 587\n",
            "Thread 0: 589\n",
            "I Thread 0: 591\n",
            "Thread 0: 593\n",
            "Thread 0: 594\n",
            "Thread 0: 595\n",
            "Thread 0: 597\n",
            "Thread 0: 599\n",
            "Thread 0: 601\n",
            "Thread 0: 602\n",
            "Thread 0: 603\n",
            "Thread 0: 604\n",
            "Thread 0: 605\n",
            "Thread 0: 606\n",
            "Thread 0: 607\n",
            "0.00.004.407 W Thread 0: 608\n",
            "Thread 0: 610\n",
            "Thread 0: 611\n",
            "Thread 0: 612\n",
            "Thread 0: 613\n",
            "Thread 0: 614\n",
            "W Thread 0: 616\n",
            "Thread 0: 617\n",
            "0.00.004.412 E Thread 0: 619\n",
            "0.00.004.413 W Thread 0: 620\n",
            "E Thread 0: 621\n",
            "0.00.004.414 W Thread 0: 624\n",
            "Thread 0: 625\n",
            "Thread 0: 626\n",
            "Thread 0: 627\n",
            "0.00.004.417 E Thread 0: 629\n",
            "0.00.004.417 I Thread 0: 630\n",
            "Thread 0: 631\n",
            "Thread 0: 632\n",
            "Thread 0: 633\n",
            "Thread 0: 634\n",
            "Thread 0: 636\n",
            "Thread 0: 637\n",
            "I Thread 0: 640\n",
            "W Thread 0: 641\n",
            "E Thread 0: 642\n",
            "W Thread 0: 644\n",
            "Thread 0: 646\n",
            "0.00.004.424 I Thread 0: 648\n",
            "0.00.004.425 W Thread 0: 649\n",
            "0.00.004.425 I Thread 0: 651\n",
            "Thread 0: 652\n",
            "W Thread 0: 653\n",
            "Thread 0: 654\n",
            "Thread 0: 655\n",
            "Thread 0: 656\n",
            "0.00.004.429 I Thread 0: 657\n",
            "0.00.004.429 I Thread 0: 658\n",
            "W Thread 0: 659\n",
            "E Thread 0: 660\n",
            "0.00.004.431 E Thread 0: 662\n",
            "0.00.004.431 E Thread 0: 663\n",
            "0.00.004.432 E Thread 0: 664\n",
            "Thread 0: 667\n",
            "Thread 0: 668\n",
            "Thread 0: 670\n",
            "Thread 0: 671\n",
            "Thread 0: 672\n",
            "Thread 0: 673\n",
            "W Thread 0: 674\n",
            "Thread 0: 676\n",
            "Thread 0: 677\n",
            "0.00.004.438 I Thread 0: 679\n",
            "Thread 0: 680\n",
            "W Thread 0: 681\n",
            "0.00.004.440 W Thread 0: 682\n",
            "0.00.004.440 E Thread 0: 683\n",
            "Thread 0: 684\n",
            "Thread 0: 685\n",
            "Thread 0: 686\n",
            "Thread 0: 687\n",
            "Thread 0: 688\n",
            "E Thread 0: 690\n",
            "E Thread 0: 691\n",
            "Thread 0: 694\n",
            "Thread 0: 695\n",
            "Thread 0: 696\n",
            "Thread 0: 697\n",
            "Thread 0: 698\n",
            "Thread 0: 699\n",
            "0.00.004.448 I Thread 0: 701\n",
            "Thread 0: 703\n",
            "Thread 0: 705\n",
            "Thread 0: 706\n",
            "Thread 0: 707\n",
            "E Thread 0: 708\n",
            "0.00.004.451 I Thread 0: 709\n",
            "0.00.004.452 I Thread 0: 710\n",
            "0.00.004.452 W Thread 0: 711\n",
            "Thread 0: 712\n",
            "Thread 0: 713\n",
            "Thread 0: 715\n",
            "I Thread 0: 716\n",
            "E Thread 0: 718\n",
            "I Thread 0: 719\n",
            "Thread 0: 720\n",
            "Thread 0: 721\n",
            "Thread 0: 723\n",
            "0.00.004.458 E Thread 0: 724\n",
            "0.00.004.458 W Thread 0: 725\n",
            "I Thread 0: 726\n",
            "E Thread 0: 728\n",
            "0.00.004.460 I Thread 0: 730\n",
            "I Thread 0: 731\n",
            "Thread 0: 733\n",
            "Thread 0: 734\n",
            "0.00.004.462 E Thread 0: 737\n",
            "Thread 0: 738\n",
            "Thread 0: 739\n",
            "Thread 0: 740\n",
            "Thread 0: 741\n",
            "Thread 0: 742\n",
            "E Thread 0: 743\n",
            "I Thread 0: 745\n",
            "0.00.004.467 W Thread 0: 746\n",
            "0.00.004.467 W Thread 0: 747\n",
            "Thread 0: 749\n",
            "Thread 0: 750\n",
            "Thread 0: 751\n",
            "Thread 0: 752\n",
            "Thread 0: 753\n",
            "Thread 0: 754\n",
            "Thread 0: 755\n",
            "Thread 0: 756\n",
            "Thread 0: 758\n",
            "Thread 0: 759\n",
            "I Thread 0: 760\n",
            "W Thread 0: 761\n",
            "0.00.004.475 W Thread 0: 762\n",
            "0.00.004.475 W Thread 0: 763\n",
            "Thread 0: 764\n",
            "Thread 0: 765\n",
            "Thread 0: 766\n",
            "Thread 0: 767\n",
            "Thread 0: 768\n",
            "0.00.004.478 I Thread 0: 769\n",
            "0.00.004.479 I Thread 0: 770\n",
            "W Thread 0: 772\n",
            "E Thread 0: 773\n",
            "I Thread 0: 774\n",
            "Thread 0: 776\n",
            "Thread 0: 777\n",
            "E Thread 0: 778\n",
            "Thread 0: 781\n",
            "Thread 0: 782\n",
            "Thread 0: 783\n",
            "0.00.004.484 E Thread 0: 784\n",
            "0.00.004.485 I Thread 0: 785\n",
            "0.00.004.485 E Thread 0: 786\n",
            "0.00.004.486 W Thread 0: 787\n",
            "0.00.004.486 I Thread 0: 788\n",
            "0.00.004.487 I Thread 0: 789\n",
            "0.00.004.488 W Thread 0: 790\n",
            "Thread 0: 793\n",
            "W Thread 0: 794\n",
            "I Thread 0: 795\n",
            "E Thread 0: 796\n",
            "0.00.004.491 I Thread 0: 799\n",
            "Thread 0: 800\n",
            "Thread 0: 801\n",
            "Thread 0: 802\n",
            "Thread 0: 803\n",
            "Thread 0: 804\n",
            "I Thread 0: 806\n",
            "0.00.004.494 E Thread 0: 807\n",
            "W Thread 0: 809\n",
            "E Thread 0: 810\n",
            "E Thread 0: 811\n",
            "0.00.004.496 W Thread 0: 812\n",
            "W Thread 0: 813\n",
            "I Thread 0: 814\n",
            "E Thread 0: 816\n",
            "W Thread 0: 817\n",
            "E Thread 0: 818\n",
            "Thread 0: 819\n",
            "Thread 0: 820\n",
            "Thread 0: 821\n",
            "Thread 0: 822\n",
            "Thread 0: 824\n",
            "Thread 0: 825\n",
            "0.00.004.502 W Thread 0: 826\n",
            "E Thread 0: 827\n",
            "I Thread 0: 828\n",
            "I Thread 0: 829\n",
            "Thread 0: 830\n",
            "0.00.004.504 E Thread 0: 832\n",
            "0.00.004.505 E Thread 0: 833\n",
            "E Thread 0: 837\n",
            "I Thread 0: 838\n",
            "E Thread 0: 839\n",
            "W Thread 0: 840\n",
            "Thread 0: 842\n",
            "Thread 0: 844\n",
            "Thread 0: 846\n",
            "Thread 0: 847\n",
            "Thread 0: 848\n",
            "Thread 0: 849\n",
            "W Thread 0: 850\n",
            "Thread 0: 851\n",
            "Thread 0: 852\n",
            "Thread 0: 854\n",
            "W Thread 0: 855\n",
            "0.00.004.514 I Thread 0: 856\n",
            "0.00.004.514 W Thread 0: 857\n",
            "0.00.004.515 I Thread 0: 858\n",
            "0.00.004.515 I Thread 0: 859\n",
            "0.00.004.516 E Thread 0: 860\n",
            "0.00.004.516 W Thread 0: 861\n",
            "I Thread 0: 862\n",
            "I Thread 0: 863\n",
            "W Thread 0: 864\n",
            "Thread 0: 866\n",
            "Thread 0: 867\n",
            "0.00.004.519 I Thread 0: 869\n",
            "Thread 0: 871\n",
            "W Thread 0: 872\n",
            "I Thread 0: 873\n",
            "Thread 0: 874\n",
            "Thread 0: 875\n",
            "E Thread 0: 876\n",
            "I Thread 0: 877\n",
            "Thread 0: 878\n",
            "Thread 0: 879\n",
            "E Thread 0: 881\n",
            "I Thread 0: 882\n",
            "0.00.004.525 I Thread 0: 883\n",
            "0.00.004.525 E Thread 0: 884\n",
            "0.00.004.526 E Thread 0: 885\n",
            "0.00.004.526 E Thread 0: 886\n",
            "E Thread 0: 887\n",
            "W Thread 0: 888\n",
            "W Thread 0: 889\n",
            "I Thread 0: 890\n",
            "E Thread 0: 892\n",
            "Thread 0: 893\n",
            "Thread 0: 894\n",
            "Thread 0: 895\n",
            "0.00.004.529 W Thread 0: 896\n",
            "0.00.004.530 I Thread 0: 897\n",
            "Thread 0: 899\n",
            "Thread 0: 900\n",
            "Thread 0: 901\n",
            "Thread 0: 902\n",
            "Thread 0: 903\n",
            "Thread 0: 904\n",
            "Thread 0: 905\n",
            "Thread 0: 906\n",
            "Thread 0: 907\n",
            "Thread 0: 908\n",
            "E Thread 0: 910\n",
            "Thread 0: 912\n",
            "0.00.004.536 W Thread 0: 913\n",
            "Thread 0: 915\n",
            "E Thread 0: 916\n",
            "E Thread 0: 917\n",
            "W Thread 0: 919\n",
            "W Thread 0: 920\n",
            "Thread 0: 921\n",
            "Thread 0: 922\n",
            "Thread 0: 923\n",
            "0.00.004.541 E Thread 0: 924\n",
            "Thread 0: 925\n",
            "0.00.004.542 I Thread 0: 926\n",
            "0.00.004.543 I Thread 0: 928\n",
            "Thread 0: 931\n",
            "Thread 0: 932\n",
            "Thread 0: 933\n",
            "Thread 0: 934\n",
            "Thread 0: 935\n",
            "Thread 0: 937\n",
            "Thread 0: 938\n",
            "0.00.004.548 E Thread 0: 940\n",
            "0.00.004.548 W Thread 0: 942\n",
            "Thread 0: 943\n",
            "W Thread 0: 945\n",
            "I Thread 0: 946\n",
            "0.00.004.550 W Thread 0: 947\n",
            "0.00.004.551 I Thread 0: 948\n",
            "0.00.004.551 I Thread 0: 949\n",
            "0.00.004.552 E Thread 0: 950\n",
            "Thread 0: 952\n",
            "Thread 0: 953\n",
            "Thread 0: 954\n",
            "0.00.004.554 W Thread 0: 955\n",
            "E Thread 0: 956\n",
            "Thread 0: 957\n",
            "Thread 0: 958\n",
            "0.00.004.556 I Thread 0: 960\n",
            "0.00.004.557 W Thread 0: 961\n",
            "Thread 0: 962\n",
            "Thread 0: 963\n",
            "Thread 0: 964\n",
            "0.00.004.559 W Thread 0: 968\n",
            "0.00.004.560 W Thread 0: 969\n",
            "Thread 0: 970\n",
            "Thread 0: 972\n",
            "Thread 0: 974\n",
            "Thread 0: 975\n",
            "W Thread 0: 976\n",
            "Thread 0: 977\n",
            "Thread 0: 978\n",
            "Thread 0: 979\n",
            "Thread 0: 980\n",
            "Thread 0: 981\n",
            "Thread 0: 982\n",
            "0.00.004.566 W Thread 0: 984\n",
            "0.00.004.566 E Thread 0: 986\n",
            "0.00.004.567 W Thread 0: 987\n",
            "0.00.004.568 E Thread 0: 988\n",
            "0.00.004.568 E Thread 0: 989\n",
            "0.00.004.569 W Thread 0: 990\n",
            "0.00.004.569 W Thread 0: 991\n",
            "I Thread 0: 993\n",
            "E Thread 0: 994\n",
            "W Thread 0: 995\n",
            "W Thread 0: 998\n",
            "W Thread 0: 999\n",
            "E Thread 2: 0\n",
            "Thread 2: 1\n",
            "Thread 2: 2\n",
            "0.00.004.617 W Thread 2: 3\n",
            "Thread 2: 5\n",
            "I Thread 2: 6\n",
            "E Thread 2: 7\n",
            "I Thread 2: 8\n",
            "0.00.004.619 I Thread 2: 10\n",
            "0.00.004.620 W Thread 2: 13\n",
            "0.00.004.621 I Thread 2: 14\n",
            "0.00.004.621 E Thread 2: 17\n",
            "0.00.004.622 E Thread 2: 18\n",
            "Thread 2: 19\n",
            "0.00.004.623 I Thread 2: 22\n",
            "W Thread 2: 23\n",
            "I Thread 2: 24\n",
            "I Thread 2: 25\n",
            "Thread 2: 26\n",
            "0.00.004.626 I Thread 2: 31\n",
            "Thread 2: 36\n",
            "Thread 2: 37\n",
            "Thread 2: 38\n",
            "E Thread 2: 39\n",
            "E Thread 2: 43\n",
            "0.00.004.629 E Thread 2: 44\n",
            "W Thread 2: 47\n",
            "Thread 2: 48\n",
            "Thread 2: 49\n",
            "Thread 2: 51\n",
            "Thread 2: 52\n",
            "I Thread 2: 53\n",
            "Thread 2: 56\n",
            "Thread 2: 57\n",
            "Thread 2: 58\n",
            "Thread 2: 59\n",
            "Thread 2: 60\n",
            "Thread 2: 62\n",
            "Thread 2: 63\n",
            "E Thread 2: 64\n",
            "Thread 2: 65\n",
            "Thread 2: 66\n",
            "Thread 2: 67\n",
            "Thread 2: 68\n",
            "Thread 2: 69\n",
            "Thread 2: 70\n",
            "Thread 2: 71\n",
            "Thread 2: 72\n",
            "Thread 2: 73\n",
            "Thread 2: 78\n",
            "Thread 2: 79\n",
            "Thread 2: 80\n",
            "Thread 2: 81\n",
            "I Thread 2: 83\n",
            "E Thread 2: 84\n",
            "I Thread 2: 85\n",
            "E Thread 2: 86\n",
            "E Thread 2: 87\n",
            "Thread 2: 91\n",
            "E Thread 2: 92\n",
            "0.00.004.649 I Thread 2: 93\n",
            "0.00.004.649 W Thread 2: 94\n",
            "I Thread 2: 95\n",
            "Thread 2: 96\n",
            "E Thread 2: 97\n",
            "I Thread 2: 98\n",
            "I Thread 2: 101\n",
            "E Thread 2: 102\n",
            "0.00.004.653 E Thread 2: 104\n",
            "0.00.004.654 W Thread 2: 105\n",
            "Thread 2: 106\n",
            "I Thread 2: 107\n",
            "0.00.004.656 W Thread 2: 108\n",
            "0.00.004.656 I Thread 2: 110\n",
            "0.00.004.657 E Thread 2: 111\n",
            "Thread 2: 112\n",
            "Thread 2: 113\n",
            "Thread 2: 114\n",
            "Thread 2: 116\n",
            "Thread 2: 117\n",
            "Thread 2: 119\n",
            "I Thread 2: 120\n",
            "I Thread 2: 121\n",
            "I Thread 2: 124\n",
            "Thread 2: 125\n",
            "0.00.004.663 W Thread 2: 126\n",
            "W Thread 2: 128\n",
            "W Thread 2: 130\n",
            "I Thread 2: 131\n",
            "Thread 2: 132\n",
            "0.00.004.666 W Thread 2: 134\n",
            "Thread 2: 135\n",
            "Thread 2: 136\n",
            "E Thread 2: 137\n",
            "I Thread 2: 139\n",
            "E Thread 2: 140\n",
            "I Thread 2: 141\n",
            "Thread 2: 142\n",
            "Thread 2: 143\n",
            "Thread 2: 144\n",
            "0.00.004.671 I Thread 2: 145\n",
            "0.00.004.671 W Thread 2: 146\n",
            "Thread 2: 148\n",
            "W Thread 2: 149\n",
            "Thread 2: 150\n",
            "Thread 2: 152\n",
            "Thread 2: 153\n",
            "Thread 2: 154\n",
            "I Thread 2: 155\n",
            "Thread 2: 156\n",
            "0.00.004.676 W Thread 2: 157\n",
            "I Thread 2: 158\n",
            "0.00.004.677 W Thread 2: 159\n",
            "0.00.004.678 I Thread 2: 160\n",
            "Thread 2: 161\n",
            "0.00.004.679 I Thread 2: 164\n",
            "Thread 2: 165\n",
            "Thread 2: 166\n",
            "E Thread 2: 168\n",
            "W Thread 2: 169\n",
            "I Thread 2: 170\n",
            "I Thread 2: 171\n",
            "0.00.004.683 W Thread 2: 173\n",
            "0.00.004.684 I Thread 2: 175\n",
            "W Thread 2: 176\n",
            "Thread 2: 180\n",
            "Thread 2: 183\n",
            "0.00.004.687 W Thread 2: 184\n",
            "0.00.004.687 I Thread 2: 185\n",
            "Thread 2: 186\n",
            "Thread 2: 188\n",
            "E Thread 2: 189\n",
            "Thread 2: 191\n",
            "Thread 2: 192\n",
            "W Thread 2: 193\n",
            "0.00.004.691 W Thread 2: 195\n",
            "Thread 2: 196\n",
            "I Thread 2: 198\n",
            "W Thread 2: 200\n",
            "W Thread 2: 201\n",
            "Thread 2: 204\n",
            "Thread 2: 205\n",
            "Thread 2: 206\n",
            "E Thread 2: 207\n",
            "I Thread 2: 208\n",
            "Thread 2: 209\n",
            "Thread 2: 211\n",
            "Thread 2: 212\n",
            "Thread 2: 216\n",
            "W Thread 2: 218\n",
            "W Thread 2: 219\n",
            "Thread 2: 220\n",
            "0.00.004.702 E Thread 2: 223\n",
            "0.00.004.702 I Thread 2: 224\n",
            "0.00.004.703 W Thread 2: 225\n",
            "0.00.004.703 W Thread 2: 227\n",
            "Thread 2: 228\n",
            "0.00.004.704 I Thread 2: 229\n",
            "0.00.004.705 E Thread 2: 230\n",
            "0.00.004.705 W Thread 2: 231\n",
            "I Thread 2: 232\n",
            "0.00.004.707 W Thread 2: 234\n",
            "Thread 2: 235\n",
            "Thread 2: 236\n",
            "Thread 2: 237\n",
            "Thread 2: 238\n",
            "Thread 2: 239\n",
            "0.00.004.710 I Thread 2: 240\n",
            "0.00.004.710 W Thread 2: 241\n",
            "0.00.004.711 I Thread 2: 242\n",
            "0.00.004.711 W Thread 2: 243\n",
            "0.00.004.712 W Thread 2: 244\n",
            "Thread 2: 245\n",
            "Thread 2: 246\n",
            "Thread 2: 247\n",
            "E Thread 2: 248\n",
            "E Thread 2: 249\n",
            "W Thread 2: 250\n",
            "Thread 2: 253\n",
            "Thread 2: 254\n",
            "Thread 2: 255\n",
            "0.00.004.718 I Thread 2: 257\n",
            "0.00.004.718 I Thread 2: 258\n",
            "Thread 2: 260\n",
            "0.00.004.719 E Thread 2: 261\n",
            "0.00.004.720 E Thread 2: 262\n",
            "0.00.004.720 E Thread 2: 263\n",
            "0.00.004.721 E Thread 2: 264\n",
            "0.00.004.721 E Thread 2: 265\n",
            "0.00.004.722 I Thread 2: 266\n",
            "0.00.004.722 E Thread 2: 268\n",
            "0.00.004.723 W Thread 2: 269\n",
            "Thread 2: 270\n",
            "Thread 2: 271\n",
            "Thread 2: 272\n",
            "Thread 2: 274\n",
            "Thread 2: 275\n",
            "Thread 2: 276\n",
            "Thread 2: 277\n",
            "Thread 2: 278\n",
            "W Thread 2: 281\n",
            "Thread 2: 282\n",
            "0.00.004.729 I Thread 2: 283\n",
            "0.00.004.730 I Thread 2: 285\n",
            "Thread 2: 286\n",
            "Thread 2: 287\n",
            "Thread 2: 288\n",
            "Thread 2: 289\n",
            "Thread 2: 290\n",
            "Thread 2: 291\n",
            "Thread 2: 293\n",
            "I Thread 2: 294\n",
            "0.00.004.735 E Thread 2: 296\n",
            "0.00.004.735 I Thread 2: 297\n",
            "0.00.004.736 W Thread 2: 298\n",
            "Thread 2: 299\n",
            "Thread 2: 300\n",
            "Thread 2: 301\n",
            "0.00.004.738 E Thread 2: 302\n",
            "0.00.004.738 I Thread 2: 303\n",
            "W Thread 2: 304\n",
            "W Thread 2: 305\n",
            "E Thread 2: 307\n",
            "0.00.004.740 W Thread 2: 310\n",
            "0.00.004.741 E Thread 2: 312\n",
            "Thread 2: 313\n",
            "Thread 2: 315\n",
            "E Thread 2: 319\n",
            "E Thread 2: 320\n",
            "0.00.004.744 W Thread 2: 321\n",
            "0.00.004.745 I Thread 2: 322\n",
            "Thread 2: 324\n",
            "0.00.004.746 I Thread 2: 325\n",
            "0.00.004.746 I Thread 2: 327\n",
            "0.00.004.747 E Thread 2: 328\n",
            "Thread 2: 330\n",
            "Thread 2: 331\n",
            "Thread 2: 334\n",
            "E Thread 2: 335\n",
            "I Thread 2: 337\n",
            "0.00.004.751 I Thread 2: 338\n",
            "0.00.004.751 W Thread 2: 339\n",
            "0.00.004.752 E Thread 2: 341\n",
            "0.00.004.752 I Thread 2: 342\n",
            "0.00.004.753 E Thread 2: 344\n",
            "Thread 2: 345\n",
            "I Thread 2: 347\n",
            "Thread 2: 348\n",
            "Thread 2: 349\n",
            "Thread 2: 350\n",
            "Thread 2: 351\n",
            "Thread 2: 352\n",
            "Thread 2: 353\n",
            "Thread 2: 354\n",
            "Thread 2: 355\n",
            "Thread 2: 356\n",
            "Thread 2: 357\n",
            "I Thread 2: 359\n",
            "Thread 2: 360\n",
            "Thread 2: 363\n",
            "Thread 2: 364\n",
            "Thread 2: 366\n",
            "Thread 2: 367\n",
            "Thread 2: 368\n",
            "Thread 2: 369\n",
            "Thread 2: 370\n",
            "Thread 2: 372\n",
            "Thread 2: 373\n",
            "Thread 2: 374\n",
            "0.00.004.767 E Thread 2: 375\n",
            "0.00.004.767 E Thread 2: 376\n",
            "Thread 2: 377\n",
            "0.00.004.768 I Thread 2: 378\n",
            "Thread 2: 379\n",
            "Thread 2: 380\n",
            "Thread 2: 381\n",
            "Thread 2: 382\n",
            "Thread 2: 383\n",
            "Thread 2: 384\n",
            "Thread 2: 386\n",
            "Thread 2: 387\n",
            "Thread 2: 388\n",
            "E Thread 2: 392\n",
            "W Thread 2: 394\n",
            "0.00.004.775 E Thread 2: 395\n",
            "W Thread 2: 397\n",
            "I Thread 2: 398\n",
            "I Thread 2: 400\n",
            "E Thread 2: 401\n",
            "Thread 2: 402\n",
            "E Thread 2: 403\n",
            "W Thread 2: 404\n",
            "W Thread 2: 405\n",
            "I Thread 2: 406\n",
            "Thread 2: 408\n",
            "0.00.004.780 W Thread 2: 409\n",
            "Thread 2: 410\n",
            "Thread 2: 411\n",
            "Thread 2: 412\n",
            "Thread 3: 0\n",
            "Thread 3: 1\n",
            "Thread 3: 2\n",
            "Thread 3: 3\n",
            "Thread 3: 4\n",
            "Thread 3: 5\n",
            "Thread 3: 6\n",
            "Thread 4: 0\n",
            "Thread 4: 1\n",
            "Thread 4: 2\n",
            "Thread 4: 4\n",
            "0.00.008.222 W Thread 4: 6\n",
            "W Thread 4: 7\n",
            "Thread 4: 8\n",
            "Thread 4: 9\n",
            "Thread 4: 10\n",
            "Thread 4: 11\n",
            "Thread 4: 12\n",
            "Thread 4: 14\n",
            "0.00.008.227 E Thread 4: 15\n",
            "0.00.008.227 E Thread 4: 16\n",
            "0.00.008.228 W Thread 4: 17\n",
            "Thread 4: 18\n",
            "Thread 4: 19\n",
            "Thread 4: 20\n",
            "Thread 4: 21\n",
            "Thread 4: 22\n",
            "Thread 4: 23\n",
            "Thread 4: 24\n",
            "E Thread 4: 25\n",
            "E Thread 4: 26\n",
            "W Thread 4: 27\n",
            "W Thread 4: 28\n",
            "I Thread 4: 29\n",
            "I Thread 4: 30\n",
            "E Thread 4: 32\n",
            "I Thread 4: 33\n",
            "0.00.008.235 W Thread 4: 35\n",
            "0.00.008.242 E Thread 4: 39\n",
            "Thread 4: 41\n",
            "Thread 4: 42\n",
            "Thread 4: 43\n",
            "Thread 4: 45\n",
            "0.00.008.248 I Thread 4: 46\n",
            "E Thread 4: 50\n",
            "Thread 4: 52\n",
            "Thread 4: 54\n",
            "E Thread 4: 55\n",
            "E Thread 4: 56\n",
            "Thread 4: 57\n",
            "Thread 4: 59\n",
            "Thread 4: 60\n",
            "W Thread 4: 61\n",
            "W Thread 4: 63\n",
            "E Thread 4: 67\n",
            "0.00.008.258 I Thread 4: 68\n",
            "Thread 4: 69\n",
            "W Thread 4: 72\n",
            "Thread 4: 74\n",
            "Thread 4: 75\n",
            "Thread 4: 76\n",
            "Thread 4: 77\n",
            "Thread 4: 78\n",
            "Thread 4: 79\n",
            "Thread 3: 7\n",
            "Thread 3: 8\n",
            "Thread 3: 9\n",
            "Thread 3: 10\n",
            "E Thread 3: 11\n",
            "W Thread 3: 12\n",
            "Thread 4: 81\n",
            "Thread 4: 82\n",
            "Thread 4: 83\n",
            "Thread 4: 84\n",
            "Thread 4: 85\n",
            "Thread 4: 86\n",
            "Thread 4: 87\n",
            "Thread 4: 88\n",
            "Thread 4: 89\n",
            "Thread 4: 90\n",
            "0.00.008.283 E Thread 4: 91\n",
            "Thread 4: 92\n",
            "0.00.008.284 E Thread 4: 93\n",
            "0.00.008.285 I Thread 4: 94\n",
            "0.00.008.285 E Thread 4: 95\n",
            "W Thread 4: 96\n",
            "Thread 4: 97\n",
            "Thread 4: 98\n",
            "I Thread 4: 99\n",
            "I Thread 4: 100\n",
            "W Thread 4: 101\n",
            "W Thread 4: 102\n",
            "W Thread 4: 103\n",
            "Thread 4: 105\n",
            "Thread 4: 106\n",
            "Thread 3: 14\n",
            "I Thread 3: 15\n",
            "W Thread 3: 18\n",
            "Thread 3: 19\n",
            "Thread 4: 107\n",
            "Thread 3: 20\n",
            "Thread 3: 21\n",
            "Thread 3: 22\n",
            "Thread 3: 23\n",
            "Thread 3: 24\n",
            "Thread 3: 25\n",
            "Thread 3: 26\n",
            "Thread 3: 27\n",
            "Thread 3: 28\n",
            "0.00.008.312 I Thread 3: 30\n",
            "0.00.008.313 W Thread 3: 31\n",
            "Thread 3: 32\n",
            "Thread 4: 111\n",
            "0.00.008.317 I Thread 4: 112\n",
            "0.00.008.317 E Thread 4: 113\n",
            "Thread 4: 115\n",
            "E Thread 4: 116\n",
            "I Thread 4: 117\n",
            "W Thread 4: 118\n",
            "I Thread 4: 121\n",
            "W Thread 4: 122\n",
            "0.00.008.322 W Thread 4: 125\n",
            "Thread 4: 126\n",
            "Thread 4: 127\n",
            "Thread 4: 128\n",
            "E Thread 4: 129\n",
            "0.00.008.325 E Thread 4: 132\n",
            "W Thread 4: 135\n",
            "E Thread 4: 136\n",
            "E Thread 4: 139\n",
            "Thread 4: 140\n",
            "E Thread 4: 144\n",
            "Thread 4: 145\n",
            "Thread 4: 146\n",
            "Thread 4: 147\n",
            "Thread 4: 148\n",
            "0.00.008.337 W Thread 4: 150\n",
            "Thread 4: 151\n",
            "0.00.008.338 W Thread 4: 152\n",
            "0.00.008.339 W Thread 4: 153\n",
            "0.00.008.339 W Thread 4: 154\n",
            "0.00.008.340 I Thread 4: 155\n",
            "0.00.008.340 I Thread 4: 156\n",
            "Thread 4: 158\n",
            "Thread 4: 159\n",
            "Thread 4: 160\n",
            "Thread 4: 161\n",
            "Thread 4: 164\n",
            "E Thread 4: 166\n",
            "I Thread 4: 168\n",
            "E Thread 4: 169\n",
            "Thread 4: 170\n",
            "Thread 4: 171\n",
            "Thread 4: 172\n",
            "0.00.008.347 I Thread 4: 176\n",
            "Thread 4: 177\n",
            "I Thread 4: 179\n",
            "E Thread 4: 180\n",
            "0.00.008.350 W Thread 4: 181\n",
            "0.00.008.350 I Thread 4: 182\n",
            "0.00.008.351 W Thread 4: 183\n",
            "0.00.008.351 E Thread 4: 184\n",
            "W Thread 4: 186\n",
            "Thread 4: 189\n",
            "W Thread 4: 190\n",
            "Thread 4: 191\n",
            "Thread 4: 192\n",
            "0.00.008.355 W Thread 4: 193\n",
            "Thread 4: 195\n",
            "Thread 4: 196\n",
            "Thread 4: 197\n",
            "0.00.008.357 W Thread 4: 198\n",
            "0.00.008.358 I Thread 4: 199\n",
            "W Thread 4: 202\n",
            "W Thread 3: 33\n",
            "Thread 3: 35\n",
            "Thread 3: 36\n",
            "Thread 4: 203\n",
            "I Thread 4: 204\n",
            "I Thread 4: 205\n",
            "W Thread 4: 206\n",
            "I Thread 4: 208\n",
            "0.00.008.369 W Thread 4: 209\n",
            "Thread 4: 210\n",
            "Thread 4: 212\n",
            "Thread 4: 214\n",
            "Thread 4: 216\n",
            "Thread 4: 217\n",
            "I Thread 4: 219\n",
            "E Thread 4: 220\n",
            "I Thread 4: 221\n",
            "Thread 4: 222\n",
            "E Thread 4: 223\n",
            "E Thread 4: 224\n",
            "E Thread 4: 225\n",
            "I Thread 4: 227\n",
            "W Thread 4: 228\n",
            "I Thread 4: 229\n",
            "I Thread 3: 37\n",
            "Thread 3: 39\n",
            "Thread 3: 40\n",
            "Thread 4: 230\n",
            "Thread 4: 231\n",
            "W Thread 4: 232\n",
            "0.00.008.387 E Thread 4: 233\n",
            "I Thread 4: 236\n",
            "Thread 4: 237\n",
            "Thread 4: 238\n",
            "0.00.008.389 I Thread 4: 239\n",
            "0.00.008.390 I Thread 4: 240\n",
            "0.00.008.390 I Thread 4: 241\n",
            "0.00.008.390 I Thread 4: 242\n",
            "0.00.008.391 E Thread 4: 243\n",
            "I Thread 4: 245\n",
            "Thread 4: 246\n",
            "0.00.008.393 W Thread 4: 251\n",
            "0.00.008.394 I Thread 4: 252\n",
            "Thread 4: 256\n",
            "W Thread 4: 257\n",
            "E Thread 4: 258\n",
            "I Thread 4: 259\n",
            "E Thread 4: 260\n",
            "0.00.008.397 W Thread 4: 262\n",
            "Thread 4: 264\n",
            "Thread 4: 266\n",
            "Thread 4: 267\n",
            "Thread 4: 268\n",
            "Thread 4: 270\n",
            "Thread 4: 271\n",
            "Thread 4: 272\n",
            "Thread 4: 273\n",
            "0.00.008.404 W Thread 4: 275\n",
            "0.00.008.405 I Thread 4: 276\n",
            "Thread 4: 278\n",
            "Thread 4: 279\n",
            "Thread 4: 280\n",
            "Thread 4: 281\n",
            "0.00.008.408 E Thread 3: 41\n",
            "0.00.008.413 W Thread 3: 42\n",
            "Thread 3: 44\n",
            "Thread 4: 282\n",
            "0.00.008.417 E Thread 4: 285\n",
            "Thread 4: 287\n",
            "Thread 4: 289\n",
            "I Thread 4: 290\n",
            "I Thread 4: 291\n",
            "W Thread 4: 292\n",
            "E Thread 4: 293\n",
            "Thread 4: 294\n",
            "Thread 3: 45\n",
            "Thread 4: 295\n",
            "W Thread 4: 296\n",
            "Thread 4: 297\n",
            "W Thread 4: 298\n",
            "E Thread 4: 299\n",
            "Thread 4: 300\n",
            "0.00.008.429 E Thread 4: 301\n",
            "Thread 4: 304\n",
            "Thread 4: 305\n",
            "E Thread 4: 306\n",
            "I Thread 4: 307\n",
            "E Thread 4: 308\n",
            "E Thread 4: 309\n",
            "I Thread 4: 310\n",
            "I Thread 4: 313\n",
            "Thread 4: 315\n",
            "E Thread 4: 316\n",
            "Thread 4: 317\n",
            "Thread 4: 319\n",
            "Thread 4: 321\n",
            "0.00.008.437 I Thread 4: 322\n",
            "I Thread 4: 324\n",
            "W Thread 4: 325\n",
            "W Thread 4: 326\n",
            "Thread 4: 327\n",
            "Thread 4: 328\n",
            "Thread 3: 46\n",
            "W Thread 3: 47\n",
            "W Thread 3: 48\n",
            "I Thread 4: 329\n",
            "E Thread 4: 330\n",
            "E Thread 4: 331\n",
            "E Thread 4: 332\n",
            "I Thread 4: 333\n",
            "W Thread 4: 334\n",
            "I Thread 4: 335\n",
            "E Thread 4: 337\n",
            "Thread 4: 340\n",
            "Thread 4: 341\n",
            "Thread 3: 49\n",
            "Thread 3: 50\n",
            "0.00.008.459 E Thread 3: 52\n",
            "0.00.008.459 I Thread 4: 342\n",
            "Thread 4: 343\n",
            "Thread 4: 344\n",
            "Thread 4: 345\n",
            "W Thread 4: 346\n",
            "0.00.008.464 W Thread 4: 347\n",
            "Thread 4: 348\n",
            "0.00.008.465 I Thread 4: 349\n",
            "0.00.008.466 E Thread 4: 350\n",
            "0.00.008.466 W Thread 4: 351\n",
            "0.00.008.466 W Thread 4: 352\n",
            "I Thread 4: 353\n",
            "W Thread 4: 354\n",
            "Thread 4: 355\n",
            "Thread 4: 356\n",
            "0.00.008.469 W Thread 4: 358\n",
            "Thread 4: 359\n",
            "Thread 4: 360\n",
            "Thread 4: 361\n",
            "Thread 4: 363\n",
            "Thread 4: 364\n",
            "Thread 4: 365\n",
            "W Thread 4: 366\n",
            "E Thread 4: 368\n",
            "Thread 4: 370\n",
            "Thread 4: 371\n",
            "Thread 4: 372\n",
            "0.00.008.475 W Thread 4: 373\n",
            "0.00.008.478 I Thread 4: 374\n",
            "0.00.008.478 I Thread 4: 376\n",
            "0.00.008.479 W Thread 4: 377\n",
            "0.00.008.479 I Thread 4: 378\n",
            "0.00.008.480 E Thread 4: 379\n",
            "Thread 4: 380\n",
            "Thread 4: 381\n",
            "Thread 4: 382\n",
            "Thread 4: 383\n",
            "Thread 3: 53\n",
            "I Thread 3: 54\n",
            "0.00.008.487 W Thread 3: 55\n",
            "0.00.008.488 I Thread 3: 56\n",
            "0.00.008.489 E Thread 3: 57\n",
            "0.00.008.493 I Thread 3: 58\n",
            "0.00.008.493 W Thread 3: 59\n",
            "I Thread 3: 61\n",
            "E Thread 4: 385\n",
            "I Thread 4: 386\n",
            "E Thread 4: 387\n",
            "0.00.008.499 I Thread 4: 388\n",
            "0.00.008.499 W Thread 4: 389\n",
            "E Thread 4: 390\n",
            "0.00.008.500 W Thread 4: 391\n",
            "0.00.008.501 W Thread 4: 393\n",
            "I Thread 4: 395\n",
            "0.00.008.503 I Thread 4: 397\n",
            "0.00.008.503 E Thread 4: 399\n",
            "0.00.008.504 E Thread 4: 402\n",
            "0.00.008.505 W Thread 4: 403\n",
            "0.00.008.505 E Thread 4: 404\n",
            "0.00.008.506 E Thread 4: 405\n",
            "0.00.008.506 W Thread 4: 406\n",
            "Thread 4: 407\n",
            "Thread 4: 408\n",
            "W Thread 4: 409\n",
            "E Thread 4: 411\n",
            "E Thread 4: 412\n",
            "Thread 4: 413\n",
            "Thread 4: 414\n",
            "Thread 4: 415\n",
            "0.00.008.511 I Thread 4: 416\n",
            "0.00.008.513 E Thread 3: 63\n",
            "0.00.008.518 I Thread 3: 64\n",
            "Thread 3: 65\n",
            "Thread 4: 417\n",
            "Thread 4: 418\n",
            "I Thread 4: 419\n",
            "E Thread 4: 420\n",
            "W Thread 4: 422\n",
            "I Thread 4: 423\n",
            "I Thread 4: 424\n",
            "W Thread 4: 425\n",
            "Thread 4: 426\n",
            "Thread 4: 427\n",
            "Thread 4: 428\n",
            "E Thread 4: 430\n",
            "Thread 4: 431\n",
            "Thread 4: 432\n",
            "Thread 4: 433\n",
            "E Thread 4: 434\n",
            "I Thread 4: 437\n",
            "Thread 4: 438\n",
            "Thread 4: 440\n",
            "Thread 4: 441\n",
            "Thread 4: 442\n",
            "Thread 4: 443\n",
            "Thread 4: 444\n",
            "E Thread 4: 445\n",
            "W Thread 4: 447\n",
            "0.00.008.544 I Thread 4: 448\n",
            "Thread 4: 449\n",
            "Thread 4: 450\n",
            "E Thread 4: 452\n",
            "I Thread 4: 453\n",
            "Thread 4: 454\n",
            "Thread 4: 455\n",
            "Thread 4: 456\n",
            "Thread 4: 457\n",
            "Thread 4: 458\n",
            "Thread 4: 459\n",
            "Thread 4: 460\n",
            "Thread 4: 462\n",
            "Thread 4: 463\n",
            "0.00.008.552 I Thread 4: 464\n",
            "Thread 4: 466\n",
            "Thread 4: 467\n",
            "Thread 4: 468\n",
            "Thread 4: 471\n",
            "Thread 4: 472\n",
            "Thread 4: 473\n",
            "Thread 4: 475\n",
            "Thread 4: 477\n",
            "Thread 4: 478\n",
            "E Thread 4: 481\n",
            "W Thread 4: 484\n",
            "I Thread 4: 485\n",
            "E Thread 4: 486\n",
            "Thread 4: 488\n",
            "Thread 4: 489\n",
            "Thread 4: 490\n",
            "Thread 4: 491\n",
            "Thread 4: 492\n",
            "Thread 4: 493\n",
            "Thread 4: 495\n",
            "Thread 4: 496\n",
            "E Thread 4: 497\n",
            "Thread 4: 498\n",
            "Thread 4: 499\n",
            "Thread 3: 66\n",
            "Thread 3: 67\n",
            "Thread 3: 68\n",
            "Thread 4: 500\n",
            "Thread 4: 501\n",
            "Thread 4: 502\n",
            "Thread 4: 504\n",
            "Thread 4: 507\n",
            "W Thread 4: 510\n",
            "Thread 4: 512\n",
            "Thread 4: 513\n",
            "Thread 4: 514\n",
            "Thread 4: 515\n",
            "Thread 4: 516\n",
            "Thread 4: 517\n",
            "Thread 4: 519\n",
            "Thread 4: 523\n",
            "0.00.008.584 I Thread 4: 524\n",
            "0.00.008.585 I Thread 4: 525\n",
            "Thread 4: 528\n",
            "Thread 4: 530\n",
            "Thread 4: 531\n",
            "Thread 4: 532\n",
            "0.00.008.588 W Thread 4: 534\n",
            "Thread 4: 535\n",
            "Thread 4: 536\n",
            "Thread 4: 537\n",
            "W Thread 4: 539\n",
            "Thread 4: 540\n",
            "Thread 4: 541\n",
            "Thread 4: 542\n",
            "Thread 4: 543\n",
            "Thread 4: 544\n",
            "Thread 4: 545\n",
            "Thread 4: 546\n",
            "Thread 4: 547\n",
            "Thread 4: 548\n",
            "Thread 4: 549\n",
            "Thread 4: 550\n",
            "Thread 4: 551\n",
            "Thread 4: 552\n",
            "Thread 3: 69\n",
            "Thread 4: 553\n",
            "0.00.008.602 W Thread 4: 554\n",
            "Thread 4: 555\n",
            "Thread 4: 556\n",
            "Thread 4: 557\n",
            "Thread 4: 558\n",
            "Thread 4: 560\n",
            "W Thread 4: 561\n",
            "Thread 4: 562\n",
            "E Thread 4: 563\n",
            "W Thread 4: 564\n",
            "0.00.008.609 E Thread 3: 71\n",
            "0.00.008.610 W Thread 3: 72\n",
            "0.00.008.611 W Thread 4: 565\n",
            "0.00.008.613 E Thread 4: 566\n",
            "0.00.008.613 W Thread 4: 567\n",
            "0.00.008.614 E Thread 4: 569\n",
            "E Thread 4: 573\n",
            "Thread 4: 574\n",
            "Thread 4: 576\n",
            "Thread 4: 577\n",
            "Thread 4: 578\n",
            "W Thread 4: 580\n",
            "I Thread 4: 581\n",
            "E Thread 4: 582\n",
            "Thread 4: 583\n",
            "Thread 4: 584\n",
            "Thread 4: 585\n",
            "0.00.008.623 W Thread 4: 586\n",
            "E Thread 3: 73\n",
            "Thread 3: 74\n",
            "Thread 3: 75\n",
            "E Thread 3: 76\n",
            "E Thread 4: 591\n",
            "Thread 4: 592\n",
            "Thread 4: 593\n",
            "Thread 4: 594\n",
            "Thread 4: 595\n",
            "0.00.008.635 W Thread 4: 598\n",
            "0.00.008.635 I Thread 4: 599\n",
            "0.00.008.635 W Thread 4: 600\n",
            "0.00.008.636 E Thread 4: 601\n",
            "0.00.008.636 I Thread 4: 602\n",
            "0.00.008.637 E Thread 4: 603\n",
            "0.00.008.638 W Thread 4: 604\n",
            "W Thread 4: 605\n",
            "I Thread 4: 606\n",
            "W Thread 4: 607\n",
            "Thread 4: 608\n",
            "W Thread 4: 609\n",
            "E Thread 4: 610\n",
            "W Thread 4: 612\n",
            "Thread 4: 613\n",
            "E Thread 4: 615\n",
            "E Thread 4: 616\n",
            "E Thread 4: 617\n",
            "Thread 4: 618\n",
            "0.00.008.644 W Thread 4: 619\n",
            "0.00.008.645 E Thread 3: 77\n",
            "0.00.008.649 W Thread 3: 78\n",
            "Thread 3: 79\n",
            "Thread 4: 621\n",
            "Thread 4: 622\n",
            "Thread 4: 623\n",
            "Thread 4: 625\n",
            "Thread 4: 626\n",
            "W Thread 4: 628\n",
            "Thread 4: 631\n",
            "Thread 4: 632\n",
            "Thread 4: 633\n",
            "I Thread 4: 635\n",
            "0.00.008.658 E Thread 4: 636\n",
            "0.00.008.658 W Thread 4: 637\n",
            "Thread 4: 638\n",
            "Thread 4: 639\n",
            "Thread 4: 640\n",
            "I Thread 4: 641\n",
            "E Thread 4: 643\n",
            "Thread 4: 644\n",
            "0.00.008.662 E Thread 4: 645\n",
            "0.00.008.662 I Thread 4: 646\n",
            "E Thread 4: 647\n",
            "0.00.008.663 W Thread 4: 648\n",
            "I Thread 4: 650\n",
            "I Thread 4: 651\n",
            "I Thread 4: 652\n",
            "0.00.008.665 W Thread 3: 80\n",
            "Thread 3: 83\n",
            "0.00.008.670 I Thread 3: 84\n",
            "0.00.008.674 W Thread 3: 85\n",
            "0.00.008.674 W Thread 3: 86\n",
            "0.00.008.675 E Thread 3: 87\n",
            "0.00.008.678 E Thread 3: 88\n",
            "Thread 3: 90\n",
            "Thread 3: 91\n",
            "0.00.008.680 E Thread 3: 92\n",
            "0.00.008.681 I Thread 4: 653\n",
            "Thread 4: 654\n",
            "Thread 4: 655\n",
            "W Thread 4: 656\n",
            "E Thread 4: 657\n",
            "I Thread 4: 660\n",
            "E Thread 4: 661\n",
            "W Thread 4: 663\n",
            "I Thread 4: 664\n",
            "0.00.008.687 I Thread 4: 665\n",
            "Thread 4: 666\n",
            "Thread 4: 667\n",
            "0.00.008.689 W Thread 4: 668\n",
            "Thread 4: 669\n",
            "W Thread 4: 676\n",
            "Thread 4: 677\n",
            "0.00.008.692 E Thread 4: 678\n",
            "E Thread 4: 679\n",
            "I Thread 4: 680\n",
            "I Thread 4: 681\n",
            "I Thread 4: 682\n",
            "E Thread 4: 683\n",
            "Thread 4: 684\n",
            "Thread 4: 685\n",
            "Thread 4: 686\n",
            "Thread 4: 687\n",
            "Thread 4: 691\n",
            "Thread 4: 692\n",
            "Thread 4: 693\n",
            "W Thread 4: 694\n",
            "0.00.008.700 E Thread 4: 695\n",
            "0.00.008.700 W Thread 4: 696\n",
            "Thread 4: 698\n",
            "Thread 4: 699\n",
            "Thread 4: 700\n",
            "0.00.008.703 E Thread 4: 701\n",
            "W Thread 4: 702\n",
            "E Thread 4: 703\n",
            "Thread 4: 705\n",
            "0.00.008.705 W Thread 4: 707\n",
            "0.00.008.705 I Thread 4: 708\n",
            "0.00.008.706 E Thread 4: 709\n",
            "0.00.008.706 E Thread 4: 710\n",
            "E Thread 4: 712\n",
            "W Thread 4: 713\n",
            "Thread 4: 714\n",
            "Thread 4: 715\n",
            "Thread 4: 716\n",
            "Thread 4: 719\n",
            "Thread 4: 721\n",
            "Thread 4: 722\n",
            "Thread 4: 723\n",
            "0.00.008.712 W Thread 4: 724\n",
            "0.00.008.713 W Thread 4: 725\n",
            "W Thread 4: 726\n",
            "0.00.008.714 W Thread 4: 727\n",
            "I Thread 4: 728\n",
            "W Thread 4: 729\n",
            "E Thread 4: 730\n",
            "I Thread 4: 731\n",
            "Thread 4: 732\n",
            "Thread 4: 733\n",
            "Thread 4: 734\n",
            "W Thread 4: 735\n",
            "E Thread 4: 737\n",
            "W Thread 3: 93\n",
            "W Thread 3: 94\n",
            "I Thread 3: 95\n",
            "E Thread 4: 738\n",
            "I Thread 4: 739\n",
            "Thread 4: 740\n",
            "W Thread 4: 742\n",
            "W Thread 4: 743\n",
            "W Thread 4: 744\n",
            "0.00.008.732 E Thread 4: 745\n",
            "0.00.008.732 E Thread 4: 746\n",
            "0.00.008.733 W Thread 4: 747\n",
            "0.00.008.735 I Thread 3: 96\n",
            "0.00.008.739 I Thread 3: 97\n",
            "Thread 3: 98\n",
            "Thread 4: 748\n",
            "Thread 4: 749\n",
            "Thread 4: 750\n",
            "Thread 4: 751\n",
            "W Thread 4: 754\n",
            "W Thread 4: 755\n",
            "E Thread 4: 757\n",
            "W Thread 4: 758\n",
            "E Thread 4: 759\n",
            "W Thread 4: 761\n",
            "Thread 4: 764\n",
            "Thread 4: 765\n",
            "Thread 4: 766\n",
            "Thread 4: 767\n",
            "0.00.008.750 W Thread 4: 768\n",
            "0.00.008.751 E Thread 4: 770\n",
            "I Thread 4: 771\n",
            "I Thread 4: 772\n",
            "Thread 4: 773\n",
            "0.00.008.753 I Thread 4: 774\n",
            "Thread 4: 775\n",
            "0.00.008.754 E Thread 4: 776\n",
            "0.00.008.755 E Thread 4: 777\n",
            "0.00.008.755 W Thread 4: 778\n",
            "Thread 4: 780\n",
            "Thread 4: 781\n",
            "Thread 4: 782\n",
            "Thread 4: 783\n",
            "Thread 4: 785\n",
            "E Thread 4: 787\n",
            "W Thread 4: 788\n",
            "W Thread 4: 789\n",
            "Thread 4: 790\n",
            "W Thread 4: 791\n",
            "0.00.008.762 I Thread 4: 792\n",
            "0.00.008.764 W Thread 4: 793\n",
            "Thread 4: 795\n",
            "Thread 4: 796\n",
            "Thread 4: 797\n",
            "Thread 4: 798\n",
            "Thread 4: 799\n",
            "Thread 4: 800\n",
            "Thread 4: 801\n",
            "Thread 3: 100\n",
            "Thread 3: 101\n",
            "Thread 3: 102\n",
            "Thread 4: 802\n",
            "I Thread 4: 803\n",
            "W Thread 4: 806\n",
            "W Thread 4: 807\n",
            "W Thread 4: 808\n",
            "Thread 4: 809\n",
            "Thread 4: 810\n",
            "Thread 4: 812\n",
            "Thread 3: 103\n",
            "W Thread 4: 814\n",
            "I Thread 4: 816\n",
            "I Thread 4: 817\n",
            "W Thread 4: 818\n",
            "W Thread 4: 819\n",
            "W Thread 4: 821\n",
            "0.00.008.788 W Thread 4: 822\n",
            "0.00.008.788 E Thread 4: 823\n",
            "0.00.008.789 W Thread 4: 824\n",
            "I Thread 3: 106\n",
            "E Thread 3: 107\n",
            "Thread 3: 109\n",
            "Thread 3: 110\n",
            "E Thread 4: 825\n",
            "Thread 4: 826\n",
            "0.00.008.800 E Thread 4: 827\n",
            "E Thread 4: 828\n",
            "W Thread 4: 829\n",
            "Thread 4: 830\n",
            "Thread 4: 831\n",
            "Thread 4: 832\n",
            "Thread 4: 833\n",
            "Thread 4: 834\n",
            "Thread 4: 835\n",
            "Thread 4: 836\n",
            "Thread 4: 837\n",
            "Thread 4: 838\n",
            "0.00.008.807 I Thread 4: 839\n",
            "Thread 4: 840\n",
            "Thread 4: 841\n",
            "Thread 4: 842\n",
            "Thread 4: 843\n",
            "Thread 4: 844\n",
            "Thread 4: 846\n",
            "Thread 4: 847\n",
            "I Thread 4: 848\n",
            "0.00.008.812 I Thread 4: 849\n",
            "E Thread 4: 851\n",
            "W Thread 4: 852\n",
            "I Thread 4: 853\n",
            "E Thread 4: 854\n",
            "I Thread 4: 858\n",
            "I Thread 4: 859\n",
            "W Thread 4: 860\n",
            "W Thread 4: 861\n",
            "E Thread 3: 113\n",
            "E Thread 4: 862\n",
            "E Thread 4: 863\n",
            "Thread 4: 865\n",
            "Thread 4: 866\n",
            "I Thread 4: 867\n",
            "E Thread 4: 868\n",
            "Thread 4: 869\n",
            "Thread 4: 870\n",
            "Thread 4: 871\n",
            "Thread 4: 873\n",
            "Thread 4: 874\n",
            "W Thread 4: 875\n",
            "E Thread 3: 114\n",
            "0.00.008.828 I Thread 3: 115\n",
            "Thread 3: 116\n",
            "Thread 3: 117\n",
            "0.00.008.833 I Thread 3: 118\n",
            "0.00.008.834 I Thread 4: 876\n",
            "0.00.008.836 W Thread 4: 877\n",
            "0.00.008.837 E Thread 4: 878\n",
            "Thread 4: 879\n",
            "Thread 4: 880\n",
            "Thread 4: 881\n",
            "I Thread 4: 882\n",
            "E Thread 4: 883\n",
            "Thread 4: 884\n",
            "Thread 4: 885\n",
            "Thread 4: 886\n",
            "W Thread 4: 887\n",
            "E Thread 4: 889\n",
            "Thread 4: 891\n",
            "Thread 3: 119\n",
            "Thread 4: 893\n",
            "Thread 4: 894\n",
            "E Thread 4: 895\n",
            "E Thread 4: 896\n",
            "0.00.008.850 E Thread 4: 898\n",
            "0.00.008.851 W Thread 4: 899\n",
            "0.00.008.851 W Thread 4: 900\n",
            "E Thread 4: 901\n",
            "W Thread 3: 120\n",
            "E Thread 4: 902\n",
            "I Thread 4: 903\n",
            "Thread 4: 904\n",
            "Thread 4: 905\n",
            "Thread 4: 906\n",
            "Thread 4: 907\n",
            "Thread 4: 908\n",
            "Thread 4: 909\n",
            "Thread 4: 910\n",
            "Thread 4: 911\n",
            "Thread 4: 913\n",
            "Thread 4: 914\n",
            "0.00.008.862 E Thread 4: 915\n",
            "0.00.008.862 W Thread 4: 916\n",
            "Thread 4: 917\n",
            "I Thread 4: 919\n",
            "W Thread 4: 920\n",
            "W Thread 3: 121\n",
            "I Thread 4: 921\n",
            "W Thread 4: 922\n",
            "I Thread 4: 923\n",
            "Thread 4: 925\n",
            "Thread 4: 926\n",
            "Thread 4: 927\n",
            "Thread 4: 928\n",
            "Thread 4: 930\n",
            "Thread 4: 931\n",
            "E Thread 4: 932\n",
            "I Thread 4: 933\n",
            "0.00.008.873 I Thread 4: 934\n",
            "0.00.008.874 W Thread 4: 936\n",
            "0.00.008.874 W Thread 4: 937\n",
            "0.00.008.875 W Thread 4: 938\n",
            "Thread 4: 939\n",
            "0.00.008.876 E Thread 4: 940\n",
            "I Thread 4: 942\n",
            "I Thread 4: 943\n",
            "0.00.008.879 E Thread 4: 944\n",
            "0.00.008.880 W Thread 4: 946\n",
            "Thread 4: 947\n",
            "0.00.008.881 E Thread 4: 948\n",
            "0.00.008.882 W Thread 4: 949\n",
            "Thread 4: 950\n",
            "0.00.008.883 E Thread 4: 952\n",
            "Thread 4: 953\n",
            "Thread 3: 122\n",
            "Thread 3: 124\n",
            "E Thread 3: 125\n",
            "I Thread 4: 954\n",
            "0.00.008.892 W Thread 4: 955\n",
            "I Thread 4: 956\n",
            "Thread 4: 958\n",
            "Thread 4: 959\n",
            "W Thread 4: 961\n",
            "0.00.008.895 I Thread 4: 966\n",
            "Thread 4: 967\n",
            "Thread 4: 968\n",
            "Thread 4: 969\n",
            "Thread 4: 970\n",
            "W Thread 4: 971\n",
            "I Thread 4: 972\n",
            "I Thread 4: 974\n",
            "I Thread 4: 975\n",
            "W Thread 4: 977\n",
            "I Thread 4: 978\n",
            "Thread 4: 979\n",
            "E Thread 4: 981\n",
            "E Thread 4: 982\n",
            "Thread 4: 984\n",
            "Thread 4: 985\n",
            "Thread 4: 986\n",
            "Thread 4: 987\n",
            "0.00.008.907 I Thread 4: 989\n",
            "Thread 4: 991\n",
            "Thread 4: 992\n",
            "Thread 4: 993\n",
            "Thread 4: 994\n",
            "Thread 4: 996\n",
            "Thread 4: 997\n",
            "Thread 4: 998\n",
            "Thread 3: 127\n",
            "0.00.008.917 E Thread 3: 129\n",
            "0.00.008.917 I Thread 3: 130\n",
            "0.00.008.918 E Thread 3: 131\n",
            "Thread 3: 132\n",
            "Thread 3: 134\n",
            "Thread 3: 136\n",
            "0.00.008.920 I Thread 3: 137\n",
            "Thread 3: 139\n",
            "Thread 3: 140\n",
            "Thread 3: 141\n",
            "Thread 3: 142\n",
            "W Thread 3: 144\n",
            "W Thread 3: 145\n",
            "I Thread 3: 146\n",
            "Thread 3: 147\n",
            "W Thread 3: 149\n",
            "Thread 3: 150\n",
            "Thread 3: 151\n",
            "Thread 3: 152\n",
            "Thread 3: 153\n",
            "Thread 3: 154\n",
            "Thread 3: 155\n",
            "Thread 3: 156\n",
            "Thread 3: 157\n",
            "Thread 3: 158\n",
            "Thread 3: 159\n",
            "Thread 3: 160\n",
            "0.00.008.929 I Thread 3: 161\n",
            "Thread 3: 164\n",
            "Thread 3: 165\n",
            "W Thread 3: 168\n",
            "W Thread 3: 169\n",
            "E Thread 3: 170\n",
            "E Thread 3: 171\n",
            "Thread 3: 173\n",
            "Thread 3: 174\n",
            "Thread 3: 175\n",
            "0.00.008.934 I Thread 3: 176\n",
            "0.00.008.934 E Thread 3: 177\n",
            "Thread 3: 178\n",
            "0.00.008.935 I Thread 3: 179\n",
            "Thread 3: 180\n",
            "Thread 3: 181\n",
            "0.00.008.937 I Thread 3: 183\n",
            "0.00.008.937 W Thread 3: 184\n",
            "0.00.008.938 E Thread 3: 185\n",
            "0.00.008.938 W Thread 3: 186\n",
            "0.00.008.939 E Thread 3: 187\n",
            "0.00.008.939 E Thread 3: 189\n",
            "0.00.008.940 W Thread 3: 190\n",
            "0.00.008.940 W Thread 3: 191\n",
            "Thread 3: 192\n",
            "E Thread 3: 195\n",
            "0.00.008.942 W Thread 3: 197\n",
            "0.00.008.942 W Thread 3: 198\n",
            "0.00.008.943 E Thread 3: 199\n",
            "0.00.008.943 I Thread 3: 200\n",
            "W Thread 3: 201\n",
            "Thread 3: 204\n",
            "I Thread 3: 205\n",
            "W Thread 3: 206\n",
            "W Thread 3: 207\n",
            "Thread 3: 208\n",
            "Thread 3: 209\n",
            "Thread 3: 210\n",
            "I Thread 3: 211\n",
            "Thread 3: 213\n",
            "Thread 3: 214\n",
            "Thread 3: 215\n",
            "0.00.008.949 W Thread 3: 216\n",
            "0.00.008.950 W Thread 3: 217\n",
            "0.00.008.950 W Thread 3: 218\n",
            "0.00.008.951 W Thread 3: 219\n",
            "0.00.008.951 I Thread 3: 220\n",
            "0.00.008.951 E Thread 3: 221\n",
            "Thread 3: 222\n",
            "Thread 3: 223\n",
            "Thread 3: 224\n",
            "Thread 3: 226\n",
            "Thread 3: 227\n",
            "Thread 3: 228\n",
            "Thread 3: 229\n",
            "Thread 3: 230\n",
            "Thread 3: 231\n",
            "Thread 3: 233\n",
            "Thread 3: 234\n",
            "Thread 3: 235\n",
            "Thread 3: 236\n",
            "Thread 3: 237\n",
            "0.00.008.959 I Thread 3: 238\n",
            "0.00.008.959 E Thread 3: 239\n",
            "0.00.008.960 E Thread 3: 240\n",
            "E Thread 3: 241\n",
            "Thread 3: 242\n",
            "Thread 3: 243\n",
            "Thread 3: 244\n",
            "Thread 3: 245\n",
            "Thread 3: 246\n",
            "Thread 3: 247\n",
            "Thread 3: 248\n",
            "Thread 3: 249\n",
            "Thread 3: 250\n",
            "Thread 3: 252\n",
            "Thread 3: 254\n",
            "Thread 3: 255\n",
            "Thread 3: 256\n",
            "Thread 3: 258\n",
            "0.00.008.967 I Thread 3: 259\n",
            "Thread 3: 260\n",
            "Thread 3: 263\n",
            "0.00.008.969 W Thread 3: 264\n",
            "0.00.008.969 W Thread 3: 265\n",
            "Thread 3: 266\n",
            "Thread 3: 267\n",
            "Thread 3: 268\n",
            "Thread 3: 269\n",
            "Thread 3: 270\n",
            "W Thread 3: 272\n",
            "E Thread 3: 273\n",
            "I Thread 3: 275\n",
            "Thread 3: 277\n",
            "Thread 3: 278\n",
            "Thread 3: 279\n",
            "Thread 3: 280\n",
            "0.00.008.976 E Thread 3: 283\n",
            "0.00.008.977 W Thread 3: 284\n",
            "0.00.008.977 W Thread 3: 285\n",
            "0.00.008.978 I Thread 3: 286\n",
            "Thread 3: 289\n",
            "0.00.008.979 E Thread 3: 290\n",
            "I Thread 3: 292\n",
            "W Thread 3: 293\n",
            "W Thread 3: 295\n",
            "Thread 3: 296\n",
            "Thread 3: 297\n",
            "Thread 3: 298\n",
            "Thread 3: 299\n",
            "Thread 3: 300\n",
            "E Thread 3: 301\n",
            "Thread 3: 303\n",
            "E Thread 3: 304\n",
            "Thread 3: 305\n",
            "Thread 3: 306\n",
            "I Thread 3: 308\n",
            "Thread 3: 309\n",
            "0.00.008.994 I Thread 3: 310\n",
            "I Thread 3: 311\n",
            "Thread 3: 312\n",
            "Thread 3: 313\n",
            "Thread 3: 314\n",
            "Thread 3: 315\n",
            "Thread 3: 316\n",
            "Thread 3: 317\n",
            "0.00.008.998 E Thread 3: 318\n",
            "Thread 3: 321\n",
            "Thread 3: 322\n",
            "Thread 3: 323\n",
            "0.00.009.000 I Thread 3: 324\n",
            "Thread 3: 325\n",
            "Thread 3: 326\n",
            "I Thread 3: 328\n",
            "W Thread 3: 329\n",
            "W Thread 3: 330\n",
            "Thread 3: 332\n",
            "Thread 3: 333\n",
            "Thread 3: 334\n",
            "Thread 3: 335\n",
            "0.00.009.006 I Thread 3: 336\n",
            "0.00.009.006 I Thread 3: 337\n",
            "0.00.009.007 E Thread 3: 338\n",
            "Thread 3: 339\n",
            "Thread 3: 341\n",
            "Thread 3: 342\n",
            "0.00.009.026 E Thread 3: 343\n",
            "0.00.009.026 E Thread 3: 344\n",
            "0.00.009.027 W Thread 3: 345\n",
            "0.00.009.027 E Thread 3: 347\n",
            "0.00.009.028 W Thread 3: 348\n",
            "0.00.009.028 I Thread 3: 349\n",
            "Thread 3: 350\n",
            "Thread 3: 353\n",
            "Thread 3: 354\n",
            "Thread 3: 356\n",
            "Thread 3: 357\n",
            "0.00.009.032 I Thread 3: 360\n",
            "0.00.009.033 W Thread 3: 361\n",
            "0.00.009.034 W Thread 3: 362\n",
            "I Thread 3: 363\n",
            "E Thread 3: 364\n",
            "Thread 3: 366\n",
            "Thread 3: 367\n",
            "Thread 3: 368\n",
            "Thread 3: 369\n",
            "Thread 3: 371\n",
            "Thread 3: 372\n",
            "Thread 3: 373\n",
            "Thread 3: 374\n",
            "Thread 3: 375\n",
            "Thread 3: 376\n",
            "Thread 3: 378\n",
            "W Thread 3: 379\n",
            "0.00.009.042 E Thread 3: 380\n",
            "E Thread 3: 382\n",
            "W Thread 3: 383\n",
            "Thread 3: 384\n",
            "Thread 3: 385\n",
            "Thread 3: 387\n",
            "Thread 3: 388\n",
            "E Thread 3: 389\n",
            "W Thread 3: 391\n",
            "E Thread 3: 395\n",
            "W Thread 3: 396\n",
            "Thread 3: 400\n",
            "Thread 3: 401\n",
            "Thread 3: 402\n",
            "W Thread 3: 403\n",
            "Thread 3: 404\n",
            "Thread 3: 405\n",
            "Thread 3: 406\n",
            "Thread 3: 407\n",
            "E Thread 3: 408\n",
            "0.00.009.053 W Thread 3: 409\n",
            "0.00.009.054 I Thread 3: 410\n",
            "Thread 3: 411\n",
            "I Thread 3: 412\n",
            "W Thread 3: 414\n",
            "W Thread 3: 415\n",
            "E Thread 3: 416\n",
            "Thread 3: 417\n",
            "Thread 3: 419\n",
            "Thread 3: 420\n",
            "E Thread 3: 423\n",
            "I Thread 3: 425\n",
            "I Thread 3: 427\n",
            "W Thread 3: 428\n",
            "I Thread 3: 429\n",
            "Thread 3: 431\n",
            "0.00.009.063 W Thread 3: 432\n",
            "0.00.009.064 I Thread 3: 433\n",
            "0.00.009.064 E Thread 3: 434\n",
            "0.00.009.065 W Thread 3: 435\n",
            "0.00.009.066 E Thread 3: 436\n",
            "0.00.009.066 W Thread 3: 438\n",
            "0.00.009.067 I Thread 3: 439\n",
            "Thread 3: 440\n",
            "Thread 3: 441\n",
            "Thread 3: 442\n",
            "Thread 3: 443\n",
            "Thread 3: 445\n",
            "0.00.009.070 W Thread 3: 446\n",
            "0.00.009.071 W Thread 3: 447\n",
            "0.00.009.071 I Thread 3: 449\n",
            "0.00.009.072 E Thread 3: 450\n",
            "Thread 3: 453\n",
            "Thread 3: 454\n",
            "Thread 3: 455\n",
            "W Thread 3: 456\n",
            "Thread 3: 457\n",
            "Thread 3: 458\n",
            "Thread 3: 459\n",
            "Thread 3: 460\n",
            "Thread 3: 461\n",
            "W Thread 3: 462\n",
            "W Thread 3: 465\n",
            "W Thread 3: 467\n",
            "W Thread 3: 471\n",
            "E Thread 3: 472\n",
            "0.00.009.081 I Thread 3: 473\n",
            "Thread 3: 475\n",
            "Thread 3: 476\n",
            "Thread 3: 479\n",
            "Thread 3: 480\n",
            "Thread 3: 482\n",
            "Thread 3: 483\n",
            "Thread 3: 484\n",
            "0.00.009.086 W Thread 3: 487\n",
            "0.00.009.087 W Thread 3: 488\n",
            "Thread 3: 490\n",
            "0.00.009.088 E Thread 3: 491\n",
            "Thread 3: 493\n",
            "E Thread 3: 494\n",
            "0.00.009.090 I Thread 3: 495\n",
            "Thread 3: 496\n",
            "Thread 3: 497\n",
            "0.00.009.091 W Thread 3: 498\n",
            "I Thread 3: 499\n",
            "I Thread 3: 501\n",
            "Thread 3: 502\n",
            "Thread 3: 503\n",
            "Thread 3: 504\n",
            "0.00.009.095 W Thread 3: 505\n",
            "0.00.009.096 W Thread 3: 507\n",
            "Thread 3: 508\n",
            "Thread 3: 510\n",
            "Thread 3: 511\n",
            "Thread 3: 512\n",
            "Thread 3: 513\n",
            "Thread 3: 514\n",
            "Thread 3: 515\n",
            "Thread 3: 516\n",
            "Thread 3: 517\n",
            "Thread 3: 518\n",
            "Thread 3: 520\n",
            "0.00.009.102 W Thread 3: 521\n",
            "Thread 3: 522\n",
            "Thread 3: 523\n",
            "Thread 3: 524\n",
            "Thread 3: 525\n",
            "Thread 3: 526\n",
            "0.00.009.106 E Thread 3: 527\n",
            "0.00.009.106 I Thread 3: 528\n",
            "0.00.009.107 I Thread 3: 529\n",
            "W Thread 3: 531\n",
            "I Thread 3: 533\n",
            "W Thread 3: 534\n",
            "E Thread 3: 536\n",
            "E Thread 3: 537\n",
            "W Thread 3: 538\n",
            "Thread 3: 540\n",
            "0.00.009.112 W Thread 3: 541\n",
            "Thread 3: 545\n",
            "0.00.009.113 W Thread 3: 546\n",
            "Thread 3: 548\n",
            "Thread 3: 549\n",
            "Thread 3: 550\n",
            "Thread 3: 551\n",
            "Thread 3: 553\n",
            "Thread 3: 555\n",
            "0.00.009.118 I Thread 3: 556\n",
            "Thread 3: 557\n",
            "Thread 3: 559\n",
            "Thread 3: 560\n",
            "W Thread 3: 561\n",
            "Thread 3: 562\n",
            "Thread 3: 563\n",
            "I Thread 3: 565\n",
            "Thread 3: 569\n",
            "Thread 3: 571\n",
            "Thread 3: 572\n",
            "Thread 3: 573\n",
            "Thread 3: 575\n",
            "Thread 3: 577\n",
            "Thread 3: 578\n",
            "Thread 3: 579\n",
            "Thread 3: 580\n",
            "Thread 3: 581\n",
            "Thread 3: 582\n",
            "Thread 3: 583\n",
            "Thread 3: 585\n",
            "Thread 3: 586\n",
            "Thread 3: 587\n",
            "Thread 3: 588\n",
            "Thread 3: 589\n",
            "Thread 3: 590\n",
            "Thread 3: 591\n",
            "Thread 3: 592\n",
            "0.00.009.134 W Thread 3: 593\n",
            "0.00.009.135 W Thread 3: 595\n",
            "Thread 3: 596\n",
            "W Thread 3: 598\n",
            "W Thread 3: 599\n",
            "E Thread 3: 600\n",
            "Thread 3: 601\n",
            "Thread 3: 602\n",
            "Thread 3: 603\n",
            "I Thread 3: 604\n",
            "W Thread 3: 605\n",
            "W Thread 3: 606\n",
            "I Thread 3: 607\n",
            "0.00.009.142 I Thread 3: 608\n",
            "E Thread 3: 609\n",
            "E Thread 3: 610\n",
            "E Thread 3: 611\n",
            "0.00.009.144 I Thread 3: 613\n",
            "Thread 3: 614\n",
            "Thread 3: 615\n",
            "Thread 3: 616\n",
            "Thread 3: 617\n",
            "Thread 3: 618\n",
            "Thread 3: 620\n",
            "I Thread 3: 623\n",
            "E Thread 3: 624\n",
            "E Thread 3: 625\n",
            "Thread 3: 628\n",
            "Thread 3: 629\n",
            "0.00.009.165 I Thread 3: 630\n",
            "Thread 3: 631\n",
            "Thread 3: 632\n",
            "Thread 3: 633\n",
            "Thread 3: 634\n",
            "Thread 3: 635\n",
            "Thread 3: 636\n",
            "Thread 3: 638\n",
            "Thread 3: 639\n",
            "W Thread 3: 640\n",
            "E Thread 3: 641\n",
            "W Thread 3: 642\n",
            "W Thread 3: 643\n",
            "0.00.009.183 I Thread 3: 644\n",
            "W Thread 3: 645\n",
            "Thread 3: 646\n",
            "0.00.009.184 I Thread 3: 649\n",
            "0.00.009.185 W Thread 3: 650\n",
            "0.00.009.185 E Thread 3: 651\n",
            "0.00.009.186 E Thread 3: 652\n",
            "0.00.009.187 E Thread 3: 654\n",
            "0.00.009.187 I Thread 3: 655\n",
            "0.00.009.188 E Thread 3: 656\n",
            "Thread 3: 657\n",
            "Thread 3: 658\n",
            "Thread 3: 659\n",
            "Thread 3: 660\n",
            "Thread 3: 661\n",
            "Thread 3: 662\n",
            "Thread 3: 663\n",
            "Thread 3: 664\n",
            "0.00.009.193 W Thread 3: 665\n",
            "E Thread 3: 666\n",
            "0.00.009.194 I Thread 3: 668\n",
            "Thread 3: 670\n",
            "Thread 3: 671\n",
            "I Thread 3: 673\n",
            "0.00.009.197 I Thread 3: 674\n",
            "Thread 3: 675\n",
            "Thread 3: 679\n",
            "Thread 3: 680\n",
            "0.00.009.199 E Thread 3: 682\n",
            "0.00.009.200 I Thread 3: 683\n",
            "I Thread 3: 684\n",
            "I Thread 3: 685\n",
            "0.00.009.201 I Thread 3: 686\n",
            "0.00.009.202 W Thread 3: 687\n",
            "0.00.009.202 E Thread 3: 688\n",
            "0.00.009.203 E Thread 3: 689\n",
            "0.00.009.204 I Thread 3: 691\n",
            "0.00.009.204 E Thread 3: 692\n",
            "0.00.009.204 W Thread 3: 693\n",
            "0.00.009.205 E Thread 3: 694\n",
            "0.00.009.205 I Thread 3: 695\n",
            "0.00.009.206 W Thread 3: 696\n",
            "W Thread 3: 697\n",
            "0.00.009.207 E Thread 3: 700\n",
            "0.00.009.208 I Thread 3: 702\n",
            "0.00.009.209 I Thread 3: 704\n",
            "I Thread 3: 705\n",
            "I Thread 3: 707\n",
            "I Thread 3: 708\n",
            "Thread 3: 710\n",
            "I Thread 3: 711\n",
            "W Thread 3: 712\n",
            "I Thread 3: 713\n",
            "Thread 3: 714\n",
            "W Thread 3: 715\n",
            "0.00.009.214 I Thread 3: 717\n",
            "W Thread 3: 718\n",
            "W Thread 3: 719\n",
            "W Thread 3: 720\n",
            "W Thread 3: 721\n",
            "0.00.009.217 E Thread 3: 723\n",
            "0.00.009.218 W Thread 3: 724\n",
            "Thread 3: 726\n",
            "Thread 3: 727\n",
            "0.00.009.220 E Thread 3: 729\n",
            "Thread 3: 731\n",
            "Thread 3: 732\n",
            "Thread 3: 733\n",
            "Thread 3: 734\n",
            "Thread 3: 735\n",
            "0.00.009.224 W Thread 3: 737\n",
            "I Thread 3: 738\n",
            "0.00.009.225 I Thread 3: 739\n",
            "0.00.009.226 W Thread 3: 740\n",
            "0.00.009.226 I Thread 3: 741\n",
            "Thread 3: 742\n",
            "Thread 3: 744\n",
            "Thread 3: 745\n",
            "Thread 3: 746\n",
            "Thread 3: 748\n",
            "W Thread 3: 749\n",
            "Thread 3: 751\n",
            "W Thread 3: 753\n",
            "Thread 3: 754\n",
            "I Thread 3: 756\n",
            "0.00.009.233 I Thread 3: 759\n",
            "0.00.009.234 E Thread 3: 760\n",
            "0.00.009.234 I Thread 3: 761\n",
            "I Thread 3: 762\n",
            "I Thread 3: 763\n",
            "0.00.009.236 E Thread 3: 764\n",
            "0.00.009.237 I Thread 3: 765\n",
            "E Thread 3: 766\n",
            "I Thread 3: 767\n",
            "W Thread 3: 769\n",
            "I Thread 3: 770\n",
            "Thread 3: 771\n",
            "Thread 3: 772\n",
            "Thread 3: 773\n",
            "Thread 3: 774\n",
            "Thread 3: 777\n",
            "Thread 3: 778\n",
            "Thread 3: 779\n",
            "Thread 3: 780\n",
            "Thread 3: 781\n",
            "Thread 3: 782\n",
            "Thread 3: 783\n",
            "E Thread 3: 784\n",
            "E Thread 3: 786\n",
            "0.00.009.246 E Thread 3: 787\n",
            "Thread 3: 788\n",
            "Thread 3: 789\n",
            "Thread 3: 791\n",
            "Thread 3: 792\n",
            "Thread 3: 793\n",
            "Thread 3: 794\n",
            "Thread 3: 795\n",
            "Thread 3: 796\n",
            "Thread 3: 797\n",
            "E Thread 3: 798\n",
            "E Thread 3: 799\n",
            "I Thread 3: 800\n",
            "W Thread 3: 801\n",
            "W Thread 3: 802\n",
            "E Thread 3: 803\n",
            "I Thread 3: 804\n",
            "I Thread 3: 805\n",
            "W Thread 3: 806\n",
            "E Thread 3: 807\n",
            "I Thread 3: 808\n",
            "Thread 3: 810\n",
            "Thread 3: 811\n",
            "I Thread 3: 812\n",
            "Thread 3: 813\n",
            "0.00.009.259 W Thread 3: 814\n",
            "0.00.009.260 I Thread 3: 815\n",
            "0.00.009.260 E Thread 3: 816\n",
            "0.00.009.261 W Thread 3: 817\n",
            "W Thread 3: 819\n",
            "Thread 3: 820\n",
            "Thread 3: 821\n",
            "Thread 3: 823\n",
            "Thread 3: 825\n",
            "Thread 3: 826\n",
            "Thread 3: 828\n",
            "Thread 3: 829\n",
            "Thread 3: 830\n",
            "Thread 3: 831\n",
            "Thread 3: 832\n",
            "Thread 3: 833\n",
            "W Thread 3: 834\n",
            "Thread 3: 836\n",
            "Thread 3: 837\n",
            "Thread 3: 838\n",
            "Thread 3: 839\n",
            "Thread 3: 840\n",
            "Thread 3: 841\n",
            "Thread 3: 843\n",
            "Thread 3: 844\n",
            "Thread 3: 845\n",
            "0.00.009.285 E Thread 3: 846\n",
            "0.00.009.285 W Thread 3: 847\n",
            "I Thread 3: 849\n",
            "I Thread 3: 850\n",
            "I Thread 3: 851\n",
            "0.00.009.288 I Thread 3: 854\n",
            "0.00.009.288 W Thread 3: 855\n",
            "Thread 3: 856\n",
            "Thread 3: 857\n",
            "Thread 3: 859\n",
            "Thread 3: 861\n",
            "Thread 3: 862\n",
            "Thread 3: 863\n",
            "I Thread 3: 865\n",
            "E Thread 3: 868\n",
            "I Thread 3: 869\n",
            "Thread 3: 872\n",
            "Thread 3: 874\n",
            "Thread 3: 875\n",
            "Thread 3: 876\n",
            "Thread 3: 877\n",
            "Thread 3: 878\n",
            "Thread 3: 880\n",
            "Thread 3: 881\n",
            "Thread 3: 882\n",
            "Thread 3: 883\n",
            "Thread 3: 884\n",
            "Thread 3: 885\n",
            "Thread 3: 886\n",
            "Thread 3: 888\n",
            "Thread 3: 889\n",
            "Thread 3: 890\n",
            "Thread 3: 891\n",
            "Thread 3: 892\n",
            "Thread 3: 893\n",
            "I Thread 3: 895\n",
            "0.00.009.305 W Thread 3: 896\n",
            "0.00.009.306 E Thread 3: 898\n",
            "0.00.009.306 I Thread 3: 899\n",
            "0.00.009.307 W Thread 3: 900\n",
            "0.00.009.307 I Thread 3: 902\n",
            "0.00.009.308 I Thread 3: 903\n",
            "0.00.009.308 W Thread 3: 904\n",
            "Thread 3: 906\n",
            "Thread 3: 907\n",
            "Thread 3: 908\n",
            "0.00.009.310 E Thread 3: 909\n",
            "0.00.009.311 E Thread 3: 911\n",
            "0.00.009.312 E Thread 3: 913\n",
            "Thread 3: 917\n",
            "Thread 3: 918\n",
            "Thread 3: 919\n",
            "Thread 3: 921\n",
            "Thread 3: 923\n",
            "Thread 3: 924\n",
            "Thread 3: 926\n",
            "Thread 3: 927\n",
            "0.00.009.318 E Thread 3: 928\n",
            "Thread 3: 929\n",
            "Thread 3: 930\n",
            "Thread 3: 932\n",
            "0.00.009.320 W Thread 3: 934\n",
            "Thread 3: 935\n",
            "0.00.009.321 W Thread 3: 936\n",
            "Thread 3: 937\n",
            "0.00.009.322 W Thread 3: 938\n",
            "0.00.009.323 E Thread 3: 939\n",
            "E Thread 3: 941\n",
            "Thread 3: 942\n",
            "W Thread 3: 946\n",
            "W Thread 3: 947\n",
            "E Thread 3: 951\n",
            "Thread 3: 952\n",
            "Thread 3: 954\n",
            "Thread 3: 955\n",
            "Thread 3: 956\n",
            "Thread 3: 957\n",
            "E Thread 3: 960\n",
            "Thread 3: 961\n",
            "Thread 3: 962\n",
            "I Thread 3: 963\n",
            "W Thread 3: 964\n",
            "0.00.009.332 W Thread 3: 965\n",
            "0.00.009.333 I Thread 3: 966\n",
            "I Thread 3: 968\n",
            "W Thread 3: 969\n",
            "E Thread 3: 970\n",
            "I Thread 3: 971\n",
            "I Thread 3: 972\n",
            "Thread 3: 973\n",
            "Thread 3: 974\n",
            "Thread 3: 976\n",
            "E Thread 3: 977\n",
            "Thread 3: 978\n",
            "Thread 3: 979\n",
            "Thread 3: 980\n",
            "0.00.009.340 I Thread 3: 981\n",
            "Thread 3: 982\n",
            "0.00.009.341 W Thread 3: 983\n",
            "0.00.009.342 W Thread 3: 984\n",
            "0.00.009.342 W Thread 3: 985\n",
            "0.00.009.343 E Thread 3: 986\n",
            "0.00.009.343 E Thread 3: 987\n",
            "0.00.009.344 W Thread 3: 988\n",
            "0.00.009.344 E Thread 3: 989\n",
            "Thread 3: 991\n",
            "Thread 3: 992\n",
            "Thread 3: 993\n",
            "Thread 3: 994\n",
            "Thread 3: 995\n",
            "Thread 3: 996\n",
            "0.00.009.348 I Thread 3: 997\n",
            "0.00.009.349 I Thread 3: 998\n",
            "0.00.009.349 E Thread 3: 999\n",
            "0.00.014.779 E Thread 2: 414\n",
            "Thread 2: 415\n",
            "Thread 2: 416\n",
            "Thread 2: 418\n",
            "Thread 2: 419\n",
            "W Thread 2: 420\n",
            "Thread 2: 421\n",
            "0.00.014.785 I Thread 2: 422\n",
            "0.00.014.786 W Thread 2: 423\n",
            "0.00.014.787 I Thread 2: 424\n",
            "E Thread 2: 425\n",
            "I Thread 2: 426\n",
            "0.00.014.789 W Thread 2: 428\n",
            "Thread 2: 429\n",
            "Thread 2: 431\n",
            "Thread 2: 432\n",
            "Thread 2: 433\n",
            "Thread 2: 434\n",
            "I Thread 2: 435\n",
            "Thread 2: 436\n",
            "Thread 2: 437\n",
            "Thread 2: 440\n",
            "I Thread 2: 441\n",
            "I Thread 2: 442\n",
            "W Thread 2: 443\n",
            "W Thread 2: 444\n",
            "0.00.014.797 E Thread 2: 445\n",
            "Thread 2: 446\n",
            "Thread 2: 447\n",
            "Thread 2: 448\n",
            "Thread 2: 449\n",
            "Thread 2: 450\n",
            "Thread 2: 451\n",
            "Thread 2: 452\n",
            "Thread 2: 453\n",
            "Thread 2: 454\n",
            "I Thread 2: 455\n",
            "Thread 2: 457\n",
            "Thread 2: 458\n",
            "Thread 2: 459\n",
            "Thread 2: 460\n",
            "Thread 2: 461\n",
            "Thread 2: 462\n",
            "W Thread 2: 463\n",
            "E Thread 2: 464\n",
            "W Thread 2: 465\n",
            "0.00.014.808 W Thread 2: 466\n",
            "0.00.014.809 I Thread 2: 467\n",
            "I Thread 2: 468\n",
            "E Thread 2: 469\n",
            "Thread 2: 471\n",
            "Thread 2: 472\n",
            "Thread 2: 473\n",
            "Thread 2: 476\n",
            "0.00.014.813 E Thread 2: 477\n",
            "0.00.014.814 E Thread 2: 478\n",
            "Thread 2: 479\n",
            "Thread 2: 481\n",
            "Thread 2: 482\n",
            "Thread 2: 484\n",
            "0.00.014.817 E Thread 2: 486\n",
            "0.00.014.817 E Thread 2: 487\n",
            "0.00.014.818 W Thread 2: 488\n",
            "Thread 2: 489\n",
            "I Thread 2: 492\n",
            "Thread 2: 493\n",
            "W Thread 2: 494\n",
            "E Thread 2: 496\n",
            "Thread 2: 497\n",
            "Thread 2: 498\n",
            "Thread 2: 499\n",
            "Thread 2: 501\n",
            "0.00.014.824 E Thread 2: 502\n",
            "0.00.014.824 E Thread 2: 503\n",
            "0.00.014.825 W Thread 2: 504\n",
            "0.00.014.825 W Thread 2: 505\n",
            "0.00.014.826 W Thread 2: 506\n",
            "Thread 2: 507\n",
            "0.00.014.827 E Thread 2: 509\n",
            "0.00.014.828 E Thread 2: 510\n",
            "0.00.014.828 E Thread 2: 511\n",
            "0.00.014.829 E Thread 2: 512\n",
            "Thread 2: 513\n",
            "W Thread 2: 514\n",
            "W Thread 2: 515\n",
            "E Thread 2: 517\n",
            "I Thread 2: 518\n",
            "0.00.014.833 E Thread 2: 519\n",
            "Thread 2: 521\n",
            "Thread 2: 522\n",
            "Thread 2: 525\n",
            "Thread 2: 526\n",
            "Thread 2: 527\n",
            "Thread 2: 529\n",
            "Thread 2: 531\n",
            "Thread 2: 533\n",
            "Thread 2: 534\n",
            "Thread 2: 535\n",
            "0.00.014.839 I Thread 2: 536\n",
            "0.00.014.839 I Thread 2: 537\n",
            "0.00.014.840 E Thread 2: 538\n",
            "0.00.014.841 E Thread 2: 539\n",
            "0.00.014.841 W Thread 2: 540\n",
            "0.00.014.842 I Thread 2: 541\n",
            "W Thread 2: 544\n",
            "W Thread 2: 545\n",
            "Thread 2: 547\n",
            "Thread 2: 548\n",
            "Thread 2: 550\n",
            "Thread 2: 551\n",
            "Thread 2: 554\n",
            "W Thread 2: 555\n",
            "Thread 2: 556\n",
            "Thread 2: 559\n",
            "W Thread 2: 560\n",
            "0.00.014.849 I Thread 2: 561\n",
            "W Thread 2: 562\n",
            "I Thread 2: 563\n",
            "I Thread 2: 564\n",
            "I Thread 2: 565\n",
            "E Thread 2: 568\n",
            "I Thread 2: 570\n",
            "E Thread 2: 572\n",
            "I Thread 2: 573\n",
            "I Thread 2: 574\n",
            "Thread 2: 575\n",
            "Thread 2: 576\n",
            "Thread 2: 578\n",
            "Thread 2: 579\n",
            "Thread 2: 581\n",
            "0.00.014.859 E Thread 2: 584\n",
            "0.00.014.859 E Thread 2: 586\n",
            "E Thread 2: 587\n",
            "0.00.014.861 I Thread 2: 588\n",
            "I Thread 2: 589\n",
            "E Thread 2: 590\n",
            "Thread 2: 591\n",
            "0.00.014.863 E Thread 2: 593\n",
            "0.00.014.864 W Thread 2: 594\n",
            "0.00.014.865 I Thread 2: 596\n",
            "I Thread 2: 597\n",
            "Thread 2: 598\n",
            "0.00.014.866 I Thread 2: 599\n",
            "0.00.014.867 W Thread 2: 602\n",
            "0.00.014.868 E Thread 2: 604\n",
            "I Thread 2: 607\n",
            "W Thread 2: 608\n",
            "Thread 2: 610\n",
            "0.00.014.871 I Thread 2: 611\n",
            "0.00.014.871 E Thread 2: 612\n",
            "0.00.014.872 W Thread 2: 613\n",
            "0.00.014.872 I Thread 2: 614\n",
            "Thread 2: 615\n",
            "Thread 2: 616\n",
            "Thread 2: 617\n",
            "Thread 2: 618\n",
            "Thread 2: 620\n",
            "Thread 2: 621\n",
            "Thread 2: 622\n",
            "Thread 2: 623\n",
            "Thread 2: 624\n",
            "W Thread 2: 625\n",
            "W Thread 2: 626\n",
            "I Thread 2: 627\n",
            "0.00.014.880 W Thread 2: 628\n",
            "0.00.014.880 W Thread 2: 629\n",
            "I Thread 2: 630\n",
            "Thread 2: 632\n",
            "Thread 2: 633\n",
            "Thread 2: 635\n",
            "Thread 2: 636\n",
            "Thread 2: 637\n",
            "E Thread 2: 639\n",
            "E Thread 2: 641\n",
            "W Thread 2: 643\n",
            "0.00.014.887 I Thread 2: 645\n",
            "Thread 2: 647\n",
            "Thread 2: 648\n",
            "Thread 2: 649\n",
            "Thread 2: 650\n",
            "Thread 2: 652\n",
            "Thread 2: 654\n",
            "0.00.014.892 W Thread 2: 655\n",
            "Thread 2: 656\n",
            "Thread 2: 657\n",
            "0.00.014.893 I Thread 2: 658\n",
            "0.00.014.894 E Thread 2: 659\n",
            "Thread 2: 661\n",
            "Thread 2: 662\n",
            "Thread 2: 663\n",
            "I Thread 2: 664\n",
            "I Thread 2: 665\n",
            "Thread 2: 667\n",
            "Thread 2: 668\n",
            "Thread 2: 670\n",
            "Thread 2: 671\n",
            "0.00.014.900 I Thread 2: 674\n",
            "Thread 2: 675\n",
            "Thread 2: 676\n",
            "Thread 2: 677\n",
            "Thread 2: 678\n",
            "W Thread 2: 679\n",
            "E Thread 2: 681\n",
            "0.00.014.905 I Thread 2: 682\n",
            "0.00.014.905 E Thread 2: 683\n",
            "0.00.014.906 W Thread 2: 685\n",
            "Thread 2: 686\n",
            "Thread 2: 687\n",
            "Thread 2: 688\n",
            "Thread 2: 690\n",
            "Thread 2: 691\n",
            "Thread 2: 692\n",
            "I Thread 2: 693\n",
            "I Thread 2: 694\n",
            "E Thread 2: 695\n",
            "W Thread 2: 697\n",
            "0.00.014.913 E Thread 2: 698\n",
            "0.00.014.913 E Thread 2: 699\n",
            "Thread 2: 700\n",
            "Thread 2: 701\n",
            "Thread 2: 702\n",
            "Thread 2: 703\n",
            "0.00.014.916 E Thread 2: 705\n",
            "0.00.014.916 W Thread 2: 706\n",
            "0.00.014.917 E Thread 2: 710\n",
            "Thread 2: 718\n",
            "Thread 2: 719\n",
            "Thread 2: 720\n",
            "Thread 2: 721\n",
            "Thread 2: 722\n",
            "Thread 2: 723\n",
            "0.00.014.922 W Thread 2: 724\n",
            "0.00.014.922 E Thread 2: 725\n",
            "Thread 2: 728\n",
            "Thread 2: 729\n",
            "Thread 2: 730\n",
            "Thread 2: 731\n",
            "Thread 2: 732\n",
            "Thread 2: 733\n",
            "Thread 2: 735\n",
            "0.00.014.927 W Thread 2: 736\n",
            "0.00.014.928 E Thread 2: 737\n",
            "Thread 2: 738\n",
            "Thread 2: 739\n",
            "I Thread 2: 740\n",
            "Thread 2: 741\n",
            "Thread 2: 742\n",
            "Thread 2: 743\n",
            "0.00.014.932 W Thread 2: 744\n",
            "0.00.014.933 E Thread 2: 747\n",
            "0.00.014.934 W Thread 2: 748\n",
            "Thread 2: 749\n",
            "Thread 2: 750\n",
            "Thread 2: 751\n",
            "Thread 2: 753\n",
            "Thread 2: 754\n",
            "W Thread 2: 755\n",
            "Thread 2: 756\n",
            "Thread 2: 757\n",
            "0.00.014.939 I Thread 2: 758\n",
            "0.00.014.940 I Thread 2: 759\n",
            "I Thread 2: 760\n",
            "Thread 2: 761\n",
            "W Thread 2: 762\n",
            "W Thread 2: 763\n",
            "E Thread 2: 764\n",
            "I Thread 2: 765\n",
            "W Thread 2: 766\n",
            "E Thread 2: 767\n",
            "W Thread 2: 768\n",
            "0.00.014.946 W Thread 2: 769\n",
            "W Thread 2: 771\n",
            "I Thread 2: 772\n",
            "W Thread 2: 773\n",
            "E Thread 2: 774\n",
            "Thread 2: 775\n",
            "I Thread 2: 777\n",
            "E Thread 2: 779\n",
            "W Thread 2: 781\n",
            "I Thread 2: 782\n",
            "E Thread 2: 783\n",
            "Thread 2: 784\n",
            "I Thread 2: 785\n",
            "Thread 2: 786\n",
            "I Thread 2: 787\n",
            "I Thread 2: 788\n",
            "Thread 2: 790\n",
            "0.00.014.955 I Thread 2: 792\n",
            "0.00.014.956 I Thread 2: 793\n",
            "0.00.014.956 I Thread 2: 794\n",
            "Thread 2: 795\n",
            "E Thread 2: 796\n",
            "I Thread 2: 797\n",
            "W Thread 2: 799\n",
            "W Thread 2: 800\n",
            "Thread 2: 801\n",
            "0.00.014.960 W Thread 2: 802\n",
            "0.00.014.961 E Thread 2: 803\n",
            "Thread 2: 804\n",
            "E Thread 2: 806\n",
            "0.00.014.963 I Thread 2: 808\n",
            "W Thread 2: 809\n",
            "0.00.014.965 W Thread 2: 810\n",
            "Thread 2: 811\n",
            "Thread 2: 812\n",
            "0.00.014.966 W Thread 2: 816\n",
            "0.00.014.967 W Thread 2: 817\n",
            "Thread 2: 818\n",
            "Thread 2: 819\n",
            "Thread 2: 820\n",
            "0.00.014.969 E Thread 2: 821\n",
            "Thread 2: 822\n",
            "Thread 2: 823\n",
            "Thread 2: 824\n",
            "Thread 2: 827\n",
            "Thread 2: 829\n",
            "Thread 2: 830\n",
            "Thread 2: 831\n",
            "Thread 2: 832\n",
            "Thread 2: 833\n",
            "Thread 2: 834\n",
            "0.00.014.976 I Thread 2: 835\n",
            "W Thread 2: 836\n",
            "0.00.014.977 I Thread 2: 838\n",
            "Thread 2: 840\n",
            "Thread 2: 841\n",
            "Thread 2: 842\n",
            "Thread 2: 843\n",
            "Thread 2: 844\n",
            "Thread 2: 847\n",
            "I Thread 2: 848\n",
            "Thread 2: 850\n",
            "E Thread 2: 851\n",
            "W Thread 2: 852\n",
            "E Thread 2: 854\n",
            "W Thread 2: 855\n",
            "W Thread 2: 857\n",
            "I Thread 2: 858\n",
            "I Thread 2: 859\n",
            "W Thread 2: 860\n",
            "I Thread 2: 862\n",
            "Thread 2: 863\n",
            "Thread 2: 864\n",
            "Thread 2: 865\n",
            "Thread 2: 866\n",
            "0.00.014.997 E Thread 2: 869\n",
            "0.00.014.997 W Thread 2: 871\n",
            "I Thread 2: 872\n",
            "Thread 2: 873\n",
            "0.00.014.999 E Thread 2: 874\n",
            "0.00.015.000 I Thread 2: 875\n",
            "0.00.015.000 W Thread 2: 876\n",
            "I Thread 2: 877\n",
            "W Thread 2: 881\n",
            "0.00.015.002 I Thread 2: 883\n",
            "0.00.015.003 E Thread 2: 885\n",
            "0.00.015.003 I Thread 2: 886\n",
            "0.00.015.004 I Thread 2: 887\n",
            "0.00.015.005 I Thread 2: 888\n",
            "0.00.015.005 E Thread 2: 889\n",
            "Thread 2: 893\n",
            "Thread 2: 894\n",
            "Thread 2: 896\n",
            "0.00.015.008 W Thread 2: 897\n",
            "E Thread 2: 898\n",
            "W Thread 2: 899\n",
            "Thread 2: 900\n",
            "Thread 2: 901\n",
            "Thread 2: 902\n",
            "Thread 2: 903\n",
            "Thread 2: 906\n",
            "Thread 2: 907\n",
            "Thread 2: 909\n",
            "Thread 2: 910\n",
            "Thread 2: 911\n",
            "Thread 2: 912\n",
            "E Thread 2: 913\n",
            "I Thread 2: 914\n",
            "E Thread 2: 915\n",
            "W Thread 2: 916\n",
            "Thread 2: 918\n",
            "Thread 2: 919\n",
            "Thread 2: 920\n",
            "I Thread 2: 921\n",
            "I Thread 2: 922\n",
            "E Thread 2: 925\n",
            "I Thread 2: 926\n",
            "0.00.015.022 W Thread 2: 928\n",
            "0.00.015.023 W Thread 2: 929\n",
            "0.00.015.023 I Thread 2: 930\n",
            "Thread 2: 931\n",
            "Thread 2: 932\n",
            "Thread 2: 933\n",
            "Thread 2: 934\n",
            "Thread 2: 935\n",
            "Thread 2: 936\n",
            "0.00.015.028 E Thread 2: 937\n",
            "0.00.015.028 I Thread 2: 938\n",
            "0.00.015.029 E Thread 2: 939\n",
            "Thread 2: 940\n",
            "Thread 2: 941\n",
            "0.00.015.031 E Thread 2: 945\n",
            "Thread 2: 947\n",
            "Thread 2: 948\n",
            "Thread 2: 949\n",
            "Thread 2: 950\n",
            "Thread 2: 952\n",
            "0.00.015.035 E Thread 2: 955\n",
            "0.00.015.036 I Thread 2: 956\n",
            "E Thread 2: 958\n",
            "Thread 2: 959\n",
            "0.00.015.038 E Thread 2: 960\n",
            "0.00.015.038 I Thread 2: 961\n",
            "Thread 2: 963\n",
            "0.00.015.039 E Thread 2: 965\n",
            "I Thread 2: 966\n",
            "E Thread 2: 969\n",
            "Thread 2: 970\n",
            "Thread 2: 971\n",
            "I Thread 2: 977\n",
            "E Thread 2: 978\n",
            "Thread 2: 979\n",
            "Thread 2: 980\n",
            "E Thread 2: 982\n",
            "E Thread 2: 983\n",
            "W Thread 2: 984\n",
            "E Thread 2: 986\n",
            "Thread 2: 987\n",
            "Thread 2: 988\n",
            "Thread 2: 989\n",
            "Thread 2: 991\n",
            "Thread 2: 992\n",
            "Thread 2: 995\n",
            "Thread 2: 996\n",
            "W Thread 2: 997\n",
            "Thread 2: 998\n",
            "Thread 2: 999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/build/bin/test-gguf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxppyZs4muJ5",
        "outputId": "e0d1c143-22c5-402c-c761-8708a87a8d08"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/build/bin/test-gguf: error while loading shared libraries: libggml.so: cannot open shared object file: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!find /content -name libllama.so"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJVAjoEum0WC",
        "outputId": "60ee5aa5-0e5c-46b4-a299-b781bac4656d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/build/bin/libllama.so\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/content/llama.cpp/build/Release"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "qV7NoeOWnQjr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "source": [
        "!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/content/llama.cpp/build/Release"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "W0vFNAwPnVqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/content/build/bin"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "JJ5rYJB-m3oS"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "source": [
        "!/content/build/bin/llama-cli -h"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5inN624Qm5_G",
        "outputId": "648ce1d9-1828-4b0b-cc97-d584124f4fe9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/build/bin/llama-cli: error while loading shared libraries: libllama.so: cannot open shared object file: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./llama-cli -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqPxc2OCmxUQ",
        "outputId": "956bc80e-2fc0-4a73-a245-75c4d3d99a81"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: ./llama-cli: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XRvhkueAnINR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/content/llama.cpp/build/Release"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "4LkQmGmRnW6q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "source": [
        "!/content/build/bin/llama-cli -h"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7jCTr_noaR8",
        "outputId": "cdcf3d14-d2fe-4598-a9d1-6fc2124c29ef"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/build/bin/llama-cli: error while loading shared libraries: libllama.so: cannot open shared object file: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content/build -name libllama.so."
      ],
      "metadata": {
        "id": "l3wPnmyBobKA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!find / -name libllama.so."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LCwzSQookKJ",
        "outputId": "84fea957-40ee-4c1e-fe90-c416b0752553"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "find: ‘/proc/66/task/66/net’: Invalid argument\n",
            "find: ‘/proc/66/net’: Invalid argument\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/build/bin/llama-run"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0ulB8LXoovJ",
        "outputId": "aa825d1a-2151-4303-aaa9-d9d2170c9904"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/build/bin/llama-run: error while loading shared libraries: libllama.so: cannot open shared object file: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/content/llama.cpp/build/Release"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "vMlHMS9Posso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/build/bin/llama-server"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoLTCa6ZpPWV",
        "outputId": "92a87a8b-76cc-46b0-a1bb-aac3cfbcf84b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/build/bin/llama-server: error while loading shared libraries: libllama.so: cannot open shared object file: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --branch BambaArchitecture git@github.com:gabe-l-hart/llama.cpp.git\n",
        "%cd llama.cpp\n",
        "!mkdir build\n",
        "%cd build\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQlgRKxppP35",
        "outputId": "5d1a180f-c7fe-401a-e048-e9d8ed341bad"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'llama.cpp'...\n",
            "Host key verification failed.\n",
            "fatal: Could not read from remote repository.\n",
            "\n",
            "Please make sure you have the correct access rights\n",
            "and the repository exists.\n",
            "[Errno 2] No such file or directory: 'llama.cpp'\n",
            "/content\n",
            "mkdir: cannot create directory ‘build’: File exists\n",
            "/content/build\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cmake .. -DCMAKE_BUILD_TYPE=Release\n",
        "!make -j\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xnvsuSvpcTh",
        "outputId": "cfe35d40-dcd8-43a7-96ea-8d933fbd654e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mCMake Warning:\n",
            "  Ignoring extra path from command line:\n",
            "\n",
            "   \"..\"\n",
            "\n",
            "\u001b[0m\n",
            "\u001b[0mCMake Error: The source directory \"/content\" does not appear to contain CMakeLists.txt.\n",
            "Specify --help for usage, or press the help button on the CMake GUI.\u001b[0m\n",
            "make: *** No targets specified and no makefile found.  Stop.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!make"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYmhOA9Ipnlp",
        "outputId": "78b63e1a-2bf8-4fd9-e08b-0f09177f3e2a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "make: *** No targets specified and no makefile found.  Stop.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone --branch BambaArchitecture git@github.com:gabe-l-hart/llama.cpp.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b683Vw2pp9B",
        "outputId": "9ab9ddba-ea68-4dc4-904e-b217d5b189c0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'llama.cpp'...\n",
            "Host key verification failed.\n",
            "fatal: Could not read from remote repository.\n",
            "\n",
            "Please make sure you have the correct access rights\n",
            "and the repository exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./bin/llama-cli  -ngl 0 -m /content/bamba-9b.gguf -p \"Tell me a story about a developer and their dog\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1m7A1Rsp4SR",
        "outputId": "ac0740e6-275d-46d1-c38c-832630616a5e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: ./bin/llama-cli: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!git clone --branch BambaArchitecture git@github.com:gabe-l-hart/llama.cpp.git"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDp-ToeQqf77",
        "outputId": "6ae1075f-e338-49d6-ed6f-5f1a8d9ff919"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'llama.cpp'...\n",
            "Host key verification failed.\r\n",
            "fatal: Could not read from remote repository.\n",
            "\n",
            "Please make sure you have the correct access rights\n",
            "and the repository exists.\n"
          ]
        }
      ]
    }
  ]
}